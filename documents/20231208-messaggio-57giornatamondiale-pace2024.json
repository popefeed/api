{
    "id": "20231208-messaggio-57giornatamondiale-pace2024",
    "pope_id": "francesco",
    "type": "messages",
    "date": "",
    "title": "LVII World Day of Peace 2024 - Artificial Intelligence and Peace",
    "excerpt": {
        "ar": "في بداية السّنة الجديدة، زمن النّعمة الذي يمنحه الله لكلّ واحد منّا، أودّ أن أتوجّه إلى شعب الله، وإلى شعوب العالم، ورؤساء الدّول والحكومات، وممثّلي الدّيانات المختلفة والمجتمع المدنيّ، وإلى جميع الرّجال والنّساء في زمننا، لأقدّم للجميع أمنية سلام شامل.",
        "zh_cn": "1. 科技的进步作为走向和平的途径 圣经里证实天主赐下圣神给人类，使他们有「智能、技能和知识，能做各种工程」（出卅 五 31）。人类的聪明才智是造物主赐予尊严的表现，因祂按自己的肖像和模样创造了我 们（参阅：创一 26），且让我们能有意识并自由地回应祂的爱。科技则以特别的方式， 彰显了人类智慧基本的相关特质──人类创造潜力的杰出成果。",
        "zh_tw": "1. 科技的進步作為走向和平的途徑 聖經裡證實天主賜下聖神給人類，使他們有「智慧、技能和知識，能做各種工程」（出卅 五 31）。人類的聰明才智是造物主賜予尊嚴的表現，因祂按自己的肖像和模樣創造了我 們（參閱：創一 26），且讓我們能有意識並自由地回應祂的愛。科技則以特別的方式， 彰顯了人類智慧基本的相關特質──人類創造潛力的傑出成果。",
        "hr": "Na početku nove godine, milosnog vremena koje Gospodin daruje svakome od nas, želim se obratiti narodu Božjem, narodima, čelnicima država i vlada, predstavnicima različitih vjera i civilnog društva, te svim muškarcima i ženama našeg vremena kako bih im uputio najbolje želje za mir.",
        "en": "At the beginning of the New Year, a time of grace which the Lord gives to each one of us, I would like to address God’s People, the various nations, heads of state and government, the leaders of the different religions and civil society, and all the men and women of our time, in order to offer my fervent good wishes for peace.",
        "fr": "En ce début de la nouvelle année, temps de grâce que le Seigneur accorde à chacun d’entre nous, je voudrais m’adresser au Peuple de Dieu, aux nations, aux chefs d’État et de Gouvernement, aux représentants des différentes religions et de la société civile, ainsi qu’à tous les hommes et femmes de notre temps, pour leur présenter mes meilleurs vœux de paix.",
        "de": "Zu Beginn des neuen Jahres, einer Zeit der Gnade, die der Herr jedem von uns gewährt, möchte ich mich an das Volk Gottes, an die Nationen, an die Staats- und Regierungschefs, an die Vertreter der verschiedenen Religionen und der Zivilgesellschaft sowie an alle Männer und Frauen unserer Zeit wenden, um ihnen meine besten Wünsche für den Frieden zu übermitteln.",
        "it": "All’inizio del nuovo anno, tempo di grazia che il Signore dona a ciascuno di noi, vorrei rivolgermi al Popolo di Dio, alle nazioni, ai Capi di Stato e di Governo, ai Rappresentanti delle diverse religioni e della società civile, a tutti gli uomini e le donne del nostro tempo per porgere i miei auguri di pace.",
        "pl": "Na początku Nowego Roku, czasu łaski, który Pan daje każdemu z nas, chciałbym zwrócić się do Ludu Bożego, narodów, głów państw i rządów, przedstawicieli różnych religii i społeczeństwa obywatelskiego oraz wszystkich mężczyzn i kobiet naszych czasów, aby złożyć najlepsze życzenia pokoju.",
        "pt": "No início do novo ano, tempo de graça concedido pelo Senhor a cada um de nós, quero dirigir-me ao Povo de Deus, às nações, aos Chefes de Estado e de Governo, aos Representantes das diversas religiões e da sociedade civil, a todos os homens e mulheres do nosso tempo para lhes expressar os meus votos de paz.",
        "ru": "В начале нового года, времени благодати, которое Господь дарует каждому из нас, я хочу обратиться к Народу Божьему, нациям, главам государств и правительств, представителям различных религий и гражданского общества, а также ко всем людям нашего времени с наилучшими пожеланиями мира.",
        "sl": "Na začetku novega leta, časa milosti, ki ga Gospod podarja vsakemu izmed nas, bi rad nagovoril Božje ljudstvo, narode, voditelje držav in vlad, predstavnike različnih verstev in civilne družbe, vse može in žene našega časa ter jim izrazil svoje voščilo miru.",
        "es": "Al iniciar el año nuevo, tiempo de gracia que el Señor nos da a cada uno de nosotros, quisiera dirigirme al Pueblo de Dios, a las naciones, a los Jefes de Estado y de Gobierno, a los Representantes de las distintas religiones y de la sociedad civil, y a todos los hombres y mujeres de nuestro tiempo para expresarles mis mejores deseos de paz."
    },
    "metadata": {
        "vatican_urls": {
            "ar": "https://www.vatican.va/content/francesco/ar/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
            "zh_cn": "https://www.vatican.va/content/francesco/zh_cn/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
            "zh_tw": "https://www.vatican.va/content/francesco/zh_tw/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
            "hr": "https://www.vatican.va/content/francesco/hr/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
            "en": "https://www.vatican.va/content/francesco/en/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
            "fr": "https://www.vatican.va/content/francesco/fr/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
            "de": "https://www.vatican.va/content/francesco/de/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
            "it": "https://www.vatican.va/content/francesco/it/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
            "pl": "https://www.vatican.va/content/francesco/pl/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
            "pt": "https://www.vatican.va/content/francesco/pt/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
            "ru": "https://www.vatican.va/content/francesco/ru/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
            "sl": "https://www.vatican.va/content/francesco/sl/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html",
            "es": "https://www.vatican.va/content/francesco/es/messages/peace/documents/20231208-messaggio-57giornatamondiale-pace2024.html"
        },
        "raw_html": {
            "ar": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p dir=\"RTL\" style=\"text-align: center;\"><b>رسالة</b> <b>قداسة البابا</b></p>\n<p dir=\"RTL\" style=\"text-align: center;\"><b> فرنسيس</b></p>\n<p dir=\"RTL\" style=\"text-align: center;\"><b>في مناسبة اليوم العالمي السّابع والخمسين للسّلام</b></p>\n<p dir=\"RTL\" style=\"text-align: center;\"><b>الأوّل من كانون الثّاني/يناير 2024</b></p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p dir=\"RTL\" style=\"text-align: center;\"><b>الذّكاء الاصطناعيّ والسّلام</b></p>\n<p dir=\"RTL\" style=\"text-align: right;\">في بداية السّنة الجديدة، زمن النّعمة الذي يمنحه الله لكلّ واحد منّا، أودّ أن أتوجّه إلى شعب الله، وإلى شعوب العالم، ورؤساء الدّول والحكومات، وممثّلي الدّيانات المختلفة والمجتمع المدنيّ، وإلى جميع الرّجال والنّساء في زمننا، لأقدّم للجميع أمنية سلام شامل.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><b>1. تقدّم العِلم والتّكنولوجيا كطريق للسّلام</b></p>\n<p dir=\"RTL\" style=\"text-align: right;\">يؤكّد الكتاب المقدّس أنّ الله أعطى الإنسان روحه ليملأه \"مَهارةً وفَهْمًا ومَعرِفةً بِجَميعِ الصَّنائع\" (خروج 35، 31). الفَهم أو الذّكاء هو تعبير عن الكرامة التي أعطانا إيّاها الخالق، الذي خلقنا على صورته ومثاله (راجع تكوين 1، 26)، ومكّننا من أن نجيب على محبّته بالحرّيّة والمعرفة. والعِلم والتّكنولوجيا يُظهران بصورة خاصّة هذه الطّبيعة العلائقيّة الأساسيّة للذّكاء البشريّ: فهما نتاجان استثنائيّان لقدرته الإبداعيّة.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">في الدّستور الرّعائي فرح ورجاء، أكّد المجمع الفاتيكانيّ الثّاني هذه الحقيقة، وصرَّح أنّ \"الإنسان سعى دائمًا لتطوير حياتَه بعملِه وذكائه\" <a class=\"cleaner\" href=\"#_ftn1\" name=\"_ftnref1\">[1]</a>. عندما يسعى البشر، \"بالأدوات التّقنية\"، لكي يجعلوا الأرض \"مسكنًا لائقًا بالعائلة البشريّة كلّها\" <a class=\"cleaner\" href=\"#_ftn2\" name=\"_ftnref2\">[2]</a>، فإنّهم يعملون وفقًا لتدبير الله ويتعاونون مع إرادته لإكمال الخليقة ونشر السّلام بين الشّعوب. وتقدّم العِلم والتّكنولوجيا أيضًا، يؤدّي إلى تحسين الإنسان وتغيير العالم، بقدر مساهمتهما في تحسين نظام المجتمع البشريّ، وفي زيادة الحرّيّة والشّركة الأخويّة.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">ونحن بحقّ نفرح ونشعر بالشّكر وعرفان الجميل للإنجازات غير العاديّة التي حقّقها العِلم والتّكنولوجيا، والتي بفضلها وُجِدَ علاجٌ لعدد لا يحصى من الشّرور التي ابتليت بها الحياة البشريّة وتسبّبت في آلام كبيرة. وفي الوقت نفسه، فإنّ التّقدّم التّقنيّ والعِلميّ، الذي يجعل من الممكن ممارسة سيطرة غير مسبوقة حتّى الآن على الواقع، يضع مجموعة واسعة من الإمكانيّات في يدَيّ الإنسان، والتي قد يكون بعضها خطرًا على بقاء الإنسان وعلى بيتنا المشترك <a class=\"cleaner\" href=\"#_ftn3\" name=\"_ftnref3\">[3]</a>.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">ولذلك فإنّ التّقدّم الملحوظ الذي حقّقته تكنولوجيّات المعلومات الجديدة، وخاصّة في المجال الرّقميّ، إنّما هي فرص مدهشة، وفي الوقت نفسه مجازفة خطيرة، ولها آثار جدّيّة في السّعي لتحقيق العدل والوئام بين الشّعوب. ولذلك لا بدَّ من طرح بعض الأسئلة المُلِحَّة. ما هي العواقب في المدى القريب والبعيد للتكنولوجيّات الرّقميّة الجديدة؟ وماذا سيكون تأثيرها على حياة الأفراد والمجتمع وعلى الاستقرار الدّوليّ والسّلام؟</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><b>2. مستقبل الذّكاء الاصطناعيّ بين الوعود والمخاطر</b></p>\n<p dir=\"RTL\" style=\"text-align: right;\">التقدّم في تكنولوجيا المعلومات وتطوّر التّكنولوجيّات الرّقميّة بدأ يُحدِث، في العقود الأخيرة، تغيّرات عميقة في المجتمع العالميّ وديناميكيّاته. والأدوات الرّقميّة الجديدة أخذت تغيّر وجه الاتّصالات والإدارة العامّة والتّعليم والاستهلاك والعلاقات بين الأشخاص، وجوانب أخرى لا حصر لها في الحياة اليوميّة.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">وكذلك، التّقنيّات التي تستخدم عددًا كبيرًا من الخوارزميّات يمكنها أن تستخرج، من الآثار الرّقميّة المتبقّية على ”الإنترنت“، البيانات التي تسمح بالتّحكّم في عادات الأشخاص العقليّة والعلائقيّة لأغراض تجاريّة أو سياسيّة، غالبًا دون علمِهم، ما يحدّ من ممارستهم الواعية لحرّيّة الاختيار. في الواقع، في مساحة مثل الشّبكة المعلوماتيّة العالميّة (web)، التي تتميّز بكمّيّة زائدة من المعلومات، يمكن للتّقنيّات تنظيم تدفّق البيانات وفقًا لمعايير اختيار لا يشعر المستخدم بها دائمًا.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">علينا أن نتذكّر أنّ البحث العِلميّ والابتكارات التّكنولوجيّة ليست منزوعة من الواقع ولا هي ”حياديّة“ <a class=\"cleaner\" href=\"#_ftn4\" name=\"_ftnref4\">[4]</a>، ولكنّها تخضع للمؤثّرات الثّقافيّة. ولكونها أنشطة إنسانيّة بكلّ معنى الكلمة، فإنّ الاتّجاهات التي تتّخذها تعكس اختيارات متأثّرة بالقيَم الشّخصيّة والاجتماعيّة والثّقافيّة لكلّ عصر. والأمر نفسه ينطبق على النّتائج التي تحقّقها: فلأنّها نتيجة لمقاربات إنسانيّة في البيئة المحيطة بها، لها دائمًا بُعد أخلاقيّ، يرتبط ارتباطًا وثيقًا بقرارات الذين يخطّطون للتجربة ويوجّهون الإنتاج نحو أهداف خاصّة.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">وهذا ينطبق أيضًا على أشكال الذّكاء الاصطناعيّ. حتّى الآن، لا يوجد تعريف موحّد له في عالم العِلم والتكنولوجيّا. المصطلح نفسه، الذي دخل الآن في اللغة العامّة، يشمل مجموعة متنوّعة من العلوم والنّظريّات والتّقنيّات التي تهدف إلى جعل الآلات تنتج أو تقلِّد القدرات المعرفيّة للبشر في أدائها. الحديث بصيغة الجمع عن ”أشكال الذّكاء“ يمكن أن يساعد في المقام الأوّل على التّأكيد على الفجوة التي لا يمكن ردمها والتي توجد بين هذه الأنظمة، مهما كانت عجيبة وقويّة، وبين الإنسان: فهي في نهاية المطاف ”مجزّأة“، بمعنى أنّها تستطيع فقط تقليد أو إعادة إنتاج بعض وظائف الذّكاء البشري. استخدام صيغة الجمع يبيِّن أنّ هذه الأدوات، المختلفة كثيرًا بعضها عن بعض، يجب اعتبارها دائمًا ”أنظمة اجتماعيّة تقنيّة“. وفي الواقع، فإنّ تأثيرها، بغضّ النّظر عن التّكنولوجيا الأساسيّة، لا يعتمد على التّصميم فحسب، بل يعتمد أيضًا على أهداف ومصالح الذين يمتلكونها والذين يقومون بتطويرها، وكذلك على الحالات التي تُستَخدَم فيها.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">ولذلك، يجب أن يُفهم الذّكاء الاصطناعيّ على أنّه كوكبة من الحقائق المختلفة، ولا يمكننا أن نفترض بداهة أنّ تطوّره سيقدّم مساهمة مفيدة لمستقبل البشريّة وللسّلام بين الشّعوب. ولن تكون هذه النّتيجة الإيجابيّة ممكنة إلّا إذا أثبتنا أنّنا قادرون على التّصرّف بمسؤوليّة وباحترام القيَم الإنسانيّة الأساسيّة مثل \"الشّموليّة والشّفافيّة والأمن والعدالة والسّريّة والثّقة\" <a class=\"cleaner\" href=\"#_ftn5\" name=\"_ftnref5\">[5]</a>.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">ولا يكفي حتّى أن نفترض التزام الذين يصمّمون الخوارزميّات والتّقنيّات الرّقميّة بالتّصرّف بطريقة أخلاقيّة ومسؤولة. ينبغي تعزيز، أو، إذا لزم الأمر،إنشاء هيئات مسؤولة عن دراسة القضايا الأخلاقيّة المترتّبة عليها وحماية حقوق الذين يستخدمون بعض أشكال الذّكاء الاصطناعيّ أو يتأثّرون بها <a class=\"cleaner\" href=\"#_ftn6\" name=\"_ftnref6\">[6]</a>.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">ولذلك فإنّ التّوسّع الهائل في التّكنولوجيا يجب أن يكون مصحوبًا بالتّدريب الكافي على المسؤوليّة في تطويرها. الحرّيّة والعيش معًا بسلام يتعرّضان للتّهديد عندما يستسلِم البشر لتجارب الأنانيّة والمصلحة الشّخصيّة والجشع في الرّبح والتّعطّش إلى السّلطة. ولذلك، يقع على عاتقنا واجب توسيع الرّؤية وتوجيه البحث العِلميّ والتّقنيّ إلى تحقيق السّلام والخير العام، في خدمة التّنمية المتكاملة للإنسان والمجتمع <a class=\"cleaner\" href=\"#_ftn7\" name=\"_ftnref7\">[7]</a>.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">الكرامة الجوهريّة لكلّ شخص والأخوّة التي تربطنا أعضاءً في الأسرة البشريّة الواحدة يجب أن تكون أساسًا لتطوير التّكنولوجيّات الجديدة، فتكون بمثابة معايير لا جدال فيها لتقييمها قبل استخدامها، حتّى يتمكّن التّقدّم الرّقميّ من أن يتحقّق مع احترام العدل ومع المساهمة في قضيّة السّلام. التّطورات التّكنولوجيّة التي لا تؤدّي إلى تحسين نوعيّة حياة البشريّة جمعاء، بل عكس ذلك تؤدّي إلى تفاقم عدم المساواة والصّراعات، لا يمكن اعتبارها تقدّمًا حقيقيًّا <a class=\"cleaner\" href=\"#_ftn8\" name=\"_ftnref8\">[8]</a>.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">ستزداد أهمّيّة الذّكاء الاصطناعيّ. والتّحدّيات التي تثيرها هي تحدّيات تقنيّة، ولكنّها أيضًا أنثروبولوجيّة وتربويّة واجتماعيّة وسياسيّة. فهي تَعِد، مثلًا، بتوفير الجهد، وإنتاج أكثر فعّاليّة، ووسائل نقل أكثر راحة، وحركة متزايدة في الأسواق، فضلًا عن ثورة في عمليّات جمع البيانات وتنظيمها والتحقّق منها. وعلينا أن ندرك التّحوّلات السّريعة المستمرّة وأن نديرها بطريقة تصون حقوق الإنسان الأساسيّة، وتحترم المؤسّسات والقوانين التي تعزّز التّنمية البشريّة المتكاملة. الذّكاء الاصطناعيّ يجب أن يَخدُم أفضل الإمكانات البشريّة وأسمى تطلّعاتنا، ولا يتنافس معها.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><b>3. تكنولوجيا المستقبل: آلات تتعلَّم بنفسها</b></p>\n<p dir=\"RTL\" style=\"text-align: right;\">الذّكاء الاصطناعيّ، بأشكاله المتعدّدة، القائم على تقنيّات التّعلّم التّلقائي (التّعلّم الآلي)، رغم أنّه لا يزال في مرحلة رائدة، فإنّه بدأ يُدخل تغييرات ملحوظة في نسيج المجتمعات، ويُحدِث تأثيرًا عميقًا في الثّقافات والسّلوكيّات الاجتماعيّة وبناء السّلام.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">التّطورات مثل التّعلّم الآلي أو التّعلّم العميق تطرح أسئلة تفوق مجالات التّكنولوجيا والهندسة، ولها صلة بفهم مرتبط ارتباطًا وثيقًا بمعنى الحياة البشريّة وعمليّات المعرفة الأساسيّة وقدرة العقل على الوصول إلى الحقيقة.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">قدرة بعض الأجهزة على إنتاج نصوص متماسكة ومتناسقة من حيث المعنى، على سبيل المثال، ليس ضمانًا لنثق بها. يقال إنّهم يستطيعون أن ”يُحدِثوا وهمًا“، أي أن يصدروا عبارات تبدو للوهلة الأولى معقولة، ولكن في الواقع لا أساس لها من الصّحّة أو يمكن أن تدُلَّ على أحكام مسبقة. وهذه مشكلة خطيرة عندما يُستخدَم الذّكاء الاصطناعيّ في حملات التّضليل التي تنشر أخبارًا مزيّفة وتؤدّي إلى تزايد عدم الثّقة بوسائل الإعلام. السّريّة وحيازة البيانات والملكيّة الفكريّة هي مجالات أخرى تشكّل فيها هذه التّكنولوجيّات مخاطر جسيمة، يضاف إليها المزيد من العواقب السّلبيّة المرتبطة باستخدامها بصورة غير سليمة، مثل التّفرقة، والتّدخل في العمليّات الانتخابيّة، والانحياز إلى مجتمع يراقب ويتحكّم بالنّاس، وحرمان الاستخدام الرّقميّ، وتفاقم نزعة فرديّة تسبّب انفصالًا متزايدًا عن الجماعة. كلّ هذه العوامل تهدّد بتغذية الصّراعات وعرقلة السّلام.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><b>4. حسّ المحدوديّة في النّموذج التّكنوقراطيّ</b></p>\n<p dir=\"RTL\" style=\"text-align: right;\">عالمنا واسع جدًّا، ومتنوّع ومعقّد فلا يمكن أن نعرفه معرفة كاملة وأن نصنّفه. لا يمكن للعقل البشريّ أن يدرك بصورة كاملة غِنى العالم، ولا حتّى بمساعدة أكثر الخوارزميّات تقدّمًا. في الواقع، هذه الخوارزميّات لا تقدّم لنا توقّعات مضمونة عن المستقبل، بل إحصائيّات تقريبيّة فقط. لا يمكننا التنبُّؤ بكلّ شيء، ولا يمكننا أن نحسب كلّ شيء، لأنّه في النّهاية \"الواقع أسمى من الفكرة\" <a class=\"cleaner\" href=\"#_ftn9\" name=\"_ftnref9\">[9]</a> <sup><sup>[]</sup></sup>، ومهما بلغت قدرتنا الحسابيّة، سيكون هناك دائمًا أمور متبقّية لا يمكننا أن نَصِل إليها، فهي تَعصَى على كلّ محاولة لإخضاعها لقياساتنا.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">علاوة على ذلك، كمّيّة البيانات الكبيرة التي يحلّلها الذّكاء الاصطناعيّ ليست بحدِّ ذاتها ضمانة للحياديّة. عندما تخلط الخوارزميّات بين المعلومات عند استخدامها، فإنّها تهدّد بتشويهها، وتكرّر المظالم والأحكام المسبقة في البيئات التي تنشأ فيها. وكلّما زادت السّرعة، وزاد التّعقيد فيها، كلّما زادت صعوبة الفهم لماذا نتجت هذه النّتيجة المحدّدة.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">يمكن للآلات الذّكيّة أن تؤدّي المَهام المَوكولة إليها بكفاءة متزايدة، لكن، الهدف والمعنى لعمليّاتها، سيستمرّ الإنسان هو الذي يحدّدها أو يُفَعِّلُها، والإنسان له عالم خاصّ به من القِيَم. يكمن الخطر في أنّ المعايير لبعض الاختيارات تصير أقلّ وضوحًا، وتغيب المسؤوليّة في اتّخاذ القرار، ويتخلّى المنتجون عن الالتزام بالعمل من أجل خير الجماعة. بمعنى ما، يعزّز هذه الإمكانيّة النّظام التّكنوقراطيّ، الذي يربط الاقتصاد والتّكنولوجيا، ويفضِّل معيار الفعّاليّة في الإنتاج، فيميل إلى تجاهُل كلّ ما لا يرتبط بمصالحه المباشرة <a class=\"cleaner\" href=\"#_ftn10\" name=\"_ftnref10\">[10]</a> <sup><sup>[0]</sup></sup>.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">هذا الأمر يجب أن يجعلنا نفكّر في جانبٍ كثيرًا ما نتجاهله في العقليّة التكنوقراطيّة والموجّهة نحو الإنتاج، التي نعيشها في يومنا هذا. وهو أمر حاسم للتّنمية الشّخصيّة والاجتماعيّة، وهو: ”حسّ المحدوديّة“. في الواقع، الإنسان، الذي هو كائنٌ فانٍ بتعريفه، ويفكّر في تجاوز كلّ الحدود بفضل التّكنولوجيا، يوشك أن يفقد السَّيطرة على نفسه، في هَوَسِه لإخضاع كلّ شيء لسيطرته. وفي بحثه عن الحرّيّة المطلقة، يُخاطر أن يقع في دوّامة ”الدّيكتاتوريّة التّكنولوجيّة“. الاعتراف بحدودنا كخليقة والقبول بها، هو شرط لا غِنَى عنه للإنسان لكي يحقّق، أو بالأحرى، لكي يقبل الكمال كعطيّة. بينما، في السّياق الأيديولوجيّ للنّموذج التّكنوقراطيّ، الذي يدفعه غرور مثل غرور بروميثيوس بالاكتفاء الذّاتيّ، تزداد الاختلافات وعدم المساواة، وتتراكم المعرفة والمال في أيدي قلّة من النّاس، ويصحبها مخاطر جسيمة على المجتمعات الدّيمقراطيّة وعلى العيش معًا بسلام <a class=\"cleaner\" href=\"#_ftn11\" name=\"_ftnref11\">[11]</a> <sup><sup>[1]</sup></sup>.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><b>5. مواضيع صارخة في مجال الأخلاق</b></p>\n<p dir=\"RTL\" style=\"text-align: right;\">في المستقبل، مصداقيّة الشّخص الذي يطلب قرضًا ماليًّا، وملاءمة شخصٍ ما لوظيفة، وإمكانيّة وقوع الشّخص المحكوم عليه في الجرم ثانية، أو الحقّ في الحصول على اللجوء السّياسيّ أو المساعدة الاجتماعيّة، كلّ ذلك يمكّن أن تصير أنظمة الذّكاء الاصطناعيّ هي التي تحدّده. هذه الأنظمة تلغي مختلف مستويات الوساطة، وتُعرِّض للوقوع في أشكال من التَّحيّز والتّفرقة: إذ يمكن أن تتضاعف بسهولةالأخطاء المرتبطة بنظام، فتُنتج ظُلمًا ليس فقط في حالاتٍ فرديّة، بل أيضًا أخطاء متلاحقة مثل تتابع وقوع حجارة الدّومينو، وتسبّب أشكالًا حقيقيّة من عدم المساواة الاجتماعيّة.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">بالإضافة إلى ذلك، تبدو أحيانًا أشكال الذّكاء الاصطناعيّ قادرة على أن تؤثّر على قرارات الأفراد من خلال خيارات محدّدة مسبقًا ومرتبطة بمحفّزات وإقناع بالعدول عن الموقف، أو من خلال أنظمة تتحكَّم بالخيارات الشّخصيّة بناء على كيفيّة تنظيم المعلومات. هذه الأشكال من التّلاعب والخِداع أو السّيطرة الاجتماعيّة، تتطلّب تنبّهًا وتدقيقًا حذرًا، وتقع فيها مسؤوليّة قانونيّة واضحة على المنتجين، والذين يستخدمونها والسّلطات الحكوميّة.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">الاعتماد على عمليّات أوتوماتيكيّة تصنّف الأفراد، مثلًا من خلال استخدام مفرط للرّقابة أو اعتماد أنظمة الائتمان الاجتماعيّ، يمكن أن يكون له تداعيات عميقة، وأيضًا على النّسيج المدنيّ، ويحدّد تصنيفات غير صحيحة بين المواطنين. ويمكن أن تؤدّي عمليّات التّصنيف المُصطنعة هذه إلى صراعات على السّلطة أيضًا، ليس فقط بين الأشخاص الافتراضيّين، بل بين الأشخاص الحقيقيّين أيضًا. الاحترام الأساسيّ للكرامة الإنسانيّة يتطلّب منّا رفض أن يتمّ تحديد فرادة الشّخص من خلال مجموعة من البيانات. يجب ألّا نسمح للخوارزميّات أن تحدّد الطّريقة التي فيها نفهم حقوق الإنسان، وأن تضع جانبًا القِيَم الأساسيّة للرّأفة والرّحمة والغفران، أو إلغاء إمكانيّة أن يتغيّر الفرد وأن يترك ماضيه وراءه.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">في هذا السّياق، لا يسعنا إلّا أن نأخذ بعين الاعتبار تأثير التكنولوجيّات الجديدة في مجال العمل: الأعمال التي كانت في وقت من الأوقات حِكرًا على العمل البشريّ، سيطرت عليها بسرعة التّطبيقات الصّناعية للذّكاء الاصطناعيّ. في هذه الحالة أيضًا، يوجد خطر كبير لتحقيق فائدة غير متكافئة لعدد قليل من النّاس، على حساب كثيرين يُعرَّضون للفقر. احترام كرامة العمّال وأهمّيّة العمل لتحقيق الرّفاه الاقتصاديّ للأشخاص والعائلات والمجتمعات، والأمن الوظيفيّ والأجور العادلة، كلّ ذلك عليه أن يشكّل أولويّة عُليا للمجتمع الدّوليّ، فيما تتغلغل أشكال التّكنولوجيا هذه بشكل أعمق دائمًا في أماكن العمل.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><b>6. هل سنحوّل السيوف إلى سكك للحراثة؟</b></p>\n<p dir=\"RTL\" style=\"text-align: right;\">في هذه الأيّام، ونحن ننظر إلى العالم من حولنا، لا يمكننا أن نتهرَّب من القضايا الأخلاقيّة الخطيرة المرتبطة بقطاع التّسلّح. إمكانيّة إجراء عمليّات عسكريّة من خلال أنظمة التّحكم عن بُعد أدّت إلى عدم رؤية الدّمار الذي تسبّبه هذه الأنظمة، وإلى عدم الإحساس بمسؤوليّة استخدامها، فتنظر بمزيد من البرود واللامبالاة إلى مأساة الحرب الهائلة. الأبحاث في التّقنيّات التي تنشأ في القطاع المسمّى ”بأنظمة الأسلحة الفتّاكة العاملة بصورة آليّة“، بما في ذلك استخدام الذّكاء الاصطناعيّ العسكريّ، هو سببٌ خطير يثير القلق على الصّعيد الأخلاقيّ. لا يمكن لأنظمة الأسلحة الآليّة أن تكون هي مسؤولة أخلاقيًّا: الإنسان وحده له القدرة على الحكم الأخلاقيّ واتّخاذ القرار الأخلاقيّ، والإنسان أكثر بكثير من مجرّد مجموعة معقّدة من الخوارزميّات. ومن ثمّ، لا يمكن حصر هذه القدرة الأخلاقيّة في برمجة آليّة، فهي مهما كانت ”ذكيّة“، تبقى دائمًا آلة. لهذا السّبب، لابدّ من أن نضمن رقابة بشريّة مناسبة، ومنسجمة ولها أهمّيّتها، على أنظمة الأسلحة.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">ولا نقدر أن نتجاهل إمكانيّة وقوع الأسلحة المتطوّرة في الأيدي الخطأ، فتسهّل على سبيل المثال، الهجمات الإرهابيّة أو التّدخّلات التي تهدف إلى زعزعة استقرار أنظمة حكوميّة شرعيّة. باختصار، العالم لا يحتاج إلى تقنيّات جديدة لتطوير آثم للسّوق، ولتجارة الأسلحة، تعزّز جنون الحرب. إن فعلنا ذلك، ليس الذّكاء وحده، بل قلب الإنسان نفسه، يصبح عرضة لأنيصير ”اصطناعيًّا“. يجب ألّا نستخدم أكثر التّطبيقات التّقنيّة تطوّرًا لتسهيل حلّ الصّراعات بالعنف، بل لتمهيد الطّرق إلى السّلام.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">من منظور أكثر إيجابيّة، لو تمّ استخدام الذّكاء الاصطناعيّ لتعزيز التّنمية البشريّة المتكاملة، لأمكنه أن يقدّم ابتكارات مهمّة في الزّراعة والتّعليم والثّقافة، وتحسين في مستوى المعيشة لأمم وشعوب بأكملها، وازدادت الأخوّة الإنسانيّة والصّداقة الاجتماعيّة. في النّهاية، الطّريقة التي بها نستخدمه لنشمل الأخيرين، أيْ الإخوة والأخوات الأكثر ضعفًا واحتياجًا، هي المقياس التي تُظهر إنسانيّتنا.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">النّظرة الإنسانيّة والرّغبة في مستقبل أفضل لعالمنا، يدفعان إلى ضرورة الحوار بين مختلف العلوم والتخصّصات، يهدف إلى التّطوير الأخلاقيّ للخوارزميّات - أخلاقيّات الخوارزميّات – فيه توجّه القِيَم مسارات التّقنيّات الجديدة <a class=\"cleaner\" href=\"#_ftn12\" name=\"_ftnref12\">[12]</a> <sup><sup>[2]</sup></sup>. يجب أن تُؤخذ القضايا الأخلاقيّة بعين الاعتبار منذ بداية البحث، وفي مراحل الاختبار أيضًا، والتّصميم والتّصنيع والتّوزيع والتّسويق. هذا هو النّهج الأخلاقيّ للتّصميم، الذي فيه يكون للمؤسّسات التّربويّة وصُنَّاع القرار دور أساسيّ يمارسونه.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><b>7. تحدّيات التّربية</b></p>\n<p dir=\"RTL\" style=\"text-align: right;\">تطوير التّكنولوجيا التي تحترم وتخدم الكرامة الإنسانيّة، له ارتباطات واضحة بالمؤسّسات التّربويّة وعالم الثّقافة. بمضاعفة إمكانيّات الاتّصال، سمحت التّقنيّات الرّقميّة بأن نلتقي بطرقٍ جديدة. مع ذلك، لا زلنا بحاجة لأن نتأمّل باستمرار في نوع العلاقات التي توجّهنا إليها هذه التّقنيّات. الشّباب اليوم ينمون في بيئات ثقافيّة مشبعة بالتّكنولوجيا، وهذا الأمر لا يمكن إلّا أن يثير تساؤلات حول أساليب التّدريس والتّنشئة.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">التّربية على استخدام أشكال الذّكاء الاصطناعيّ يجب أن تهدف، قبل كلّ شيء، إلى تعزيز التّفكير النّقدي. من المهمّ للمستخدمين من جميع الأعمار، وخاصّة الشّباب، أن يطوّروا قدرتهم على التّمييز في استخدام البيانات والمحتويات المجموعة على الشّبكة المعلوماتيّة العالميّة (web) أو التي أنتجتها أنظمة الذّكاء الاصطناعيّ. المدارس والجامعات والجمعيّات العلميّة مدعوّة إلى أن تساعد الطّلاب والمختصّين ليتبنّوا الجوانب الاجتماعيّة والأخلاقيّة لتطوير واستخدام التّكنولوجيا.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">التّنشئة على استخدام أدوات الاتّصال الجديدة يجب أن تأخذ بعين الاعتبار، ليس فقط تشويه المعلومات والأخبار المزيّفة، بل أيضًا العودة المقلقة إلى \"مخاوف قديمة [...] استطاعت أن تختبئ وتتطوّر خلف التقنيّات الجديدة\" <a class=\"cleaner\" href=\"#_ftn13\" name=\"_ftnref13\">[13]</a> <sup><sup>[3]</sup></sup>. للأسف، نجد أنفسنا مرّة أخرى مضطرّين لأن نواجه ”الميل لإقامة ثقافة الجدران، ورفع الجدران، لمنع اللقاء مع الثّقافات الأخرى، ومع الآخرين“ <a class=\"cleaner\" href=\"#_ftn14\" name=\"_ftnref14\">[14]</a> <sup><sup>[4]</sup></sup> وتطوير العيش معًا بسلام وأخوّة.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><b>8. تحدّيات تطوير القانون الدّوليّ</b></p>\n<p dir=\"RTL\" style=\"text-align: right;\">انتشار الذّكاء الاصطناعيّ العالميّ يوضح، إلى جانب مسؤوليّة الدّول ذات السّيادة لتنظيم استخدامه داخليًّا، دور المنظّمات الدّولية التي يمكنها أن تلعب دورًا حاسمًا في التّوصّل إلى اتفاقيّات متعدّدة الأطراف وتنسيق تطبيقها وتنفيذها <a class=\"cleaner\" href=\"#_ftn15\" name=\"_ftnref15\">[15]</a>. وفي هذا الصّدد، أحثّ هيئة الأمم للعمل معًا لتبنّي معاهدة دوليّة ملزمة، تنظِّم تطوير واستخدام الذّكاء الاصطناعيّ بأشكاله المتعدّدة. وبطبيعة الحال، ينبغي ألّا يكون هدف التّنظيم منع الممارسات السّيّئة فحسب، بل ينبغي أيضًا أن يكون تشجيع الممارسات الجيّدة، وتحفيز الأساليب الجديدة والإبداعيّة، وتسهيل المبادرات الشّخصيّة والجماعيّة <a class=\"cleaner\" href=\"#_ftn16\" name=\"_ftnref16\">[16]</a>.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">وفي النّهاية، في البحث عن النّماذج التّنظيميّة التي يمكن أن توفّر توجيهًا أخلاقيًّا لمطوّري التّكنولوجيّات الرّقميّة، من الضّروريّ تحديد القِيَم الإنسانيّة التي يجب أن تكون على أساس التزام المجتمعات لصياغة وتبنّي وتطبيق الأطر التّشريعيّة اللازمة. العمل على صياغة مبادئ توجيهيّة أخلاقيّة لإنتاج أشكال الذّكاء الاصطناعيّ لا يمكن أن يتجاهل النّظر في أسئلة أعمق تتعلّق بمعنى الحياة الإنسانيّة، وحماية حقوق الإنسان الأساسيّة، والسّعي لتحقيق العدل والسّلام. عمليّة التّمييز الأخلاقيّ والقانونيّ هذه يمكن أن تكون فرصة ثمينة للتفكير المشترك في الدّور الذي يجب أن تلعبه التّكنولوجيا في حياتنا الفرديّة والجماعيّة، وكيف يمكن أن يؤدّي استخدامها إلى المساهمة في خلق عالم فيه مزيد من المساواة والإنسانيّة. ولهذا السّبب، في المناقشات في تنظيم الذّكاء الاصطناعيّ، يجب الأخذ بعين الاعتبار أصوات جميع الأطراف المعنيّة، بما في ذلك الفقراء والمهمّشين وغيرهم ممّن يظلّون غالبًا لا صوت لهم في عمليّات صنع القرارات العالميّة.</p>\n<p dir=\"RTL\"> </p>\n<p dir=\"RTL\" style=\"text-align: center;\">* * * * *</p>\n<p dir=\"RTL\" style=\"text-align: center;\"> </p>\n<p dir=\"RTL\" style=\"text-align: right;\">أتمنّى أن يشجّعنا هذا التّفكير حتّى يكون التّقدّم في تطوير أشكال الذّكاء الاصطناعيّ خادمًا في نهاية الأمر لقضيّة الأخوّة الإنسانيّة والسّلام. إنّها ليست مسؤوليّة بعض النّاس القليلين، بل مسؤوليّة الأسرة البشريّة بأكملها. السّلام، في الواقع، هو ثمرة العلاقات التي تعترِف بالآخرين وتقبَلهم في كرامتهم غير القابلة للمساومة، وهو ثمرة التّعاون والالتزام في السّعي لتحقيق التّنمية المتكاملة لجميع الأشخاص وجميع الشّعوب.</p>\n<p dir=\"RTL\" style=\"text-align: right;\">صلاتي في بداية السّنة الجديدة هي أنّ التّطوّر السّريع لأشكال الذّكاء الاصطناعيّ لا يزيد من عدم المساواة والمظالم الكبيرَة الموجودَة أصلًا في العالم، بل يساهم في وضع حدّ للحروب والصّراعات، ويخفّف من أشكال الآلام الكثيرة التي تبتلي الأسرة البشريّة. أتمنّى أن يتعاون المؤمنون المسيحيّون، والمؤمنون من مختلف الدّيانات، والرّجال والنّساء ذوو الإرادة الصّالحة، كلّهم منسجمين معًا، ليغتنموا الفرص ويواجهوا التّحدّيات التي تثيرها الثّورة الرّقميّة، وليسلّموا الأجيال القادمة عالمًا فيه مزيد من التّضامن والعدل والسّلام.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"> </p>\n<p dir=\"RTL\" style=\"text-align: right;\">من حاضرة الفاتيكان، يوم 8 كانون الأوّل/ديسمبر من عام 2023.</p>\n<p dir=\"RTL\"> </p>\n<p dir=\"RTL\" style=\"text-align: center;\">***********</p>\n<p dir=\"RTL\" style=\"text-align: center;\">© جميع الحقوق محفوظة – حاضرة الفاتيكان 2023</p>\n<p> </p>\n<hr align=\"left\" size=\"1\" width=\"33%\">\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref1\" name=\"_ftn1\">[1]</a> رقم 33.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref2\" name=\"_ftn2\">[2]</a>  <i>المرجع نفسه</i>، رقم 57.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref3\" name=\"_ftn3\">[3]</a> رسالة عامّة بابويّة، <i>كُنْ مُسَبَّحًا</i> (24 أيار/مايو 2015)، 104.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref4\" name=\"_ftn4\">[4]</a> راجع <i>المرجع نفسه</i>، 114.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref5\" name=\"_ftn5\">[5]</a> <i> لقاء مع المشاركين في لقاء ”Minerva Dialogues“</i> (27 آذار/مارس 2023).</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref6\" name=\"_ftn6\">[6]</a> راجع <i>المرجع نفسه</i>.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref7\" name=\"_ftn7\">[7]</a> راجع <i>رسالة إلى الرّئيس التّنفيذي ”للمنتدى الاقتصادي العالمي“ في دافوس-كلوسترز</i> (12 كانون الثّاني/ يناير 2018).</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref8\" name=\"_ftn8\">[8]</a> راجع رسالة عامّة بابويّة، <i>كُنْ مُسَبَّحًا</i>، 194؛ <i>كلمة للمشاركين في ندوة ”الخير العام في العصر الرّقمي“</i> (27 أيلول/سبتمبر 2019).</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref9\" name=\"_ftn9\">[9]</a> الإرشاد الرّسوليّ، <i>فرح الإنجيل</i> (24 تشرين الثّاني/نوفمبر 2013)، 233.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref10\" name=\"_ftn10\">[10]</a> راجع رسالة عامّة بابويّة، <i>كُنْ مُسَبَّحًا</i>، 54.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref11\" name=\"_ftn11\">[11]</a> راجع <i>كلمة للمشاركين في مؤتمر الأكاديميّة البابويّة للحياة</i> (28 شباط/فبراير 2020).</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref12\" name=\"_ftn12\">[12]</a> راجع <i>المرجع نفسه</i>.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref13\" name=\"_ftn13\">[13]</a> رسالة عامّة بابويّة، <i>كلّنا إخوة - Fratelli tutti</i> (3 تشرين الأوّل/أكتوبر 2020)، 27.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref14\" name=\"_ftn14\">[14]</a> راجع <i>المرجع نفسه</i>.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref15\" name=\"_ftn15\">[15]</a> راجع <i>المرجع نفسه</i>، 170-175.</p>\n<p dir=\"RTL\" style=\"text-align: right;\"><a class=\"cleaner\" href=\"#_ftnref16\" name=\"_ftn16\">[16]</a> راجع رسالة عامّة بابويّة، <i>كُنْ مُسَبَّحًا</i>، 177.</p><div class=\"clearfix\"></div></hr></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>",
            "zh_cn": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p style=\"text-align: center;\"><span class=\"title-1-color\"><b>教宗方济各</b></span></p>\n<p style=\"text-align: center;\"><span class=\"title-1-color\"><b>第 57届世界和平日文告 </b></span></p>\n<p style=\"text-align: center;\"><span class=\"title-1-color\"><b>2024 年 1 月 1 日 </b></span></p>\n<p> </p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b>人工智能与和平 </b></p>\n<p>新年，是上主赐给我们每一个人的恩宠时刻，在这新的一年开始，我愿向全体天主子 民，向不同的民族、国家及政府首长、不同宗教和民间社团的领袖，以及我们这个时代 的所有男士、女士致意，献上我对和平的热切祝愿。 </p>\n<p>1. 科技的进步作为走向和平的途径 圣经里证实天主赐下圣神给人类，使他们有「智能、技能和知识，能做各种工程」（出卅 五 31）。人类的聪明才智是造物主赐予尊严的表现，因祂按自己的肖像和模样创造了我 们（参阅：创一 26），且让我们能有意识并自由地回应祂的爱。科技则以特别的方式， 彰显了人类智慧基本的相关特质──人类创造潜力的杰出成果。 </p>\n<p>梵二大公会议文献《论教会在现代世界》牧职宪章里重申此一真理，宪章提到「人类经 常劳动并动用脑筋，以改善自己的生活。」1 当人类藉助技术，努力使大地成为适合全人 类的住所时，2 他们就履行了天主的计划，同时与祂的旨意合作，使这创造臻于完美， 并促成各民族之间的和平。科学技术的进步，已使人类社会更加有序，并更具有兄弟情 谊般的共融与自由，导致了人类的进步和世界的变革。 </p>\n<p>由于科学与技术上令人瞩目的成就，过去使人类生活饱受煎熬且造成极大痛苦的疾病， 如今得以医治，我们理当为此高兴与感激。科技的进步，使得人类能控制现实的程度前 所未有，于是我们可以有大量的选择，包括那些对我们的生存和家园会造成威胁的选 择。3 </p>\n<p>新的信息科技，特别是在数字领域的惊人进步，给了我们令人兴奋的机会，也带来重大 的风险，对于追求人民之间的正义与和谐产生了严重的影响，因此必须提出许多迫切的 问题：这些新的数字科技会带来那些中、长期的后果？对个人的生活和社会、国际的稳 定及和平，会有什么影响？ </p>\n<p>2. 人工智能的未来：在承诺与风险之间 近数十年来，信息科技和数字技术的进步，已使全球社会及各种动态产生深远的改变。 新的数字工具甚至正在改变传播、公共行政、教育、消费、人与人之间的互动，以及我 们日常生活中无数其他层面的样貌。 </p>\n<p>此外，从遍布因特网的数字足迹中，科技利用各种算法来提取数据，使它们能在我们不 知情的情况下，控制我们的心理和相关习惯，以达到它们的商业和政治目的，因而限制 了我们有意识的选择自由。在承载过量的网络空间中，他们可以经常在使用者察觉不到 的情况下，根据使用者的选择标准来建立数据流。 </p>\n<p>我们必须记住，科学研究和技术创新不是脱离实体的，也不是「中立」4 的，总会受到 文化的影响。作为全体人类的活动，它们所发展的方向反映出在任一特定年龄的个人、 社会和文化价值观之下所作的选择。人类以什么方式对待周遭世界，一如所产生的结 果，是有道德的层面，是与人所作的决定密切相关，意即设计实验计划，其结果是针对 一些特定的目标。 </p>\n<p>用在人工智能的形式也是一样。至今为止，在科学和技术领域中，对于人工智能，还没 有一个单一的定义。这个词汇本身如今已成为日常生活的用语，包含各种科学、理论和 技术，其目的是使机器的功能可以复制或模仿人类的认知能力。我们用复数谈论「不同 形式的智能」，更有助于强调这些系统与人类之间不可逾越的差距，不论那智能是多么 令人惊叹和强大，最终也只是「零碎」的，意思是说，也只能模仿或重现人类智能的某 些功能。同样，多种的智能形式也指出以下的事实，那就是这些设备之间存有极大的差 异，应该始终被视为是一种「社会技术系统」，因为任何人工智能设备的影响──不论 其基础技术如何──都不仅取决于技术设计，也取决于其拥有者及开发者的目标和利 益，以及应用的场景。 </p>\n<p>为此，人工智能应该被理解为恍如星系的不同现实。我们不能事先假定它的发展会有益 于人类的未来及人民之间的和平。只有在我们展现自己有能力负责，并尊重「包容、透 明、安全、公平、隐私和可靠」5 等人性基本价值的情况下，才有可能得到这正面的结 果。 </p>\n<p>同样，我们也不能只是假定那些设计算法和数字科技的人，愿意承诺对他们的行为负起 责任且是合乎道德的。我们必须加强，或有必要时去建立机构，来负责审查这一领域中 所出现的道德问题，并保护那些采用人工智能或受其影响者的权益。6 </p>\n<p>因此，科技的巨大扩张，必须随之有适当的培育，使科技对未来的发展负责。只要人类 一旦屈服于自私自利、追求利润和渴望权力等，自由与和平的共存就受到威胁。为了个 人及团体的整体发展，我们有责任拓宽视野，把科学技术研究导向追求和平及共同利益 层面。7 </p>\n<p>每个人与生俱来的尊严，以及把我们凝聚成一个人类大家庭的兄弟情谊，必须成为新技 术发展的根基，并在这些技术被应用之前，作为无庸置疑的评估标准，这样，数字的进 步才能与正义并行，且有助于和平大业。技术发展若不能提升全人类的生活质量，反而 加重不平等及冲突，则永远不能视之为真正的进步。8 </p>\n<p>人工智能会越来越重要。它造成的问题既是技术上的，也是人类学、教育、社会和政治 上的。例如，它保证我们免于辛苦的工作，提高制造效率、更便捷的交通运输、更方便 的市场，且大大革新了收集、整理和确认数据的过程。然而，我们必须小心留意如今的 快速转变，并要谨慎加以管控，好使基本人权得以保护，同时强调推动人类整体发展的 制度及遵守法律。人工智能应有助于发展我们最佳的潜力和最崇高的志向，而不是与之 相抗衡。 </p>\n<p>3. 未来的技术：能自行学习的机器 人工智能有多种形式，而基于「机器学习」（machine learning）所发展的人工智能，虽 然还在开创阶段，但已经给社会的结构带来可观的改变，对文化、社会行为及建立和平 等也产生了深远的影响。 </p>\n<p>像这种机器学习或「深度学习」（deep learning）的发展，引发了超越技术和工程领域的 问题，事关深刻了解生命的意义、知识的建构及心灵获得真理的能力。 </p>\n<p>例如，某些仪器虽有能力产生句法和语意一致的文本，但不能保证它的可靠性。据说它 们是在「幻想」，也就是说，会创造出一些乍看之下似乎可信，其实是毫无根据或有不 实偏见的陈述。当人工智能用于传播假新闻，引起人们对媒体的日渐不信任，就会带来 严重的问题。隐私、数据所有权及知识产权等，也是此一技术会引起风险的领域。我们 还可以加上这些技术的滥用所带来的其他负面后果，诸如：歧视、干预选举、对社会的 监控增加、滥用因特网排斥他人，以及与社会越来越脱节的个人主义等问题，日益严 重。这种种因素都会助长冲突，阻碍和平。 </p>\n<p>4. 在技术官僚范例中对限度的意识 我们的世界太广大、变化多端且复杂，永远无法充分了解和完整分类，即使借助最先进 的算法，人类的思想也永远无法将世界里丰富的东西一一探讨。这样的算法无法保证对 未来的预测，只能提供统计上的近似值。不是所有事都能预测，也不是一切都能计算； 「现实终究大于思想」，9 不论我们的计算能力有多惊人，总是会有一些无法计量的空 间，让我们对任何量化的尝试，力有未逮。 </p>\n<p>此外，人工智能所分析的庞大数据，本身不能保证客观公正。用算法推断信息时，总是 存在着失真的风险，复制了原来环境中的不公正与偏见。算法越快速、越复杂，就越难 了解为何会产生某一特定的结果。 </p>\n<p>「智能」机器会以越来越高的效率，来执行指派给它们的任务，但它们操作的目的和意 义，仍然会由人类自己拥有的宇宙价值观来决定或操控。其风险就是，在某些决定背后 的标准，会变得不清晰，对那些决定的责任被隐匿，制造商则能规避他们为小区利益而 行动的义务。在某种意义上，这是技术官僚制度所青睐的，将经济与技术连在一起，并 特别重视效率，而忽视与直接利益无关的任何事物。10 </p>\n<p>这应该促使我们省思在当前技术官僚和效率导向的心态上往往被忽略的一些事，这对个 人及社会发展极为重要，那就是「对限度的意识」。按定义来说，人必有一死。但人意 图借着科技来克服每一种限度，不能抑制地渴望控制一切，我们就可能失去对自己的掌 控；为了追求绝对的自由，我们可能陷入「技术独裁」的漩涡。承认并接纳我们身为受 造物，即承认我们是有限度的，这是我们得到，或更好说是欣然接受「成就」这份恩赐 所不可或缺的条件。在技术官僚的范例脉络中，被普罗米修斯般的心态激发，也就是在 自以为是的意识型态下，不平等的现象可能会急遽成长，知识和财富集中在少数人手 中，使民主社会及和平共存受到严重的危害。11 </p>\n<p>5. 伦理上的急迫问题 未来，申请抵押贷款者的信用、申请工作者的适用性、罪犯再犯的可能性，或是接受政 治庇护或社会福利等，都可由人工智能系统来决定。这些系统的引进，由于缺乏不同层 级的调停，特别容易造成各种形式的偏见及歧视：系统性错误很容易倍增，不但在个别 案例中会产生不公正，而且由于骨牌效应，也会产生真正的社会不平等。 </p>\n<p>有时人工智能的各种形式会受制于事先确定的、与激励和劝阻相关的选项，或透过以信 息设计来操作的系统来规范人的选择，这些似乎都能影响个人的决定。这些形式的掌控 或社会规范，需要非常谨慎地去关注及加以监督，同时也意味着，制造商、部署者和政 府当局都需要负起明确的法律责任。 </p>\n<p>对于自动化过程的依赖，例如：广泛使用监视器，或采用社会信用体系，将个别人士分 类，同样会对社会结构产生深远的恶果，因为它在人民之间造成了阶级之分。这种人工 分类的过程，也会导致权力冲突，因为它不仅关系到虚拟用户，也关系到真实的人民。 基于对人类尊严的基本尊重之要求，我们拒绝将人的独特性视为等同于一组数据。算法 必不可用来决定我们如何了解人权，从而把人类的固有价值，如：同情、仁慈和宽恕置 之一旁， 而且也无法避免一个人有可能用它改变并摆脱自己的过去。 </p>\n<p>在这种情况下，我们也不能不考虑到新科技对工作场所的影响。过去专属于人力劳动领 域的那些工作，如今迅速被人工智能在工业上的应用所取代。在这方面，也存在着少数 人获得极大利益，而多数人却付出贫困代价的风险。尊重劳工的尊严，以及就业对个 人、家庭和社会经济福祉的重要性，应该是国际社会最应优先关注的，因为这些科技形 式已更深入地渗透我们的工作场所中。 </p>\n<p>6. 我们要化刀剑为犁头吗？ 在这些日子，当我们环顾这世界，会看到一个无法逃避的严重道德问题，与军火产业有 关。利用遥控系统指挥军事行动的能力，会使人疏于留意系统所造成的破坏，以及对使 用武器负责的心理负担，以致对战争的巨大悲剧更加冷漠无感。对于正在兴起的所谓 「致命自动武器系统」，包括武器人工智能化的研究，会引起对道德伦理的严重挑战。 自动武器系统绝不可能负起伦理道德的责任，唯有人类有能力作道德判断及合乎伦理的 决定，这是一组复杂的算法远不能及的，毕竟那能力不能简化为将机器程序化，不论那 机器多有智能，终究是一部机器。因此，人类亟需对武器系统进行充分、持续且有意义 的监督。</p>\n<p>我们也不能忽视尖端武器最后落在不当人士手中的可能性，例如：促成恐怖分子的攻击 或颠覆政府的合法体制。总之，这世界不需要有助于商业及武器交易的「新」技术，这 只会导致不公义的发展或疯狂的战争。若这样做，不只是人的智慧，甚至人类心灵本身 也有可能变得更「人工化」。最先进的科技，不应用来助长以暴力解决冲突，而应该为 和平铺路。 </p>\n<p>从更积极的角度来看，如果将人工智能用于促进整体人类的发展，就可以在农业、教育 和文化上带来重要的新发明，改善整个国家和人民的生活水平，并增进人类的手足情谊 及社会的友爱。最后，我们如何以最小弟兄姊妹、易受伤害者以及最需要帮助者为念， 来使用人工智能，才是衡量人性的真正标准。 </p>\n<p>一个真正人性化的观点，以及对我们世界有更美好未来的渴望，无疑表示我们需要进行 跨领域的交谈，以实现算法合乎伦理──即演算伦理──的发展，其价值观会塑造出新 科技的走向。12在研究工作的起始，即应考虑到伦理问题，并且持续到实验、设计、生 产、分发及营销的各个阶段。这就是设计伦理学的做法，也是教育机构和决策者必须扮 演的重要角色。 </p>\n<p>7. 教育面临的挑战 一个尊重人类尊严并为其服务的技术发展，对我们的教育机构和文化世界有明显的影 响。数字科技大幅增加了传播的机会，使我们能以新的方式彼此相遇。然而，我们仍必 须不断地省思，这科技会引导我们进入何种关系。我们的年轻人成长于科技普及的文化 环境，这也不可避免地对我们教学、教育和培训的方法带来了挑战。 </p>\n<p>使用各种形式的人工智能来从事教育，其首要目标应该是促进批判性思考。各个年龄层 的使用者，特别是青年，对于在网上收集的数据，或由人工智能系统生成的内容，必须 培养一种辨明的能力。学校、大学和科学社团都面临挑战，要帮助学生和专业人士理解 科技的发展和应用上的社会层面及伦理道德。 </p>\n<p>训练人们使用新的传播工具，不但要考虑错误讯息和「假新闻」，也要考虑到下面令人 困扰的情形复发，那就是「隐藏在新技术背后且不断蔓延的由来已久的恐惧……。」 13令 人遗憾的是，我们发现自己要再次面对「建立围墙文化的诱惑，竖立围墙，以阻止我们 与其他文化和与其他人民交流」14 的恶果，以及对和平友好共存发展的影响。 </p>\n<p>8. 发展国际公约所面对的挑战 从人工智能的全球化规模可以清楚地看到，除了主权国家有责任由内部规范它的使用 外，国际组织在达成多边协议及其应用和执行方面，也有决定性的角色要扮演。15 关于 这方面，我力促各国的全球社群能共同合作，以制订一个有约束力的国际协议，来规范 各种形式的人工智能的发展和使用。当然，规范的目的不应该只是防止有害的使用，也 要鼓励做最好的用途，要能激发新颖且有创意的做法，并鼓励个人或团体的创新。16 </p>\n<p>总而言之，在寻求能对数字科技的开发者提供道德指导的规范模型过程中，必须要能指 出人类的价值观，才能驾驭社团制订、采用并执行所需要的规范架构。为产生各种形式 的人工智能的工作而制订的道德指南，不能不思考人类存在意义、保障基本人权和追求 正义与和平等更深刻的议题。伦理和法律上的分辨，可成为一个可贵的机会，来共同省 思科技在个人和公共生活中应扮演的角色，以及要如何应用才能有助于创造一个更公 正、更人道的世界。因此，在谈论人工智能的规范时，所有利害关系人的声音都应纳入 考虑，包括那些在全球决策过程中经常被忽视的贫困者、无权无势者及其他人士。 </p>\n<p style=\"text-align: center;\">* * * * * * * </p>\n<p>我希望上述的反思，能鼓励大家努力，确使人工智能形式的进展最终将成为服务于人类 友谊与和平的大业。那并非少数人的责任，而是整个人类大家庭的责任。因为在人类关 系中，「和平」是承认并接纳他人不可剥夺尊严的果实，也是在追求个人及民族的整体 发展中，合作和承诺的果实。 </p>\n<p>值此新年伊始，我祈愿各式各样人工智能的快速发展，不致加剧普遍存在于当今世界的 不平等和不公义情况，而是帮助这世界终止战争和冲突，减轻人类大家庭所遭受的多种 苦难。愿基督信徒、不同宗教的追随者，以及所有善心人士，在和谐中共同努力，迎接 数字革命带来的各种机会，并面对所带来的挑战，让我们的后代能有一个更精诚团结、 更富于正义与和平的世界。 </p>\n<p>教宗方济各 </p>\n<p>发自梵蒂冈 <br> 2023年 12月 8日 </br></p>\n<p> </p>\n<p>（台湾明爱会 恭译） </p>\n<p> </p>\n<p>  </p>\n<p>________________________________________</p>\n<p>1 《論教會在現代世界》牧職憲章，33。</p>\n<p>2  同上，57。</p>\n<p>3 參閱：《願祢受讚頌》通諭 ，104，（2015 年 5 月 24 日）。 </p>\n<p>4 參閱：同上，114。</p>\n<p>5  在密涅瓦對話（Minerva Dialogues）活動中向與會者致詞（2023 年 3 月 27 日）。</p>\n<p> 6  參閱：同上。 </p>\n<p>7  參閱：〈致達佛斯世界經濟論壇會議主席的訊息〉 (2018 年 1 月 12 日)。 </p>\n<p>8  參閱：《願祢受讚頌》通諭，194，（2015 年 5 月 24 日）；〈向「電子時代的公共利益研討會」與會 者致詞〉，（2019 年 9 月 27 日）。</p>\n<p>9 《福音的喜樂》勸諭，233，（2013 年 11 月 24 日）。  </p>\n<p>10  參閱：《願祢受讚頌》通諭 ，54，（2015 年 5 月 24 日）。 </p>\n<p>11  參閱：向宗座生命科學院大會與會者致詞，（2020 年 2 月 28 日）。 </p>\n<p>12  參閱：同上。 </p>\n<p>13 《眾位弟兄》通諭 ，27，（2020 年 10 月 3 日）。  </p>\n<p>14  同上。 </p>\n<p>15  參閱：同上，170~175。</p>\n<p> 16  參閱：《願祢受讚頌》通諭，177，（2015 年 5 月 24 日）。 </p><div class=\"clearfix\"></div></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>",
            "zh_tw": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b><span class=\"title-1-color\">教宗方濟各</span></b></p>\n<p style=\"text-align: center;\"><b><span class=\"title-1-color\">第 57屆世界和平日文告 </span></b></p>\n<p style=\"text-align: center;\"><b><span class=\"title-1-color\">2024 年 1 月 1 日 </span></b></p>\n<p> </p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b>人工智能與和平</b></p>\n<p>新年，是上主賜給我們每一個人的恩寵時刻，在這新的一年開始，我願向全體天主子 民，向不同的民族、國家及政府首長、不同宗教和民間社團的領袖，以及我們這個時代 的所有男士、女士致意，獻上我對和平的熱切祝願。 </p>\n<p>1. 科技的進步作為走向和平的途徑 聖經裡證實天主賜下聖神給人類，使他們有「智慧、技能和知識，能做各種工程」（出卅 五 31）。人類的聰明才智是造物主賜予尊嚴的表現，因祂按自己的肖像和模樣創造了我 們（參閱：創一 26），且讓我們能有意識並自由地回應祂的愛。科技則以特別的方式， 彰顯了人類智慧基本的相關特質──人類創造潛力的傑出成果。 </p>\n<p>梵二大公會議文獻《論教會在現代世界》牧職憲章裡重申此一真理，憲章提到「人類經 常勞動並動用腦筋，以改善自己的生活。」1 當人類藉助技術，努力使大地成為適合全 人類的住所時，2 他們就履行了天主的計畫，同時與祂的旨意合作，使這創造臻於完 美，並促成各民族之間的和平。科學技術的進步，已使人類社會更加有序，並更具有兄 弟情誼般的共融與自由，導致了人類的進步和世界的變革。 </p>\n<p>由於科學與技術上令人矚目的成就，過去使人類生活飽受煎熬且造成極大痛苦的疾病， 如今得以醫治，我們理當為此高興與感激。科技的進步，使得人類能控制現實的程度前 所未有，於是我們可以有大量的選擇，包括那些對我們的生存和家園會造成威脅的選 擇。3 </p>\n<p>新的資訊科技，特別是在數位領域的驚人進步，給了我們令人興奮的機會，也帶來重大 的風險，對於追求人民之間的正義與和諧產生了嚴重的影響，因此必須提出許多迫切的 問題：這些新的數位科技會帶來那些中、長期的後果？對個人的生活和社會、國際的穩 定及和平，會有什麼影響？ </p>\n<p>2. 人工智能的未來：在承諾與風險之間 近數十年來，資訊科技和數位技術的進步，已使全球社會及各種動態產生深遠的改變。 新的數位工具甚至正在改變傳播、公共行政、教育、消費、人與人之間的互動，以及我 們日常生活中無數其他層面的樣貌。 </p>\n<p>此外，從遍布網際網路的數位足跡中，科技利用各種演算法來提取數據，使它們能在我 們不知情的情況下，控制我們的心理和相關習慣，以達到它們的商業和政治目的，因而 限制了我們有意識的選擇自由。在承載過量的網路空間中，他們可以經常在使用者察覺 不到的情況下，根據使用者的選擇標準來建立數據流。 </p>\n<p>我們必須記住，科學研究和技術創新不是脫離實體的，也不是「中立」4 的，總會受到 文化的影響。作為全體人類的活動，它們所發展的方向反映出在任一特定年齡的個人、 社會和文化價值觀之下所作的選擇。人類以什麼方式對待周遭世界，一如所產生的結 果，是有道德的層面，是與人所作的決定密切相關，意即設計實驗計畫，其結果是針對 一些特定的目標。 </p>\n<p>用在人工智能的形式也是一樣。至今為止，在科學和技術領域中，對於人工智能，還沒 有一個單一的定義。這個詞彙本身如今已成為日常生活的用語，包含各種科學、理論和 技術，其目的是使機器的功能可以複製或模仿人類的認知能力。我們用複數談論「不同 形式的智能」，更有助於強調這些系統與人類之間不可逾越的差距，不論那智能是多麼 令人驚嘆和強大，最終也只是「零碎」的，意思是說，也只能模仿或重現人類智慧的某 些功能。同樣，多種的智能形式也指出以下的事實，那就是這些設備之間存有極大的差 異，應該始終被視為是一種「社會技術系統」，因為任何人工智能設備的影響──不論 其基礎技術如何──都不僅取決於技術設計，也取決於其擁有者及開發者的目標和利 益，以及應用的場景。 </p>\n<p>為此，人工智能應該被理解為恍如星系的不同現實。我們不能事先假定它的發展會有益 於人類的未來及人民之間的和平。只有在我們展現自己有能力負責，並尊重「包容、透 明、安全、公平、隱私和可靠」5 等人性基本價值的情況下，才有可能得到這正面的結 果。 </p>\n<p>同樣，我們也不能只是假定那些設計演算法和數位科技的人，願意承諾對他們的行為負 起責任且是合乎道德的。我們必須加強，或有必要時去建立機構，來負責審查這一領域 中所出現的道德問題，並保護那些採用人工智能或受其影響者的權益。6 </p>\n<p>因此，科技的巨大擴張，必須隨之有適當的培育，使科技對未來的發展負責。只要人類 一旦屈服於自私自利、追求利潤和渴望權力等，自由與和平的共存就受到威脅。為了個 人及團體的整體發展，我們有責任拓寬視野，把科學技術研究導向追求和平及共同利益 層面。7 </p>\n<p>每個人與生俱來的尊嚴，以及把我們凝聚成一個人類大家庭的兄弟情誼，必須成為新技 術發展的根基，並在這些技術被應用之前，作為無庸置疑的評估標準，這樣，數位的進 步才能與正義並行，且有助於和平大業。技術發展若不能提升全人類的生活品質，反而 加重不平等及衝突，則永遠不能視之為真正的進步。8 </p>\n<p>人工智能會越來越重要。它造成的問題既是技術上的，也是人類學、教育、社會和政治 上的。例如，它保證我們免於辛苦的工作，提高製造效率、更便捷的交通運輸、更方便 的市場，且大大革新了收集、整理和確認數據的過程。然而，我們必須小心留意如今的 快速轉變，並要謹慎加以管控，好使基本人權得以保護，同時強調推動人類整體發展的 制度及遵守法律。人工智能應有助於發展我們最佳的潛力和最崇高的志向，而不是與之 相抗衡。 </p>\n<p>3. 未來的技術：能自行學習的機器 人工智能有多種形式，而基於「機器學習」（machine learning）所發展的人工智能，雖 然還在開創階段，但已經給社會的結構帶來可觀的改變，對文化、社會行為及建立和平 等也產生了深遠的影響。 </p>\n<p>像這種機器學習或「深度學習」（deep learning）的發展，引發了超越技術和工程領域的 問題，事關深刻了解生命的意義、知識的建構及心靈獲得真理的能力。 </p>\n<p>例如，某些儀器雖有能力產生句法和語意一致的文本，但不能保證它的可靠性。據說它 們是在「幻想」，也就是說，會創造出一些乍看之下似乎可信，其實是毫無根據或有不 實偏見的陳述。當人工智能用於傳播假新聞，引起人們對媒體的日漸不信任，就會帶來 嚴重的問題。隱私、資料所有權及智慧財產權等，也是此一技術會引起風險的領域。我 們還可以加上這些技術的濫用所帶來的其他負面後果，諸如：歧視、干預選舉、對社會 的監控增加、濫用網際網路排斥他人，以及與社會越來越脫節的個人主義等問題，日益 嚴重。這種種因素都會助長衝突，阻礙和平。 </p>\n<p>4. 在技術官僚範例中對限度的意識 我們的世界太廣大、變化多端且複雜，永遠無法充分了解和完整分類，即使借助最先進 的演算法，人類的思想也永遠無法將世界裡豐富的東西一一探討。這樣的演算法無法保 證對未來的預測，只能提供統計上的近似值。不是所有事都能預測，也不是一切都能計 算；「現實終究大於思想」，9 不論我們的計算能力有多驚人，總是會有一些無法計量的 空間，讓我們對任何量化的嘗試，力有未逮。 </p>\n<p>此外，人工智能所分析的龐大數據，本身不能保證客觀公正。用演算法推斷資訊時，總 是存在著失真的風險，複製了原來環境中的不公正與偏見。演算法越快速、越複雜，就 越難了解為何會產生某一特定的結果。 </p>\n<p>「智能」機器會以越來越高的效率，來執行指派給它們的任務，但它們操作的目的和意 義，仍然會由人類自己擁有的宇宙價值觀來決定或操控。其風險就是，在某些決定背後 的標準，會變得不清晰，對那些決定的責任被隱匿，製造商則能規避他們為社區利益而 行動的義務。在某種意義上，這是技術官僚制度所青睞的，將經濟與技術連在一起，並 特別重視效率，而忽視與直接利益無關的任何事物。10 </p>\n<p>這應該促使我們省思在當前技術官僚和效率導向的心態上往往被忽略的一些事，這對個 人及社會發展極為重要，那就是「對限度的意識」。按定義來說，人必有一死。但人意 圖藉著科技來克服每一種限度，不能抑制地渴望控制一切，我們就可能失去對自己的掌 控；為了追求絕對的自由，我們可能陷入「技術獨裁」的漩渦。承認並接納我們身為受 造物，即承認我們是有限度的，這是我們得到，或更好說是欣然接受「成就」這份恩賜 所不可或缺的條件。在技術官僚的範例脈絡中，被普羅米修斯般的心態激發，也就是在 自以為是的意識型態下，不平等的現象可能會急遽成長，知識和財富集中在少數人手 中，使民主社會及和平共存受到嚴重的危害。11 </p>\n<p>5. 倫理上的急迫問題 未來，申請抵押貸款者的信用、申請工作者的適用性、罪犯再犯的可能性，或是接受政 治庇護或社會福利等，都可由人工智能系統來決定。這些系統的引進，由於缺乏不同層 級的調停，特別容易造成各種形式的偏見及歧視：系統性錯誤很容易倍增，不但在個別 案例中會產生不公正，而且由於骨牌效應，也會產生真正的社會不平等。 </p>\n<p>有時人工智能的各種形式會受制於事先確定的、與激勵和勸阻相關的選項，或透過以資 訊設計來操作的系統來規範人的選擇，這些似乎都能影響個人的決定。這些形式的掌控 或社會規範，需要非常謹慎地去關注及加以監督，同時也意味著，製造商、部署者和政 府當局都需要負起明確的法律責任。 </p>\n<p>對於自動化過程的依賴，例如：廣泛使用監視器，或採用社會信用體系，將個別人士分 類，同樣會對社會結構產生深遠的惡果，因為它在人民之間造成了階級之分。這種人工 分類的過程，也會導致權力衝突，因為它不僅關係到虛擬用戶，也關係到真實的人民。 基於對人類尊嚴的基本尊重之要求，我們拒絕將人的獨特性視為等同於一組數據。演算 法必不可用來決定我們如何了解人權，從而把人類的固有價值，如：同情、仁慈和寬恕 置之一旁， 而且也無法避免一個人有可能用它改變並擺脫自己的過去。 </p>\n<p>在這種情況下，我們也不能不考慮到新科技對工作場所的影響。過去專屬於人力勞動領 域的那些工作，如今迅速被人工智能在工業上的應用所取代。在這方面，也存在著少數 人獲得極大利益，而多數人卻付出貧困代價的風險。尊重勞工的尊嚴，以及就業對個 人、家庭和社會經濟福祉的重要性，應該是國際社會最應優先關注的，因為這些科技形 式已更深入地滲透我們的工作場所中。 </p>\n<p>6. 我們要化刀劍為犁頭嗎？ 在這些日子，當我們環顧這世界，會看到一個無法逃避的嚴重道德問題，與軍火產業有 關。利用遙控系統指揮軍事行動的能力，會使人疏於留意系統所造成的破壞，以及對使 用武器負責的心理負擔，以致對戰爭的巨大悲劇更加冷漠無感。對於正在興起的所謂 「致命自動武器系統」，包括武器人工智能化的研究，會引起對道德倫理的嚴重挑戰。 自動武器系統絕不可能負起倫理道德的責任，唯有人類有能力作道德判斷及合乎倫理的 決定，這是一組複雜的演算法遠不能及的，畢竟那能力不能簡化為將機器程式化，不論 那機器多有智慧，終究是一部機器。因此，人類亟需對武器系統進行充分、持續且有意 義的監督。</p>\n<p>我們也不能忽視尖端武器最後落在不當人士手中的可能性，例如：促成恐怖分子的攻擊 或顛覆政府的合法體制。總之，這世界不需要有助於商業及武器交易的「新」技術，這 只會導致不公義的發展或瘋狂的戰爭。若這樣做，不只是人的智慧，甚至人類心靈本身 也有可能變得更「人工化」。最先進的科技，不應用來助長以暴力解決衝突，而應該為 和平鋪路。 </p>\n<p>從更積極的角度來看，如果將人工智能用於促進整體人類的發展，就可以在農業、教育 和文化上帶來重要的新發明，改善整個國家和人民的生活水準，並增進人類的手足情誼 及社會的友愛。最後，我們如何以最小弟兄姊妹、易受傷害者以及最需要幫助者為念， 來使用人工智能，才是衡量人性的真正標準。 </p>\n<p>一個真正人性化的觀點，以及對我們世界有更美好未來的渴望，無疑表示我們需要進行 跨領域的交談，以實現演算法合乎倫理──即演算倫理──的發展，其價值觀會塑造出 新科技的走向。12在研究工作的起始，即應考慮到倫理問題，並且持續到實驗、設計、 生產、分發及營銷的各個階段。這就是設計倫理學的做法，也是教育機構和決策者必須 扮演的重要角色。 </p>\n<p>7. 教育面臨的挑戰 一個尊重人類尊嚴並為其服務的技術發展，對我們的教育機構和文化世界有明顯的影 響。數位科技大幅增加了傳播的機會，使我們能以新的方式彼此相遇。然而，我們仍必 須不斷地省思，這科技會引導我們進入何種關係。我們的年輕人成長於科技普及的文化 環境，這也不可避免地對我們教學、教育和培訓的方法帶來了挑戰。 </p>\n<p>使用各種形式的人工智能來從事教育，其首要目標應該是促進批判性思考。各個年齡層 的使用者，特別是青年，對於在網上收集的數據，或由人工智能系統生成的內容，必須 培養一種辨明的能力。學校、大學和科學社團都面臨挑戰，要幫助學生和專業人士理解 科技的發展和應用上的社會層面及倫理道德。 </p>\n<p>訓練人們使用新的傳播工具，不但要考慮錯誤訊息和「假新聞」，也要考慮到下面令人 困擾的情形復發，那就是「隱藏在新技術背後且不斷蔓延的由來已久的恐懼……。」13 令人遺憾的是，我們發現自己要再次面對「建立圍牆文化的誘惑，豎立圍牆，以阻止我 們與其他文化和與其他人民交流」14 的惡果，以及對和平友好共存發展的影響。 </p>\n<p>8. 發展國際公約所面對的挑戰 從人工智能的全球化規模可以清楚地看到，除了主權國家有責任由內部規範它的使用 外，國際組織在達成多邊協定及其應用和執行方面，也有決定性的角色要扮演。15 關於 這方面，我力促各國的全球社群能共同合作，以制訂一個有約束力的國際協定，來規範 各種形式的人工智能的發展和使用。當然，規範的目的不應該只是防止有害的使用，也 要鼓勵做最好的用途，要能激發新穎且有創意的做法，並鼓勵個人或團體的創新。16 </p>\n<p>總而言之，在尋求能對數位科技的開發者提供道德指導的規範模型過程中，必須要能指 出人類的價值觀，才能駕馭社團制訂、採用並執行所需要的規範架構。為產生各種形式 的人工智能的工作而制訂的道德指南，不能不思考人類存在意義、保障基本人權和追求 正義與和平等更深刻的議題。倫理和法律上的分辨，可成為一個可貴的機會，來共同省 思科技在個人和公共生活中應扮演的角色，以及要如何應用才能有助於創造一個更公 正、更人道的世界。因此，在談論人工智能的規範時，所有利害關係人的聲音都應納入 考慮，包括那些在全球決策過程中經常被忽視的貧困者、無權無勢者及其他人士。 </p>\n<p style=\"text-align: center;\">* * * * * * * </p>\n<p>我希望上述的反思，能鼓勵大家努力，確使人工智能形式的進展最終將成為服務於人類 友誼與和平的大業。那並非少數人的責任，而是整個人類大家庭的責任。因為在人類關 係中，「和平」是承認並接納他人不可剝奪尊嚴的果實，也是在追求個人及民族的整體 發展中，合作和承諾的果實。 </p>\n<p>值此新年伊始，我祈願各式各樣人工智能的快速發展，不致加劇普遍存在於當今世界的 不平等和不公義情況，而是幫助這世界終止戰爭和衝突，減輕人類大家庭所遭受的多種 苦難。願基督信徒、不同宗教的追隨者，以及所有善心人士，在和諧中共同努力，迎接 數位革命帶來的各種機會，並面對所帶來的挑戰，讓我們的後代能有一個更精誠團結、 更富於正義與和平的世界。 </p>\n<p>教宗方濟各 </p>\n<p>發自梵蒂岡<br> 2023年 12月 8日 </br></p>\n<p> </p>\n<p>（臺灣明愛會 恭譯） </p>\n<p>  </p>\n<p>___________________________________</p>\n<p>1 《論教會在現代世界》牧職憲章，33。</p>\n<p>2 同上，57。</p>\n<p>3 參閱：《願祢受讚頌》通諭 ，104，（2015 年 5 月 24 日）。 </p>\n<p>4 參閱：同上，114。 </p>\n<p>5  在密涅瓦對話（Minerva Dialogues）活動中向與會者致詞（2023 年 3 月 27 日）。</p>\n<p>6  參閱：同上。</p>\n<p>7  參閱：〈致達佛斯世界經濟論壇會議主席的訊息〉 (2018 年 1 月 12 日)。</p>\n<p>8  參閱：《願祢受讚頌》通諭，194，（2015 年 5 月 24 日）；〈向「電子時代的公共利益研討會」與會 者致詞〉，（2019 年 9 月 27 日）。 </p>\n<p>9 《福音的喜樂》勸諭，233，（2013 年 11 月 24 日）。 </p>\n<p>10  參閱：《願祢受讚頌》通諭 ，54，（2015 年 5 月 24 日）。</p>\n<p>11  參閱：向宗座生命科學院大會與會者致詞，（2020 年 2 月 28 日）。 </p>\n<p>12  參閱：同上。</p>\n<p>13 《眾位弟兄》通諭 ，27，（2020 年 10 月 3 日）。 </p>\n<p>14  同上。 </p>\n<p>15  參閱：同上，170~175。</p>\n<p>16  參閱：《願祢受讚頌》通諭，177，（2015 年 5 月 24 日）。 </p>\n<p> </p><div class=\"clearfix\"></div></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>",
            "hr": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p style=\"text-align: center;\"><span class=\"color-text\">PORUKA SVETOGA OCA<br> <b>FRANJE<br/> </b>ZA</br></span><br/> <b><span class=\"title-1-color\">57. SVJETSKI DAN MIRA</span></b></p>\n<p style=\"text-align: center;\"><b><span class=\"color-text\">1. SIJEČNJA 2024.</span></b></p>\n<p> </p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b>Umjetna inteligencija i mir</b></p>\n<p>Na početku nove godine, milosnog vremena koje Gospodin daruje svakome od nas, želim se obratiti narodu Božjem, narodima, čelnicima država i vlada, predstavnicima različitih vjera i civilnog društva, te svim muškarcima i ženama našeg vremena kako bih im uputio najbolje želje za mir.</p>\n<p>1.<i> Napredak znanosti i tehnologije kao put do mira</i></p>\n<p>Sveto pismo svjedoči da je Bog ljudima dao svoga Duha kako bi ih resila »umješnost, sposobnost i razumijevanje u svim poslovima« (<i>Izl</i> 35, 31). Inteligencija je izraz dostojanstva kojim nas je obdario Stvoritelj, koji nas je stvorio na svoju sliku i priliku (usp. <i>Post </i>1, 26) i osposobio nas da na njegovu ljubav odgovorimo slobodom i spoznajom. Znanost i tehnologija na osobit način pokazuju tu fundamentalno relacijsku prirodu ljudske inteligencije: oni su izvanredan plod njezina kreativnog potencijala.</p>\n<p>U Pastoralnoj konstituciji <i>Gaudium et spes</i> Drugi vatikanski koncil potvrdio je tu istinu izjavivši: »Svojim radom i snagom svojega duha čovjek je uvijek nastojao što šire razviti svoj život« [1]. Kad ljudi nastoje »pomoću tehničkih umijeća« Zemlju učiniti »dostojnim prebivalištem cjelokupne ljudske obitelji« [2], oni djeluju po Božjem naumu i surađuju s njegovom voljom da dovrše djelo stvaranja i šire mir među narodima. I napredak znanosti i tehnologije, u mjeri u kojoj pridonosi boljem uređenju ljudskog društva, rastu i razvoju slobode i bratskog zajedništva, vodi, dakle, čovjekovu boljitku i preobrazbi svijeta.</p>\n<p>S pravom se radujemo i zahvalni smo za izvanredna dostignuća znanosti i tehnologije zahvaljujući kojima se doskočilo bezbrojnim zlima koja su mučila ljudski život i uzrokovala veliku patnju. Istodobno, znanstveni i tehnološki napredak, koji omogućuje dosad nezapamćenu kontrolu nad stvarnošću, stavlja ljudima u ruke mnoštvo mogućnosti od kojih neke mogu predstavljati prijetnju čovjekovom opstanku i opasnost za zajednički dom [3].</p>\n<p>Značajni napreci u novim informacijskim tehnologijama, posebno na digitalnom polju, donose, dakle, zadivljujuće mogućnosti i ozbiljne opasnosti, s ozbiljnim implikacijama na težnju za postizanjem pravde i sklada među narodima. Zato je prijeko potrebno postaviti neka hitna pitanja. Koje će, srednjoročno i dugoročno gledano, biti posljedice novih digitalnih tehnologija? I kakav će utjecaj one imati na život pojedinaca i društva, na međunarodnu stabilnost i mir?</p>\n<p>2.<i> Budućnost umjetne inteligencije između obećanja i rizika</i></p>\n<p>Napreci postignuti u informacijskoj tehnologiji i razvoj digitalnih tehnologija proteklih desetljeća već su doveli do dubokih promjena u globalnom društvu i njegovoj dinamici. Novi digitalni alati mijenjaju lice komunikacije, javne uprave, obrazovanja, potrošnje, osobnih interakcija i bezbrojnih drugih vidova svakodnevnog života.</p>\n<p>Nadalje, pomoću tehnologija koje koriste pregršt algoritama moguće je iz digitalnih tragova ostavljenih na internetu izvući podatke koji omogućuju kontrolu razmišljanja i navika ljudi u odnosima, često bez njihovog znanja, u komercijalne ili političke svrhe, čime se ograničava njihovu svjesnu slobodu izbora. U internetskom prostoru prenakrcanom informacijama oni mogu oblikovati tok podataka prema kriterijima odabira koje korisnik ne zamjećuje uvijek.</p>\n<p>Moramo zapamtiti da znanstveno istraživanje i tehnološke inovacije nisu odvojene od stvarnosti i »neutralne« [4], nego su podložne kulturnim utjecajima. Kako je riječ o potpuno ljudskim aktivnostima, smjerovi kojim idu odražavaju izbore uvjetovane osobnim, društvenim i kulturnim vrjednotama svakog doba. Isto vrijedi i za rezultate koje postižu: upravo zato što su plod specifičnog ljudskog pristupa svijetu koji nas okružuje, uvijek imaju etičku dimenziju, usko povezanu s odlukama onih koji provode eksperimente i usmjeravaju proizvodnju prema određenim ciljevima.</p>\n<p>To vrijedi i za oblike umjetne inteligencije. U svijetu znanosti i tehnologije zasad ne postoji jedinstvena definicija za nju. Sam izraz, koji je već ušao u svakodnevnu upotrebu, obuhvaća niz znanjâ, teorijâ i tehnikâ kojima je cilj postići to da strojevi, u svom radu, reproduciraju ili oponašaju kognitivne sposobnosti ljudi. Govoriti u množini o “oblicima inteligencije” može nadasve pomoći da se naglasi nepremostivi jaz koji postoji između tih sustava, ma koliko nevjerojatni i moćni bili, i ljudske osobe: oni su, u konačnici, “fragmentarni”, u smislu da mogu samo oponašati ili reproducirati neke funkcije ljudske inteligencije. Upotrebom množine također se naglašava da te, međusobno jako različite, uređaje treba uvijek promatrati kao “sociotehničke sustave”. Naime, njihov učinak, neovisno o temeljnoj tehnologiji, ne ovisi samo o načinu na koji su izrađeni, nego i o ciljevima i interesima onih koji ih posjeduju i onih koji ih razvijaju, te o situacijama u kojima se koriste.</p>\n<p>Umjetnu inteligenciju stoga treba shvaćati kao zaseban svijet sazdan od različitih stvarnosti pa ne možemo <i>a priori</i> pretpostaviti da će njezin razvoj dati pozitivan doprinos budućnosti čovječanstva i miru među narodima. Takav pozitivan ishod bit će moguć samo ako se pokažemo sposobnima ponašati se odgovorno i poštivati temeljne ljudske vrjednote kao što su »inkluzivnost, transparentnost, sigurnost, pravda, povjerljivost i pouzdanost« [5].</p>\n<p>Nije dovoljno, isto tako, pretpostaviti da će se oni koji razvijaju algoritme i digitalne tehnologije ponašati etično i odgovorno. Potrebno je ojačati ili, ako je potrebno, uspostaviti tijela zadužena za razmatranje novih etičkih pitanja i zaštitu pravâ onih koji koriste neki od oblika umjetne inteligencije ili su izloženi njihovu utjecaju [6].</p>\n<p>Silno veliko širenje tehnologije mora stoga biti praćeno odgovarajućom izgradnjom za preuzimanje odgovornosti za njezin razvoj. Sloboda i miran suživot su ugroženi kad ljudi podlegnu iskušenju egoizma, osobnog interesa, žudnje za profitom i želje za moći. Imamo stoga dužnost proširiti svoj pogled i usmjeriti tehnološka i znanstvena istraživanja prema težnji za postizanjem mira i općeg dobra, u službi cjelovitog razvoja čovjeka i zajednice [7].</p>\n<p>Neotuđivo dostojanstvo svakog ljudskog bića i bratstvo koje nas povezuje kao članove jedne ljudske obitelji moraju biti u temelju razvoja novih tehnologija i služiti kao neosporan kriterij za njihovu procjenu prije nego ih se stavi u upotrebu, kako bi se digitalni napredak ostvarivao u duhu pravde i pridonosio miru. Tehnološki razvoji koji ne vode do poboljšanja kvalitete života cijelog čovječanstva, nego naprotiv pogoršavaju nejednakosti i sukobe, nikako se ne mogu smatrati pravim napretkom [8].</p>\n<p>Umjetna inteligencija postajat će sve važnija. Izazovi koje pred nas stavlja su tehnički, ali i antropološki, didaktički, društveni i politički. Obećava, primjerice, uštedu naporâ, efikasniju proizvodnju, učinkovitiji transport i dinamičnija tržišta kao i revoluciju u prikupljanju, organizaciji i provjeri podataka. Moramo biti svjesni brzih promjena koje se trenutno događaju i njima upravljati na način da se štiti temeljna ljudska prava i poštuje institucije i zakone koji promiču cjelovit ljudski razvoj. Umjetna inteligencija mora biti u službi najboljih ljudskih potencijala i naših najviših ciljeva, a ne u suparništvu s njima.</p>\n<p>3.<i> Tehnologija budućnosti: strojevi koji uče sami</i></p>\n<p>U svojim mnogostrukim oblicima, umjetna inteligencija, utemeljena na tehnikama strojnog učenja (<i>machine learning</i>), premda je još u pionirskoj fazi, već uvodi značajne promjene u strukturu društava i ima dubok utjecaj na kulture, društvena ponašanja i izgradnju mira.</p>\n<p>Razvoji kao što su strojno učenje (<i>machine learning</i>) ili duboko učenje (<i>deep learning</i>) pokreću pitanja koja nadilaze područja tehnologije i inženjerstva i tiču se razumijevanja koje je usko povezano sa smislom ljudskog života, temeljnim kognitivnim procesima i sposobnošću uma da se vine do istine.</p>\n<p>Tako, primjerice, sposobnost nekih uređaja da iznjedre sintaktički i semantički suvisle tekstove nije jamstvo pouzdanosti. Za njih se kaže da mogu “halucinirati”, odnosno generirati tvrdnje koje se na prvi pogled čine uvjerljivima, ali zapravo su neutemeljene ili odaju predrasude. To predstavlja ozbiljan problem kad se umjetna inteligencija koristi u kampanjama dezinformiranja koje šire lažne vijesti i vode do rastućeg nepovjerenja u sredstva komunikacije. Povjerljivost, vlasništvo nad podacima i intelektualno vlasništvo druga su područja u kojima te tehnologije za sobom povlače ozbiljne opasnosti, kojima valja pribrojati druge negativne posljedice njihove zlouporabe, kao što su diskriminacija, uplitanje u izborne procese, nastanak modela društva koje nadzire i kontrolira ljude, digitalna isključenost i jačanje individualizma sve više otrgnutog od kolektiviteta. Svi ti čimbenici prijete da raspiruju sukobe i da budu prepreka miru.</p>\n<p>4.<i> Osjećaj ograničenosti u tehnokratskoj paradigmi</i></p>\n<p>Naš je svijet pregolem, previše raznolik i presložen da bi ga se moglo u potpunosti upoznati i klasificirati. Ljudski um nikada neće moći iscrpiti sve njegovo bogatstvo, pa ni uz pomoć najnaprednijih algoritama. Ovi potonji, naime, ne nude nikakva pouzdana predviđanja za budućnost, već samo statističke aproksimacije. Ne može se sve predvidjeti, ne može se sve izračunati. U konačnici, »stvarnost […] je važnija od ideje« [9] i bez obzira na to koliko naši računalni kapaciteti bili čudesni, uvijek će postojati nedostupan ostatak koji izmiče svim pokušajima mjerenja.</p>\n<p>K tome, velika količina podataka koje analizira umjetna inteligencija sama po sebi nije jamstvo nepristranosti. Kad algoritmi ekstrapoliraju informacije, uvijek se izlažu opasnosti da ih iskrive, replicirajući nepravde i predrasude okruženja iz kojeg potječu. Što su brži i složeniji, to je teže razumjeti zašto su dali određeni rezultat.</p>\n<p>“Inteligentni” strojevi mogu obavljati dodijeljene im zadaće sa sve većom učinkovitošću, ali svrhu i značenje njihovih operacija i dalje će određivati ili omogućavati ljudi, svaki sa svojim svijetom vrijednosti. Tu se javlja opasnost da kriteriji na kojima se temelje određene odluke postanu manje jasni, da se odgovornost za odluke zamagljuje i da proizvođači izbjegavaju svoju obvezu djelovanja za dobrobit zajednice. To, u stanovitom smislu, potiče tehnokratski sustav koji „stvara savez“ između ekonomije i tehnologije i daje povlašteno mjesto kriteriju učinkovitosti, težeći tome da zanemari sve što nije povezano s njegovim neposrednim interesima [10].</p>\n<p>To nas mora potaknuti na razmišljanje o vidu koji je, u današnjem tehnokratskom mentalitetu usmjerenom na učinkovitost, tako često zanemaren, a ipak je ključan za osobni i društveni razvoj, a to je “osjećaj ograničenosti”.</p>\n<p>Kad čovjek, koji je po definiciji smrtan, misli da tehnologijom može nadići svaku ograničenost, u opasnosti je da, opsjednut željom da sve kontrolira, izgubi kontrolu nad samim sobom; da, u potrazi za apsolutnom slobodom, upadne u spiralu tehnološke diktature. Prepoznati i prihvatiti vlastitu ograničenost kao stvorenja neizostavan je uvjet da čovjek postigne puninu ili, bolje rečeno, prihvati puninu kao dar. Međutim, u ideološkom kontekstu tehnokratske paradigme, nadahnute prometejskom pretpostavkom samodostatnosti, nejednakosti bi mogle rasti preko mjere, a znanje i bogatstvo mogli bi se gomilati u rukama nekolicine, što za sobom povlači ozbiljne opasnosti za demokratska društva i miran suživot [11].</p>\n<p>5.<i> Goruća pitanja za etiku</i></p>\n<p>U budućnosti bi sustavi umjetne inteligencije mogli određivati pouzdanost zajmotražitelja, prikladnost osobe za neki posao, vjerojatnost da će neki osuđenik ponoviti zlodjelo ili pravo na dobivanje političkog azila ili socijalne pomoći. Nepostojanje različitih razina posredovanja koje ti sustavi uvode posebno je izloženo određenim oblicima predrasude i diskriminacije: pogreške u sustavu mogu se lako umnožiti i dovesti ne samo do nepravde u pojedinačnim slučajevima, već i, domino efektom, do stvarnih oblika društvene nejednakosti.</p>\n<p>Kadikad se, k tome, čini da oblici umjetne inteligencije mogu utjecati na odluke pojedinaca kroz unaprijed određene opcije povezane s poticajima i razuvjeravanjima (odvraćanjima) odnosno putem sustavâ koji reguliraju osobne izbore temeljene na organizaciji podataka. Ti oblici manipulacije ili društvene kontrole zahtijevaju pažljivu pozornost i nadzor i za sobom povlače jasnu zakonsku odgovornost od strane proizvođačâ, korisnikâ i državnih vlasti.</p>\n<p>Oslanjanje na automatizirane procese koji kategoriziraju pojedince, na primjer sveprisutnom upotrebom sustava nadzora ili uvođenjem sustava društvenog rejtinga, također bi moglo imati nesagledive posljedice na društvo, uspostavljajući neprikladna rangiranja građanâ. A ti umjetni procesi klasifikacije mogli bi također dovesti do sukobâ moći, jer se ne tiču samo virtualnih primatelja, već i stvarnih ljudi. Temeljno poštivanje ljudskog dostojanstva zahtijeva odbacivanje poistovjećivanja jedinstvenosti osobe sa skupom podataka. Ne smije se dopustiti da algoritmi diktiraju način na koji shvaćamo ljudska prava, da se ostavi po strani temeljne vrjednote suosjećanja, milosrđa i oproštenja ili ukloni mogućnost da se pojedinac može promijeniti i ostaviti prošlost iza sebe.</p>\n<p>U tom pogledu naprosto moramo razmišljati o utjecaju novih tehnologija na svijet rada: poslove koji su nekoć bili isključiva domena radne snage brzo preuzimaju industrijske primjene umjetne inteligencije. I u ovom slučaju postoji velika opasnost od stjecanja nerazmjerne koristi nekolicine na račun osiromašivanja mnogih pojedinaca. Poštivanje dostojanstva radnikâ i važnost zapošljavanja za materijalno blagostanje pojedinaca, obitelji i društava, sigurnost poslova i pravedne plaće trebali bi biti visoki prioritet za međunarodnu zajednicu, dok ti oblici tehnologije sve dublje prodiru u svijet rada.</p>\n<p>6.<i> Hoćemo li mačeve prekovati u plugove?</i></p>\n<p>U današnje vrijeme, gledajući svijet koji nas okružuje, nemoguće je izbjeći ozbiljna etička pitanja vezana uz sektor naoružanja. Mogućnost vođenja vojnih operacija korištenjem daljinski upravljanih sustava dovela je do smanjene percepcije razaranja koja za sobom ostavljaju i odgovornosti za njihovo korištenje, pridonoseći još hladnijem i distanciranijem odnosu prema golemoj tragediji rata. Istraživanje tehnologija koje se javljaju na području takozvanih “smrtonosnih autonomnih oružanih sustava”, uključujući korištenje umjetne inteligencije u ratu, ozbiljan je razlog etičke zabrinutosti. Autonomni oružani sustavi nikada neće moći biti moralno odgovorni subjekti: isključivo ljudska sposobnost moralnog prosuđivanja i etičkog odlučivanja više je od složenog skupa algoritama a ta se sposobnost ne može svesti na programiranje stroja koji, ma koliko “inteligentan” bio, uvijek ostaje stroj. Zato jamčenje odgovarajućeg, smislenog i dosljednog ljudskog nadzora nad oružanim sustavima predstavlja imperativ.</p>\n<p>Ne možemo zanemariti ni mogućnost da sofisticirano oružje dospije u pogrešne ruke, omogućavajući, na primjer, terorističke napade ili intervencije sa ciljem destabilizacije legitimnih sustava vlasti. Ukratko, svijetu doista nisu potrebne nove tehnologije koje pridonose nepravednom razvoju tržišta i trgovine oružjem, promičući tako bezumlje rata. Na taj način, ne samo ljudskoj inteligenciji, već i samom čovjekovu srcu, prijeti opasnost da postane sve više “umjetno”. Najnaprednije tehničke aplikacije ne bi se trebale koristiti za olakšavanje nasilnog rješavanja sukobâ, već za utiranje putova miru.</p>\n<p>Gledano s pozitivnijeg stanovišta, kad bi se umjetnu inteligenciju koristilo za promicanje cjelovitog ljudskog razvoja, to bi moglo dovesti do važnih inovacija u poljoprivredi, obrazovanju i kulturi, poboljšanju životnog standarda cijelih nacija i naroda te rastu ljudskog bratstva i društvenog prijateljstva. Na kraju krajeva, način na koji je koristimo da uključimo najmanje, odnosno našu najslabiju i braću i sestre koji su u najvećoj potrebi, mjera je koja pokazuje našu ljudskost.</p>\n<p>Humana perspektiva i želja za boljom budućnošću našeg svijeta dovode do potrebe za interdisciplinarnim dijalogom usmjerenim na etički pristup razvoju algoritama – <i>algoretiku </i>– gdje će vrjednote biti te koje će usmjeravati putove razvoja novih tehnologija [12]. Etička pitanja treba uzimati u obzir od početka istraživanja, kao i u fazama testiranja, razvoja, proizvodnje, distribucije i komercijalizacije. To je pristup etike planiranja u kojem obrazovne ustanove i odgovorni za proces donošenja odluka imaju ključnu ulogu.</p>\n<p>7.<i> Izazovi za obrazovanje</i></p>\n<p>Razvoj tehnologije koja poštuje i služi ljudskom dostojanstvu ima jasne implikacije za obrazovne ustanove i svijet kulture. Digitalne su tehnologije umnožavanjem mogućnostî komunikacije omogućile nam susretati se na nove načine. No, potrebno je neprestano razmišljati o vrsti odnosâ prema kojima nas usmjeravaju. Mladi odrastaju u kulturnim okruženjima prožetima tehnologijom, što neizbježno za sobom povlači pitanja vezana uz metode nastave i obrazovanja.</p>\n<p>Podučavanje korištenju raznih oblika umjetne inteligencije prvenstveno treba imati za cilj promicanje kritičkog mišljenja. Prijeko je potrebno da korisnici svih dobnih skupina, a posebno mladi, razviju sposobnost kritičkog korištenja podataka i sadržaja kojima se pristupa putem interneta ili koje kreiraju sustavi umjetne inteligencije. Škole, sveučilišta i znanstvene zajednice pozvane su pomoći studentima i stručnjacima da ovladaju društvenim i etičkim vidovima razvoja i korištenja tehnologije.</p>\n<p>U odgoju za korištenje novih komunikacijskih sredstava trebalo bi uzeti u obzir ne samo dezinformaciju, <i>fake news</i>, već i uznemirujuće ponovno oživljavanje »iskonskih strahova [koji] su se uspjeli sakriti i ojačati u okrilju novih tehnologija« [13]. Ponovno se, nažalost, suočavamo s »napašću da se gradi kulturu zidova, da se podižu zidovi, zidovi u srcu, zidovi na zemlji, kako bi se spriječio ovaj susret s drugim kulturama, s drugim ljudima« [14] i razvoj mirnog i bratskog suživota.</p>\n<p>8.<i> Izazovi za razvoj međunarodnoga prava</i></p>\n<p>Globalni doseg umjetne inteligencije jasno pokazuje da, osim odgovornosti suverenih država da reguliraju njezinu uporabu unutar svojih granica, međunarodne organizacije mogu igrati ključnu ulogu u sklapanju multilateralnih sporazuma te u koordinaciji njihove primjene i provedbe [15]. U vezi s tim, pozivam međunarodnu zajednicu na zajednički rad u cilju usvajanja obvezujućeg međunarodnog ugovora kojim će se regulirati razvoj i korištenje umjetne inteligencije u njezinim različitim oblicima. Ta bi regulacije, naravno, trebala imati za cilj ne samo sprječavanje štetnih praksi, već i poticanje dobrih praksi, poticanjem novih i kreativnih pristupa i olakšavanjem pojedinačnih i grupnih inicijativa [16].</p>\n<p>U konačnici, u potrazi za normativnim propisima koji mogu pružiti etičke smjernice onima koji rade na razvijanju digitalnih tehnologija, bitno je prepoznati i utvrditi ljudske vrijednosti na kojima bi se trebali temeljiti napori društava oko formuliranja, usvajanja i primijene potrebnih pravnih okvira. U radu na izradi etičkih smjernica za proizvodnju oblikâ umjetne inteligencije ne može se zanemariti dublja pitanja o smislu ljudskog postojanja, zaštiti temeljnih ljudskih prava i težnji za postizanjem pravde i mira. Taj proces etičkog i pravnog razlučivanja može se pokazati dragocjenom prigodom za zajedničko promišljanje o ulozi koju bi tehnologija trebala imati u našim životima kao pojedinaca i zajednice kao i o tome kako njezino korištenje može pridonijeti stvaranju pravednijeg i humanijeg svijeta. Zato se u raspravama o regulaciji umjetne inteligencije treba uzeti u obzir glasove svih zainteresiranih strana, uključujući siromašne, marginalizirane i druge koji su u globalnim procesima donošenja odluka često bez glasa.</p>\n<p style=\"text-align: center;\">* * * * *</p>\n<p>Nadam se da će nas ova razmišljanja potaknuti da se pobrinemo da napredak u razvoju oblika umjetne inteligencije u konačnici služi cilju ljudskog bratstva i mira. To nije odgovornost nekolicine, već čitave ljudske obitelji. Mir je, naime, plod odnosâ koji drugog prepoznaju i prihvaćaju u njegovu neotuđivom dostojanstvu kao i suradnje i predanog zalaganja u potrazi za cjelovitim razvojem svih ljudi i svih naroda.</p>\n<p>Moja molitva na početku nove godine jest ova: da brzi razvoj oblika umjetne inteligencije ne poveća nejednakosti i nepravde kojih je već ionako premnogo u svijetu, nego da pomogne u okončanju ratova i sukoba i ublažavanju mnogih oblika patnji koji muče ljudsku obitelj. Neka kršćani, vjernici različitih religija i muškarci i žene dobre volje, skladno surađuju kako bi iskoristili prilike i uhvatili se u koštac sa izazovima koje pred nas stavlja digitalna revolucija i predali budućim naraštajima svijet u kojem će biti više solidarnosti, pravde i mira.</p>\n<p><i>Iz Vatikana, 8. prosinca 2023.</i></p>\n<p style=\"text-align: center;\">FRANJO</p>\n<p> </p>\n<p>________________________________</p>\n<p>[1] Br. 33.</p>\n<p>[2] <i>Isto</i>, br. 57.</p>\n<p>[3] Usp. enc. <i>Laudato si’</i> (24. svibnja 2015.), 104.</p>\n<p>[4] Usp. <i>isto</i>, 114.</p>\n<p>[5<i>] Obraćanje sudionicima skupa „Minerva Dijalozi”</i> (<i>Udienza ai partecipanti all’Incontro “Minerva Dialogues”</i>) (27. ožujka 2023.).</p>\n<p>[6] Usp. <i>isto</i>.</p>\n<p>[7] <i>Poruka predsjedavajućem “Svjetskog ekonomskog foruma” u Davos-Klostersu</i> (<i>Messaggio al Presidente Esecutivo del “World Economic Forum” a Davos-Klosters</i>) (12. siječnja 2018.).</p>\n<p>[8] Usp. enc.<i> Laudato si’</i>, 194; <i>Obraćanje sudionicima seminara “Opće dobro u digitalnom dobu” </i>(<i>Discorso ai partecipanti al Seminario “Il bene comune nell’era digitale”</i>) (27. rujna 2019.).</p>\n<p>[9] Apost. pob. <i>Evangelii gaudium</i> (24. studenog 2013.), 233.</p>\n<p>[10] Usp. enciklika <i>Laudato si’</i>, 54.</p>\n<p>[11] Usp. <i>Obraćanje sudionicima plenarne skupštine Papinske akademije za život</i> (<i>Discorso ai partecipanti alla Plenaria della Pontificia Accademia per la Vita</i>) (28. veljače 2020.).</p>\n<p>[12] Usp. <i>isto</i>.</p>\n<p>[13] Enc. <i>Fratelli tutti</i> (3. listopada 2020.), 27.</p>\n<p>[14] Usp. <i>isto</i>.</p>\n<p>[15] Usp. <i>isto</i>, 170-175.</p>\n<p>[16] Usp. enc. <i>Laudato si’</i>, 177.</p>\n<p> </p><div class=\"clearfix\"></div></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>",
            "en": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p style=\"text-align: center;\"><span class=\"color-text\">MESSAGE OF HIS HOLINESS POPE<b><br> FRANCIS<br/> </br></b>FOR THE 57th<br/> </span><b><span class=\"title-1-color\">WORLD DAY OF PEACE</span></b></p>\n<p style=\"text-align: center;\"><span class=\"color-text\">1 JANUARY 2024</span></p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b><i>Artificial Intelligence and Peace</i></b></p>\n<p> </p>\n<p>At the beginning of the New Year, a time of grace which the Lord gives to each one of us, I would like to address God’s People, the various nations, heads of state and government, the leaders of the different religions and civil society, and all the men and women of our time, in order to offer my fervent good wishes for peace.</p>\n<p style=\"text-align: left;\">1. <i>The progress of science and technology as a path to peace</i></p>\n<p>Sacred Scripture attests that God bestowed his Spirit upon human beings so that they might have “skill and understanding and knowledge in every craft” (<i>Ex</i> 35:31). Human intelligence is an expression of the dignity with which we have been endowed by the Creator, who made us in his own image and likeness (cf. <i>Gen</i> 1:26), and enabled us to respond consciously and freely to his love. In a particular way, science and technology manifest this fundamentally relational quality of human intelligence; they are brilliant products of its creative potential.</p>\n<p>In its Pastoral Constitution <i><a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html\">Gaudium et Spes</a></i>, the <a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/index.htm\">Second Vatican Council</a> restated this truth, declaring that “through its labours and its native endowments, humanity has ceaselessly sought to better its life”. <a class=\"cleaner\" href=\"#_ftn1\" name=\"_ftnref1\">[1]</a> When human beings, “with the aid of technology”, endeavour to make “the earth a dwelling worthy of the whole human family”, <a class=\"cleaner\" href=\"#_ftn2\" name=\"_ftnref2\">[2]</a> they carry out God’s plan and cooperate with his will to perfect creation and bring about peace among peoples. Progress in science and technology, insofar as it contributes to greater order in human society and greater fraternal communion and freedom, thus leads to the betterment of humanity and the transformation of the world.</p>\n<p>We rightly rejoice and give thanks for the impressive achievements of science and technology, as a result of which countless ills that formerly plagued human life and caused great suffering have been remedied. At the same time, techno-scientific advances, by making it possible to exercise hitherto unprecedented control over reality, are placing in human hands a vast array of options, including some that may pose a risk to our survival and endanger our common home. <a class=\"cleaner\" href=\"#_ftn3\" name=\"_ftnref3\">[3]</a></p>\n<p>The remarkable advances in new information technologies, particularly in the digital sphere, thus offer exciting opportunities and grave risks, with serious implications for the pursuit of justice and harmony among peoples. Any number of urgent questions need to be asked. What will be the consequences, in the medium and long term, of these new digital technologies? And what impact will they have on individual lives and on societies, on international stability and peace?</p>\n<p style=\"text-align: left;\">2. <i>The future of artificial intelligence: between promise and risk</i></p>\n<p>Progress in information technology and the development of digital technologies in recent decades have already begun to effect profound transformations in global society and its various dynamics. New digital tools are even now changing the face of communications, public administration, education, consumption, personal interactions and countless other aspects of our daily lives.</p>\n<p>Moreover, from the digital footprints spread throughout the Internet, technologies employing a variety of<b> </b>algorithms can extract data that enable them to control mental and relational habits for commercial or political purposes, often without our knowledge, thus limiting our conscious exercise of freedom of choice. In a space like the Web, marked by information overload, they can structure the flow of data according to criteria of selection that are not always perceived by the user.</p>\n<p>We need to remember that scientific research and technological innovations are not disembodied and “neutral”, <a class=\"cleaner\" href=\"#_ftn4\" name=\"_ftnref4\">[4]</a> but subject to cultural influences. As fully human activities, the directions they take reflect choices conditioned by personal, social and cultural values in any given age. The same must be said of the results they produce: precisely as the fruit of specifically human ways of approaching the world around us, the latter always have an ethical dimension, closely linked to decisions made by those who design their experimentation and direct their production towards particular objectives.</p>\n<p>This is also the case with forms of artificial intelligence. To date, there is no single definition of artificial intelligence in the world of science and technology. The term itself, which by now has entered into everyday parlance, embraces a variety of sciences, theories and techniques aimed at making machines reproduce or imitate in their functioning the cognitive abilities of human beings. To speak in the plural of “forms of intelligence” can help to emphasize above all the unbridgeable gap between such systems, however amazing and powerful, and the human person: in the end, they are merely “fragmentary”, in the sense that they can only imitate or reproduce certain functions of human intelligence. The use of the plural likewise brings out the fact that these devices greatly differ among themselves and that they should always be regarded as “socio-technical systems”. For the impact of any artificial intelligence device – regardless of its underlying technology – depends not only on its technical design, but also on the aims and interests of its owners and developers, and on the situations in which it will be employed.</p>\n<p>Artificial intelligence, then, ought to be understood as a galaxy of different realities. We cannot presume a priori that its development will make a beneficial contribution to the future of humanity and to peace among peoples. That positive outcome will only be achieved if we show ourselves capable of acting responsibly and respect such fundamental human values as “inclusion, transparency, security, equity, privacy and reliability”. <a class=\"cleaner\" href=\"#_ftn5\" name=\"_ftnref5\">[5]</a></p>\n<p>Nor is it sufficient simply to presume a commitment on the part of those who design algorithms and digital technologies to act ethically and responsibly. There is a need to strengthen or, if necessary, to establish bodies charged with examining the ethical issues arising in this field and protecting the rights of those who employ forms of artificial intelligence or are affected by them. <a class=\"cleaner\" href=\"#_ftn6\" name=\"_ftnref6\">[6]</a></p>\n<p>The immense expansion of technology thus needs to be accompanied by an appropriate formation in responsibility for its future development. Freedom and peaceful coexistence are threatened whenever human beings yield to the temptation to selfishness, self-interest, the desire for profit and the thirst for power. We thus have a duty to broaden our gaze and to direct techno-scientific research towards the pursuit of peace and the common good, in the service of the integral development of individuals and communities. <a class=\"cleaner\" href=\"#_ftn7\" name=\"_ftnref7\">[7]</a></p>\n<p>The inherent dignity of each human being and the fraternity that binds us together as members of the one human family must undergird the development of new technologies and serve as indisputable criteria for evaluating them before they are employed, so that digital progress can occur with due respect for justice and contribute to the cause of peace. Technological developments that do not lead to an improvement in the quality of life of all humanity, but on the contrary aggravate inequalities and conflicts, can never count as true progress. <a class=\"cleaner\" href=\"#_ftn8\" name=\"_ftnref8\">[8]</a></p>\n<p>Artificial intelligence will become increasingly important. The challenges it poses are technical, but also anthropological, educational, social and political. It promises, for instance, liberation from drudgery, more efficient manufacturing, easier transport and more ready markets, as well as a revolution in processes of accumulating, organizing and confirming data. We need to be aware of the rapid transformations now taking place and to manage them in ways that safeguard fundamental human rights and respect the institutions and laws that promote integral human development. Artificial intelligence ought to serve our best human potential and our highest aspirations, not compete with them.</p>\n<p style=\"text-align: left;\">3. <i>The technology of the future: machines that “learn” by themselves</i></p>\n<p>In its multiple forms, artificial intelligence based on machine learning techniques, while still in its pioneering phases, is already introducing considerable changes to the fabric of societies and exerting a profound influence on cultures, societal behaviours and peacebuilding.</p>\n<p>Developments such as machine learning or deep learning, raise questions that transcend the realms of technology and engineering, and have to do with the deeper understanding of the meaning of human life, the construction of knowledge, and the capacity of the mind to attain truth.</p>\n<p>The ability of certain devices to produce syntactically and semantically coherent texts, for example, is no guarantee of their reliability. They are said to “hallucinate”, that is, to create statements that at first glance appear plausible but are unfounded or betray biases. This poses a serious problem when artificial intelligence is deployed in campaigns of disinformation that spread false news and lead to a growing distrust of the communications media. Privacy, data ownership and intellectual property are other areas where these technologies engender grave risks. To which we can add other negative consequences of the misuse of these technologies, such as discrimination, interference in elections, the rise of a surveillance society, digital exclusion and the exacerbation of an individualism increasingly disconnected from society. All these factors risk fueling conflicts and hindering peace.</p>\n<p style=\"text-align: left;\">4. <i>The sense of limit in the technocratic paradigm</i></p>\n<p>Our world is too vast, varied and complex ever to be fully known and categorized. The human mind can never exhaust its richness, even with the aid of the most advanced algorithms. Such algorithms do not offer guaranteed predictions of the future, but only statistical approximations. Not everything can be predicted, not everything can be calculated; in the end, “realities are greater than ideas”. <a class=\"cleaner\" href=\"#_ftn9\" name=\"_ftnref9\">[9]</a> <sup><sup>[]</sup></sup> No matter how prodigious our calculating power may be, there will always be an inaccessible residue that evades any attempt at quantification.</p>\n<p>In addition, the vast amount of data analyzed by artificial intelligences is in itself no guarantee of impartiality. When algorithms extrapolate information, they always run the risk of distortion, replicating the injustices and prejudices of the environments where they originate. The faster and more complex they become, the more difficult it proves to understand why they produced a particular result.</p>\n<p>“Intelligent” machines may perform the tasks assigned to them with ever greater efficiency, but the purpose and the meaning of their operations will continue to be determined or enabled by human beings possessed of their own universe of values. There is a risk that the criteria behind certain decisions will become less clear, responsibility for those decisions concealed, and producers enabled to evade their obligation to act for the benefit of the community. In some sense, this is favoured by the technocratic system, which allies the economy with technology and privileges the criterion of efficiency, tending to ignore anything unrelated to its immediate interests. <a class=\"cleaner\" href=\"#_ftn10\" name=\"_ftnref10\">[10]</a></p>\n<p>This should lead us to reflect on something frequently overlooked in our current technocratic and efficiency-oriented mentality, as it is decisive for personal and social development: the “sense of limit”. Human beings are, by definition, mortal; by proposing to overcome every limit through technology, in an obsessive desire to control everything, we risk losing control over ourselves; in the quest for an absolute freedom, we risk falling into the spiral of a “technological dictatorship”. Recognizing and accepting our limits as creatures is an indispensable condition for reaching, or better, welcoming fulfilment as a gift. In the ideological context of a technocratic paradigm inspired by a Promethean presumption of self-sufficiency, inequalities could grow out of proportion, knowledge and wealth accumulate in the hands of a few, and grave risks ensue for democratic societies and peaceful coexistence. <a class=\"cleaner\" href=\"#_ftn11\" name=\"_ftnref11\">[11]</a>  </p>\n<p>5.<i> Burning issues for ethics</i></p>\n<p>In the future, the reliability of an applicant for a mortgage, the suitability of an individual for a job, the possibility of recidivism on the part of a convicted person, or the right to receive political asylum or social assistance could be determined by artificial intelligence systems. The lack of different levels of mediation that these systems introduce is particularly exposed to forms of bias and discrimination: systemic errors can easily multiply, producing not only injustices in individual cases but also, due to the domino effect, real forms of social inequality.</p>\n<p>At times too, forms of artificial intelligence seem capable of influencing individuals’ decisions by operating through pre-determined options associated with stimuli and dissuasions, or by operating through a system of regulating people’s choices based on information design. These forms of manipulation or social control require careful attention and oversight, and imply a clear legal responsibility on the part of their producers, their deployers, and government authorities.</p>\n<p>Reliance on automatic processes that categorize individuals, for instance, by the pervasive use of surveillance or the adoption of social credit systems, could likewise have profound repercussions on the social fabric by establishing a ranking among citizens. These artificial processes of categorization could lead also to power conflicts, since they concern not only virtual users but real people. Fundamental respect for human dignity demands that we refuse to allow the uniqueness of the person to be identified with a set of data. Algorithms must not be allowed to determine how we understand human rights, to set aside the essential human values of compassion, mercy and forgiveness, or to eliminate the possibility of an individual changing and leaving his or her past behind.</p>\n<p>Nor can we fail to consider, in this context, the impact of new technologies on the workplace. Jobs that were once the sole domain of human labour are rapidly being taken over by industrial applications of artificial intelligence. Here too, there is the substantial risk of disproportionate benefit for the few at the price of the impoverishment of many. Respect for the dignity of labourers and the importance of employment for the economic well-being of individuals, families, and societies, for job security and just wages, ought to be a high priority for the international community as these forms of technology penetrate more deeply into our workplaces.</p>\n<p>6.<i> Shall we turn swords into ploughshares?</i></p>\n<p>In these days, as we look at the world around us, there can be no escaping serious ethical questions related to the armaments sector.  The ability to conduct military operations through remote control systems has led to a lessened perception of the devastation caused by those weapon systems and the burden of responsibility for their use, resulting in an even more cold and detached approach to the immense tragedy of war. Research on emerging technologies in the area of so-called Lethal Autonomous Weapon Systems, including the weaponization of artificial intelligence, is a cause for grave ethical concern. Autonomous weapon systems can never be morally responsible subjects. The unique human capacity for moral judgment and ethical decision-making is more than a complex collection of algorithms, and that capacity cannot be reduced to programming a machine, which as “intelligent” as it may be, remains a machine. For this reason, it is imperative to ensure adequate, meaningful and consistent human oversight of weapon systems.</p>\n<p>Nor can we ignore the possibility of sophisticated weapons ending up in the wrong hands, facilitating, for instance, terrorist attacks or interventions aimed at destabilizing the institutions of legitimate systems of government. In a word, the world has no need of new technologies that contribute to the unjust development of commerce and the weapons trade and consequently end up promoting the folly of war. By so doing, not only intelligence but the human heart itself would risk becoming ever more “artificial”. The most advanced technological applications should not be employed to facilitate the violent resolution of conflicts, but rather to pave the way for peace.</p>\n<p>On a more positive note, if artificial intelligence were used to promote integral human development, it could introduce important innovations in agriculture, education and culture, an improved level of life for entire nations and peoples, and the growth of human fraternity and social friendship. In the end, the way we use it to include the least of our brothers and sisters, the vulnerable and those most in need, will be the true measure of our humanity.</p>\n<p>An authentically humane outlook and the desire for a better future for our world surely indicates the need for a cross-disciplinary dialogue aimed at an ethical development of algorithms – an algor-ethics – in which values will shape the directions taken by new technologies. <a class=\"cleaner\" href=\"#_ftn12\" name=\"_ftnref12\">[12]</a> Ethical considerations should also be taken into account from the very beginning of research, and continue through the phases of experimentation, design, production, distribution and marketing. This is the approach of ethics by design, and it is one in which educational institutions and decision-makers have an essential role to play.</p>\n<p style=\"text-align: left;\">7. <i>Challenges for education</i></p>\n<p>The development of a technology that respects and serves human dignity has clear ramifications for our educational institutions and the world of culture. By multiplying the possibilities of communication, digital technologies have allowed us to encounter one another in new ways. Yet there remains a need for sustained reflection on the kinds of relationships to which they are steering us. Our young people are growing up in cultural environments pervaded by technology, and this cannot but challenge our methods of teaching, education and training.</p>\n<p>Education in the use of forms of artificial intelligence should aim above all at promoting critical thinking. Users of all ages, but especially the young, need to develop a discerning approach to the use of data and content collected on the web or produced by artificial intelligence systems. Schools,<b></b> universities and scientific societies are challenged to help students and professionals to grasp the social and ethical aspects of the development and uses of technology.</p>\n<p>Training in the use of new means of communication should also take account not only of disinformation, “fake news”, but also the disturbing recrudescence of “certain ancestral fears… that have been able to hide and spread behind new technologies”. <a class=\"cleaner\" href=\"#_ftn13\" name=\"_ftnref13\">[13]</a> Sadly, we once more find ourselves having to combat “the temptation to build a culture of walls, to raise walls… in order to prevent an encounter with other cultures and other peoples”, <a class=\"cleaner\" href=\"#_ftn14\" name=\"_ftnref14\">[14]</a> and the development of a peaceful and fraternal coexistence.</p>\n<p style=\"text-align: left;\">8. <i>Challenges for the development of international<b> </b>law</i></p>\n<p>The global scale of artificial intelligence makes it clear that, alongside the responsibility of sovereign states to regulate its use internally, international organizations can play a decisive role in reaching multilateral agreements and coordinating their application and enforcement. <a class=\"cleaner\" href=\"#_ftn15\" name=\"_ftnref15\">[15]</a> In this regard, I urge the global community of nations to work together in order to adopt a binding international treaty that regulates the development and use of artificial intelligence in its many forms. The goal of regulation, naturally, should not only be the prevention of harmful practices but also the encouragement of best practices, by stimulating new and creative approaches and encouraging individual or group initiatives. <a class=\"cleaner\" href=\"#_ftn16\" name=\"_ftnref16\">[16]</a></p>\n<p>In the quest for normative models that can provide ethical guidance to developers of digital technologies, it is indispensable to identify the human values that should undergird the efforts of societies to formulate, adopt and enforce much-needed regulatory frameworks. The work of drafting ethical guidelines for producing forms of artificial intelligence can hardly prescind from the consideration of deeper issues regarding the meaning of human existence, the protection of fundamental human rights and the pursuit of justice and peace. This process of ethical and juridical discernment can prove a precious opportunity for shared reflection on the role that technology should play in our individual and communal lives, and how its use can contribute to the creation of a more equitable and humane world. For this reason, in debates about the regulation of artificial intelligence, the voices of all stakeholders should be taken into account, including the poor, the powerless and others who often go unheard in global decision-making processes.</p>\n<p style=\"text-align: center;\">* * *</p>\n<p>I hope that the foregoing reflection will encourage efforts to ensure that progress in developing forms of artificial intelligence will ultimately serve the cause of human fraternity and peace. It is not the responsibility of a few but of the entire human family. For peace is the fruit of relationships that recognize and welcome others in their inalienable dignity, and of cooperation and commitment in seeking the integral development of all individuals and peoples.</p>\n<p>It is my prayer at the start of the New Year that the rapid development of forms of artificial intelligence will not increase cases of inequality and injustice all too present in today’s world, but will help put an end to wars and conflicts, and alleviate many forms of suffering that afflict our human family. May Christian believers, followers of various religions and men and women of good will work together in harmony to embrace the opportunities and confront the challenges posed by the digital revolution and thus hand on to future generations a world of greater solidarity, justice and peace.</p>\n<p><i>From the Vatican, 8 December 2023</i></p>\n<p style=\"text-align: center;\">FRANCISCUS</p>\n<hr align=\"left\" size=\"1\" width=\"33%\">\n<p> </p>\n<p><a class=\"cleaner\" href=\"#_ftnref1\" name=\"_ftn1\">[1]</a>  <a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html\">No</a>. 33.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref2\" name=\"_ftn2\">[2]</a>  <a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html\">Ibid</a>., 57.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref3\" name=\"_ftn3\">[3]</a> Cf. Encyclical Letter <i><a href=\"https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#104\">Laudato Si’</a> </i>(24 May 2015), 104.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref4\" name=\"_ftn4\">[4]</a> Cf. <a href=\"https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#114\">ibid</a>., 114.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref5\" name=\"_ftn5\">[5]</a>  <i><a href=\"https://www.vatican.va/content/francesco/en/speeches/2023/march/documents/20230327-minerva-dialogues.html\">Address to Participants in the “Minerva Dialogues”</a></i> (27 March 2023).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref6\" name=\"_ftn6\">[6]</a> Cf. <a href=\"https://www.vatican.va/content/francesco/en/speeches/2023/march/documents/20230327-minerva-dialogues.html\">ibid</a>.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref7\" name=\"_ftn7\">[7]</a> Cf. <i><a href=\"https://www.vatican.va/content/francesco/en/messages/pont-messages/2018/documents/papa-francesco_20180112_messaggio-davos2018.html\">Message to the Executive Chairman of the “World Economic Forum” meeting in Davos</a></i> (12 January 2018).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref8\" name=\"_ftn8\">[8]</a> Cf. Encyclical Letter <i><a href=\"https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#194\">Laudato Si’</a> </i>(24 May 2015), 194; <i><a href=\"https://www.vatican.va/content/francesco/en/speeches/2019/september/documents/papa-francesco_20190927_eradigitale.html\">Address to Participants in the Seminar “The Common Good in the Digital Age”</a></i> (27 September 2019).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref9\" name=\"_ftn9\">[9]</a> Apostolic Exhortation <i><a href=\"https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20131124_evangelii-gaudium.html#Realities_are_more_important_than_ideas\">Evangelii Gaudium</a></i> (24 November 2013), 233.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref10\" name=\"_ftn10\">[10]</a> Cf. Encyclical Letter <i><a href=\"https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#54\">Laudato Si’</a> </i>(24 May 2015), 54.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref11\" name=\"_ftn11\">[11]</a> Cf. <i><a href=\"https://www.vatican.va/content/francesco/en/speeches/2020/february/documents/papa-francesco_20200228_accademia-perlavita.html\">Meeting with Participants in the Plenary Assembly of the Pontifical Academy for Life</a></i> (28 February 2020).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref12\" name=\"_ftn12\">[12]</a> Cf. <a href=\"https://www.vatican.va/content/francesco/en/speeches/2020/february/documents/papa-francesco_20200228_accademia-perlavita.html\">ibid</a>.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref13\" name=\"_ftn13\">[13]</a> Encyclical Letter <i><a href=\"https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#27\">Fratelli Tutti</a> </i>(3 October 2020), 27.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref14\" name=\"_ftn14\">[14]</a>  <a href=\"https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#27\">Ibid</a>.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref15\" name=\"_ftn15\">[15]</a> Cf. <a href=\"https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#170\">ibid</a>, 170-175.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref16\" name=\"_ftn16\">[16]</a> Cf. Encyclical Letter <i><a href=\"https://www.vatican.va/content/francesco/en/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#177\">Laudato Si’</a> </i>(24 May 2015), 177.</p><div class=\"clearfix\"></div></hr></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>",
            "fr": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p style=\"text-align: center;\"><span class=\"color-text\">MESSAGE <br/>\n DE SA SAINTETÉ<br/>\n<b>FRANÇOIS</b><br/>\n POUR LA 57<sup>ème</sup><br/>\n</span><b><span class=\"title-1-color\">JOURNÉE MONDIALE DE LA PAIX</span></b></p>\n<p style=\"text-align: center;\"><span class=\"color-text\">1<sup>er</sup> JANVIER 2024</span></p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b><i>Intelligence artificielle et paix</i></b></p>\n<p>En ce début de la nouvelle année, temps de grâce que le Seigneur accorde à chacun d’entre nous, je voudrais m’adresser au Peuple de Dieu, aux nations, aux chefs d’État et de Gouvernement, aux représentants des différentes religions et de la société civile, ainsi qu’à tous les hommes et femmes de notre temps, pour leur présenter mes meilleurs vœux de paix.</p>\n<p><i>1. Le progrès de la science et de la technologie comme chemin vers la paix</i></p>\n<p>L’Écriture Sainte témoigne que Dieu a donné aux hommes son Esprit pour qu’ils aient « la sagesse, l’intelligence et la connaissance de toutes sortes de travaux » (<i>Ex</i> 35, 31). L’intelligence est l’expression de la dignité que nous a donnée le Créateur qui nous a créés à son image et à sa ressemblance (cf. <i>Gn</i> 1, 26) et nous a permis de répondre à son amour par la liberté et la connaissance. La science et la technologie manifestent de manière particulière cette qualité fondamentalement relationnelle de l’intelligence humaine : elles sont des produits extraordinaires de son potentiel créatif.</p>\n<p>Dans la Constitution pastorale <i><a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_fr.html\">Gaudium et Spes</a></i>, le <a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/index_fr.htm\">Concile Vatican II</a> a réaffirmé cette vérité en déclarant que « par son travail et son ingéniosité, l’homme a toujours cherché à développer sa propre vie ». <a class=\"cleaner\" href=\"#_ftn1\" name=\"_ftnref1\">[1]</a> Lorsque les êtres humains, « avec l’aide de la technologie », s’efforcent de faire de la terre « une demeure digne de toute la famille humaine », <a class=\"cleaner\" href=\"#_ftn2\" name=\"_ftnref2\">[2]</a> ils agissent selon le plan de Dieu et coopèrent à sa volonté de porter à son achèvement la création et de répandre la paix parmi les peuples. De même, le progrès des sciences et des techniques, dans la mesure où il contribue à un meilleur ordonnancement de la société humaine, à l’accroissement de la liberté et de la communion fraternelle, conduit à l’amélioration de l’homme et à la transformation du monde.</p>\n<p>Nous nous réjouissons à juste titre et nous sommes reconnaissants pour les extraordinaires avancées de la science et de la technologie, grâce auxquelles d’innombrables maux qui affligeaient la vie humaine et causaient de grandes souffrances ont été corrigés. En même temps, les progrès techniques et scientifiques, en permettant l’exercice d’un contrôle sans précédent sur la réalité, mettent entre les mains de l’homme un vaste éventail de possibilités, dont certaines peuvent constituer un risque pour la survie de l’humanité et un danger pour la maison commune. <a class=\"cleaner\" href=\"#_ftn3\" name=\"_ftnref3\">[3]</a></p>\n<p>Les remarquables progrès des nouvelles technologies de l’information, en particulier dans la sphère numérique, présentent des opportunités enthousiasmantes et des risques graves, avec de sérieuses implications pour la poursuite de la justice et de l’harmonie entre les peuples. C’est pourquoi il est nécessaire de se poser certaines questions urgentes. Quelles seront les conséquences à moyen et à long terme des nouvelles technologies numériques? Quel sera leur impact sur la vie des individus et de la société, sur la stabilité internationale et sur la paix?</p>\n<p>2.<i> L’avenir de l’intelligence artificielle : entre promesses et risques</i></p>\n<p>Les progrès en informatique et le développement des technologies numériques au cours des dernières décennies ont déjà commencé à provoquer de profondes transformations dans la société dans son ensemble, et dans ses dynamiques. Les nouveaux outils numériques changent le visage des communications, de l’administration publique, de l’enseignement, de la consommation, des interactions personnelles et d’innombrables autres aspects de la vie quotidienne.</p>\n<p>En outre, les technologies employant une multiplicité d’algorithmes peuvent extraire, à partir des traces numériques laissées sur Internet, des données qui permettent de contrôler les habitudes mentales et relationnelles des personnes, souvent à leur insu, à des fins commerciales ou politiques, en limitant l’exercice conscient de leur liberté de choix. En effet, sur un espace comme la toile, caractérisé par une surcharge d’informations, elles peuvent structurer le flux des données selon des critères de sélection qui ne sont pas toujours perçus par l’utilisateur.</p>\n<p>Nous devons rappeler que la recherche scientifique et les innovations technologiques ne sont ni désincarnées de la réalité ni « neutres », <a class=\"cleaner\" href=\"#_ftn4\" name=\"_ftnref4\">[4]</a> mais qu’elles sont soumises à des influences culturelles. En tant qu’activités pleinement humaines, les orientations qu’elles prennent reflètent des choix conditionnés par des valeurs personnelles, sociales et culturelles propres à chaque époque. Il en va de même pour les résultats obtenus : précisément parce qu’ils sont le fruit d’approches spécifiquement humaines du monde qui les entoure, ils ont toujours une dimension éthique, étroitement liée aux décisions de ceux qui conçoivent l’expérimentation et orientent la production vers des objectifs particuliers.</p>\n<p>Il en va de même pour les formes d'intelligence artificielle. Il n’en existe pas à ce jour de définition univoque dans le monde de la science et de la technologie. Le terme lui-même, désormais entré dans le langage courant, englobe une variété de sciences, de théories et de techniques visant à ce que les machines reproduisent ou imitent, dans leur fonctionnement, les capacités cognitives de l'être humain. Parler au pluriel de “formes d'intelligence” permet surtout de souligner le fossé infranchissable qui existe entre ces systèmes, aussi étonnants et puissants soient-ils, et la personne humaine : ils sont en définitive “fragmentaires”, en ce sens qu'ils ne peuvent qu’imiter ou reproduire certaines fonctions de l'intelligence humaine. L’utilisationdu pluriel souligneque ces dispositifs très différents entre eux doivent toujours être considérés comme des “systèmes sociotechniques”. En effet, leur impact, quelle que soit la technologiesous-jacente, dépend non seulement de leur conception, mais aussi des objectifs et des intérêts de ceux qui les possèdent et de ceux qui les développent, ainsi que des situations dans lesquelles ils sont utilisés.</p>\n<p>L'intelligence artificielle doit donc être comprise comme une galaxie de réalités différenteset nous ne pouvons pas supposer a priori que son développement contribuera de manière bénéfique à l'avenir de l'humanité et à la paix entre les peuples. Un tel résultat positif ne sera possible que si nous nous montrons capables d'agir de manière responsable et de respecter les valeurs humaines fondamentales telles que « l’inclusion, la transparence, la sécurité, l’équité, la confidentialité et la fiabilité ». <a class=\"cleaner\" href=\"#_ftn5\" name=\"_ftnref5\">[5]</a></p>\n<p>Il ne suffit pas non plus de supposer que ceux qui conçoivent les algorithmes et les technologies numériques s'engagent à agir de manière éthique et responsable. Des organismes doivent être renforcés ou, si nécessaire, créés pour examiner les questions éthiques émergentes et protéger les droits de ceux qui utilisent les formes d’intelligence artificielle ou sont influencés par elles. <a class=\"cleaner\" href=\"#_ftn6\" name=\"_ftnref6\">[6]</a></p>\n<p>L'immense expansion de la technologie doit donc s'accompagner d'une formation appropriée à la responsabilité dans son développement. La liberté et la coexistence pacifique sont menacées lorsque les êtres humains succombent à la tentation de l'égoïsme, de l'intérêt personnel, de l'appât du gain et de la soif de pouvoir. Nous avons donc le devoir d'élargir notre regard et d'orienter la recherche technico-scientifique vers la paix et le bien commun, pour le service du développement intégral de l'homme et de la communauté. <a class=\"cleaner\" href=\"#_ftn7\" name=\"_ftnref7\">[7]</a></p>\n<p>La dignité intrinsèque de chaque personne et la fraternité qui nous lient en tant que membres de l'unique famille humaine doivent rester à la base du développement des nouvelles technologies et servir de critères indiscutables pour les évaluer avant leur utilisation, afin que le progrès numérique se fasse dans le respect de la justice et contribue à la cause de la paix. Les développements technologiques qui ne conduisent pas à une amélioration de la qualité de vie de l'ensemble de l'humanité, mais qui au contraire exacerbent les inégalités et les conflits, ne pourront jamais être considérés comme un véritable progrès. <a class=\"cleaner\" href=\"#_ftn8\" name=\"_ftnref8\">[8]</a></p>\n<p>L'intelligence artificielle va devenir de plus en plus importante. Les défis qu'elle pose sont techniques, mais aussi anthropologiques, éducatifs, sociaux et politiques. Elle promet, par exemple, des économies de main-d'œuvre, une production plus efficace, des transports plus faciles et des marchés plus dynamiques, ainsi qu'une révolution dans les processus de collecte, d'organisation et de vérification des données. Nous devons être conscients des transformations rapides en cours et les gérer de manière à sauvegarder les droits humains fondamentaux, en respectant les institutions et les lois qui favorisent le développement humain intégral. L'intelligence artificielle doit servir le potentiel humain le meilleur ainsi que nos aspirations les plus élevées, et non les concurrencer.</p>\n<p>3. <i>La technologie du futur : des machines qui apprennent par elles-mêmes</i></p>\n<p>Sous ses diverses formes, l’intelligence artificielle, basée sur des techniques d’apprentissage automatique (<i>machine learning</i>), bien qu’elle en soit encore à son stade initial, introduit déjà des changements significatifs dans le tissu des sociétés, exerçant une influence profonde sur les cultures, les comportements sociaux et la construction de la paix.</p>\n<p>Des développements tels que l’apprentissage automatique ou l’apprentissage en profondeur (<i>deep learning</i>) soulèvent des questions qui dépassent les domaines de la technologie et de l’ingénierie et ont trait à une compréhension étroitement liée au sens de la vie humaine, aux processus fondamentaux de la connaissance et à la capacité de l’esprit à atteindre la vérité.</p>\n<p>La capacité de certains appareils à produire des textes syntaxiquement et sémantiquement cohérents, par exemple, n’est pas une garantie de fiabilité. On dit qu’ils peuvent “halluciner”, c’est-à-dire générer des affirmations qui semblent à première vue plausibles, mais qui sont en fait infondées ou qui trahissent des préjugés. Cela pose un sérieux problème lorsque l’intelligence artificielle est utilisée dans des campagnes de désinformation qui diffusent des nouvelles fausses et entraînent une méfiance croissante à l’égard des moyens de communication. La confidentialité, la propriété des données et la propriété intellectuelle sont d’autres domaines dans lesquels ces technologies présentent des risques graves, auxquels s’ajoutent d’autres conséquences négatives liées à leur mauvaise utilisation, telles que la discrimination, l’ingérence dans les processus électoraux, la mise en place d’une société qui surveille et contrôle les personnes, l’exclusion numérique et l’exacerbation d’un individualisme de plus en plus déconnecté de la collectivité. Tous ces facteurs risquent d’alimenter les conflits et d’entraver la paix.</p>\n<p>4. <i>Le sens de la limite dans le paradigme technocratique</i></p>\n<p>Notre monde est trop vaste, trop diversifié et trop complexe pour être entièrement connu et classifié. L’esprit humain ne pourra jamais en épuiser la richesse, même avec l’aide des algorithmes les plus avancés. Ceux-ci, en effet, ne proposent pas de prévisions garanties de l’avenir, mais seulement des approximations statistiques. Tout ne peut pas être prédit, tout ne peut pas être calculé. En fin de compte, « la réalité est supérieure à l’idée » <a class=\"cleaner\" href=\"#_ftn9\" name=\"_ftnref9\">[9]</a> et, aussi prodigieuse que puisse être notre capacité de calcul, il y aura toujours un résidu inaccessible qui échappera à toute tentative de quantification.</p>\n<p>En outre, la grande quantité de données analysées par les intelligences artificielles n’est pas en soi une garantie d’impartialité. Lorsque les algorithmes extrapolent des informations, ils courent toujours le risque de les déformer, reproduisant les injustices et les préjugés des milieux d’où ils proviennent. Plus ils deviennent rapides et complexes, plus il est difficile de comprendre pourquoi ils ont produit un résultat donné.</p>\n<p>Les machines intelligentes peuvent accomplir les tâches qui leur sont assignées avec de plus en plus d’efficacité, mais le but et le sens de leurs opérations continueront à être déterminés ou autorisés par des êtres humains ayant leur propre univers de valeurs. Le risque est que les critères qui sous-tendent certains choix deviennent moins clairs, que la responsabilité de la prise de décision soit dissimulée et que les producteurs puissent se soustraire à l’obligation d’agir pour le bien de la communauté. D’une certaine manière, cela est favorisé par le système technocratique, qui allie l’économie à la technologie et privilégie le critère de l’efficacité, tendant à ignorer tout ce qui n’est pas lié à ses intérêts immédiats. <a class=\"cleaner\" href=\"#_ftn10\" name=\"_ftnref10\">[10]</a></p>\n<p>Cela doit nous faire réfléchir sur un aspect très souvent négligé dans la mentalité actuelle, technocratique et recherchant l’efficacité, mais décisif pour le développement personnel et social : le “sens de la limite”. En effet, l’être humain, mortel par définition, pensant dépasser toutes les limites grâce à la technique, risque, dans l’obsession de vouloir tout contrôler, de perdre le contrôle de lui-même ; dans la recherche d’une liberté absolue, de tomber dans la spirale d’une dictature technologique. Reconnaître et accepter ses limites de créature est pour l’homme une condition indispensable pour obtenir, ou mieux accueillir, la plénitude comme un don. Au contraire, dans le contexte idéologique d’un paradigme technocratique, marqué par une présomption prométhéenne d’autosuffisance, les inégalités pourraient croître de manière disproportionnée, le savoir et la richesse s’accumuler dans les mains de quelques-uns, avec de graves risques pour les sociétés démocratiques et la coexistence pacifique. <a class=\"cleaner\" href=\"#_ftn11\" name=\"_ftnref11\">[11]</a></p>\n<p>5. <i>Sujets d’actualité en matière d’éthique</i></p>\n<p>À l’avenir, la fiabilité d’un demandeur de prêt bancaire, l’aptitude d’un individu à un emploi, la possibilité de récidive d’une personne condamnée ou bien le droit à recevoir l’asile politique ou l’aide sociale pourraient être déterminés par des systèmes d’intelligence artificielle. L’absence de divers niveaux de médiation, que ces systèmes présentent, expose particulièrement à des formes de préjugés et de discriminations : les erreurs systémiques peuvent facilement se multiplier, produisant non seulement des injustices dans des cas individuels, mais aussi, par effet domino, de véritables formes d’inégalités sociales.</p>\n<p>De plus, les formes d’intelligence artificielle semblent parfois capables d’influencer les décisions des individus par le biais d’options prédéterminées associées à des stimuli et des dissuasions, ou par le biais de systèmes de régulation des choix personnels fondés sur l’organisation des informations. Ces formes de manipulation ou de contrôle social requièrent une attention et une supervision minutieuses et impliquent une responsabilité juridique claire de la part des producteurs, de ceux qui les emploient et des autorités gouvernementales.</p>\n<p>Le recours à des processus automatiques qui catégorisent les individus, par exemple par l’utilisation généralisée de la surveillance ou l’adoption de systèmes de crédit social, pourrait également avoir de profondes répercussions sur le tissu de la société, établissant des classements inappropriés entre les citoyens. Ces processus artificiels de classification pourraient également conduire à des conflits de pouvoir, car ils ne concernent pas seulement des destinataires virtuels, mais des personnes en chair et en os. Le respect fondamental de la dignité humaine suppose de refuser que l’unicité de la personne soit identifiée par un ensemble de données. Il ne faut pas permettre aux algorithmes de déterminer la manière dont nous entendons les droits humains, de mettre de côté les valeurs essentielles de compassion, de miséricorde et de pardon, ou d’éliminer la possibilité qu’un individu change et laisse derrière lui le passé.</p>\n<p>Dans ce contexte, on ne peut s’empêcher de considérer l’impact des nouvelles technologies dans le domaine du travail : des emplois qui étaient autrefois l’apanage exclusif de la main-d’œuvre humaine sont rapidement absorbés par les applications industrielles de l’intelligence artificielle. Là encore, le risque d’un avantage disproportionné pour quelques-uns au détriment de l’appauvrissement du plus grand nombre est important. Le respect de la dignité des travailleurs et l’importance de l’emploi pour le bien-être économique des personnes, des familles et des sociétés, la sécurité de l’emploi et l’équité des salaires devraient être une priorité absolue pour la Communauté internationale, alors que ces formes de technologies pénètrent de plus en plus profondément sur les lieux de travail.</p>\n<p><i>6. Transformerons-nous les épées en socs ?</i></p>\n<p>En regardant le monde qui nous entoure, on ne peut ces jours-ci échapper aux graves questions éthiques liées au secteur de l’armement. La possibilité de mener des opérations militaires à travers des systèmes de contrôle à distance a conduit à une perception plus faible de la dévastation que ceux-ci causent et de la responsabilité de leur utilisation, contribuant à une approche encore plus froide et détachée de l’immense tragédie de la guerre. La recherche sur les technologies émergentes dans le domaine des “systèmes d’armes létales autonomes”, y compris l’utilisation belliqueuse de l’intelligence artificielle, est un grave sujet de préoccupation éthique. Les systèmes d’armes autonomes ne pourront jamais être des sujets moralement responsables : la capacité humaine exclusive de jugement moral et de décision éthique est plus qu’un ensemble complexe d’algorithmes, et cette capacité ne peut être réduite à la programmation d’une machine qui, bien qu’“intelligente”, reste toujours une machine. C’est pourquoi il est impératif de garantir une supervision humaine adéquate, significative et cohérente des systèmes d’armes.</p>\n<p>Nous ne pouvons pas non plus ignorer la possibilité que des armes sophistiquées tombent entre de mauvaises mains, facilitant par exemple des attaques terroristes ou des interventions visant à déstabiliser des institutions gouvernementales légitimes. En somme, le monde n’a pas vraiment besoin que les nouvelles technologies contribuent au développement injuste du marché et du commerce des armes, en promouvant la folie de la guerre. Ce faisant, non seulement l’intelligence, mais le cœur même de l’homme, court le risque de devenir de plus en plus “artificiel”. Les applications techniques les plus avancées ne doivent pas être utilisées pour faciliter la résolution violente des conflits, mais pour paver les voies de la paix.</p>\n<p>Dans une perspective plus positive, si l’intelligence artificielle était utilisée pour promouvoir le développement humain intégral, elle pourrait introduire d’importantes innovations dans l’agriculture, dans l’éducation et dans la culture, une amélioration du niveau de vie de nations et de peuples entiers, la croissance de la fraternité humaine et de l’amitié sociale. En définitive, la façon dont nous l’utilisons pour inclure les derniers, c’est-à-dire les frères et sœurs les plus faibles et les plus nécessiteux, est la mesure révélatrice de notre humanité.</p>\n<p>Un regard humain et le désir d’un avenir meilleur pour notre monde conduisent à la nécessité d’un dialogue interdisciplinaire visant à un développement éthique des algorithmes – l <i>'algor-éthique</i> –, où les valeurs orientent les parcours des nouvelles technologies. <a class=\"cleaner\" href=\"#_ftn12\" name=\"_ftnref12\">[12]</a> Les questions éthiques devraient être prises en compte dès le début de la recherche, ainsi que dans les phases d’expérimentation, de conception, de production, de distribution et de commercialisation. Il s’agit d’une approche de l’éthique de la conception, dans laquelle les institutions éducatives et les décideurs ont un rôle essentiel à jouer.</p>\n<p><i>7. Défis pour l’éducation</i></p>\n<p>Le développement d’une technologie qui respecte et serve la dignité humaine a des implications claires pour les institutions éducatives et pour le monde de la culture. En multipliant les possibilités de communication, les technologies numériques nous ont permis de nous rencontrer de manière nouvelle. Toutefois, une réflexion constante reste nécessaire sur le type de rapports vers lesquels nous nous dirigeons. Les jeunes grandissent dans des environnements culturels imprégnés par la technologie et cela ne peut que remettre en cause les méthodes d’enseignement et de formation.</p>\n<p>L’éducation à l’utilisation des formes d’intelligence artificielle devrait viser avant tout à promouvoir la pensée critique. Il est nécessaire que les utilisateurs de tout âge, mais surtout les jeunes, développent une capacité de discernement dans l’utilisation des données et contenus recueillis sur la toile ou produits par des systèmes d’intelligence artificielle. Les écoles, les universités et les sociétés savantes sont appelées à aider les étudiants et les professionnels à s’approprier les aspects sociaux et éthiques du développement et de l’utilisation de la technologie.</p>\n<p>La formation à l’utilisation des nouveaux outils de communication devrait tenir compte non seulement de la désinformation, des fausses nouvelles, mais aussi de la recrudescence inquiétante de « peurs ancestrales […] qui ont su se cacher et se renforcer derrière les nouvelles technologies ». <a class=\"cleaner\" href=\"#_ftn13\" name=\"_ftnref13\">[13]</a> Malheureusement, une fois de plus, nous devons combattre « la tentation de créer une culture de murs, d’élever des murs empêchant la rencontre avec d’autres cultures, avec d’autres personnes » <a class=\"cleaner\" href=\"#_ftn14\" name=\"_ftnref14\">[14]</a> et le développement d’une coexistence pacifique et fraternelle.</p>\n<p>8. <i>Défis pour le développement du droit international</i></p>\n<p>Compte tenu de la portée mondiale de l’intelligence artificielle, il est évident qu’à côté de la responsabilité des États souverains de réglementer son utilisation interne, les Organisations internationales peuvent jouer un rôle décisif dans la conclusion d’accords multilatéraux et dans la coordination de leur application et de leur mise en œuvre. <a class=\"cleaner\" href=\"#_ftn15\" name=\"_ftnref15\">[15]</a> À cet égard, j’exhorte la Communauté des nations à travailler ensemble afin d’adopter un traité international contraignant qui réglemente le développement et l’utilisation de l’intelligence artificielle sous ses multiples formes. L’objectif de la réglementation, bien sûr, devrait être non seulement la prévention des mauvaises pratiques, mais aussi l’encouragement des bonnes pratiques, en stimulant des approches nouvelles et créatives et en facilitant des initiatives personnelles et collectives. <a class=\"cleaner\" href=\"#_ftn16\" name=\"_ftnref16\">[16]</a></p>\n<p>En fin de compte, dans la recherche de modèles réglementaires qui puissent fournir un guide éthique aux développeurs de technologies numériques, il est indispensable d’identifier les valeurs humaines qui doivent être à la base de l’engagement des sociétés pour formuler, adopter et mettre en œuvre les cadres législatifs nécessaires. Le travail de rédaction de directives éthiques pour la production de formes d’intelligence artificielle ne peut pas faire abstraction de la prise en compte de questions plus profondes concernant le sens de l’existence humaine, la protection des droits humains fondamentaux, la poursuite de la justice et de la paix. Ce processus de discernement éthique et juridique peut s’avérer être une occasion précieuse pour une réflexion partagée sur le rôle que la technologie devrait avoir dans notre vie individuelle et communautaire, et sur la façon dont son utilisation peut contribuer à la création d’un monde plus équitable et plus humain. C’est pourquoi, dans les débats sur la réglementation de l’intelligence artificielle, il faudrait tenir compte de la voix de toutes les parties prenantes, y compris les pauvres, les marginalisés et d’autres qui restent souvent ignorés dans les processus décisionnels mondiaux.</p>\n<p class=\"MsoNormal\" style=\"text-align: center;\">* * * * *</p>\n<p>J’espère que cette réflexion encouragera à faire en sorte que les progrès dans le développement de formes d’intelligence artificielle servent, en dernière analyse, la cause de la fraternité humaine et de la paix. Ce n’est pas la responsabilité d’un petit nombre, mais de toute la famille humaine. La paix, en effet, est le fruit de relations qui reconnaissent et qui accueillent l’autre dans sa dignité inaliénable, ainsi que de la coopération et de l’engagement dans la recherche du développement intégral de toutes les personnes et de tous les peuples.</p>\n<p>Ma prière au début de l’année nouvelle est que le développement rapide de formes d’intelligence artificielle n’augmente pas les trop nombreuses inégalités et injustices déjà présentes dans le monde, mais contribue à mettre fin aux guerres et aux conflits, et à soulager les nombreuses formes de souffrance qui affligent la famille humaine. Puissent les fidèles chrétiens, les croyants de différentes religions et les hommes et les femmes de bonne volonté collaborer en harmonie pour saisir les opportunités et affronter les défis posés par la révolution numérique, et livrer aux générations futures un monde plus solidaire, juste et pacifique.</p>\n<p><i>Du Vatican, le 8 décembre 2023</i></p>\n<p class=\"MsoNormal\" style=\"text-align: center;\">FRANÇOIS</p>\n<p> </p>\n<p> </p>\n<div>\n<br clear=\"all\">\n<hr align=\"left\" size=\"1\" width=\"33%\">\n<p><a class=\"cleaner\" href=\"#_ftnref1\" name=\"_ftn1\">[1]</a> N. 33.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref2\" name=\"_ftn2\">[2]</a> <i>Ibid.</i>, n. 57.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref3\" name=\"_ftn3\">[3]</a> Cf. Lett. enc. <i><a href=\"https://www.vatican.va/content/francesco/fr/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#104.\">Laudato si’</a> </i>(24 mai 2015), n. 104.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref4\" name=\"_ftn4\">[4]</a> <a href=\"https://www.vatican.va/content/francesco/fr/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#114.\"><i>Ibid</i>.</a>, n. 114.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref5\" name=\"_ftn5\">[5]</a> <i><a href=\"https://www.vatican.va/content/francesco/fr/speeches/2023/march/documents/20230327-minerva-dialogues.html\">Audience aux participants à la rencontre “Minerva Dialogues”</a></i> (27 mars 2023).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref6\" name=\"_ftn6\">[6]</a> Cf.  <i><a href=\"https://www.vatican.va/content/francesco/fr/speeches/2023/march/documents/20230327-minerva-dialogues.html\">ibid.</a></i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref7\" name=\"_ftn7\">[7]</a> Cf. <i><a href=\"https://www.vatican.va/content/francesco/fr/messages/pont-messages/2018/documents/papa-francesco_20180112_messaggio-davos2018.html\">Message au Président Exécutif du “Forum économique mondial” à Davos-Klosters</a></i> (12 janvier 2018).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref8\" name=\"_ftn8\">[8]</a> Cf. Lett. enc. <i><a href=\"https://www.vatican.va/content/francesco/fr/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#194.\">Laudato si'</a></i>, n. 194 ; <i><a href=\"https://www.vatican.va/content/francesco/fr/speeches/2019/september/documents/papa-francesco_20190927_eradigitale.html\">Discours aux participants au Séminaire “Le bien commun à l’ère numérique”</a></i>(27 septembre 2019).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref9\" name=\"_ftn9\">[9]</a> Exhort. ap. <i><a href=\"https://www.vatican.va/content/francesco/fr/apost_exhortations/documents/papa-francesco_esortazione-ap_20131124_evangelii-gaudium.html#La_réalité_est_plus_importante_que_l’idée\">Evangelii gaudium</a></i> (24 novembre 2013), n. 233.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref10\" name=\"_ftn10\">[10]</a> Cf. Lett. enc. <i><a href=\"https://www.vatican.va/content/francesco/fr/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#54.\">Laudato si’</a></i>, n. 54.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref11\" name=\"_ftn11\">[11]</a> Cf. <i><a href=\"https://www.vatican.va/content/francesco/fr/speeches/2020/february/documents/papa-francesco_20200228_accademia-perlavita.html\">Discours aux participants à l’Assemblée Plénière de l’Académie Pontificale pour la Vie</a></i> (28 février 2020).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref12\" name=\"_ftn12\">[12]</a> Cf. <i><a href=\"https://www.vatican.va/content/francesco/fr/speeches/2020/february/documents/papa-francesco_20200228_accademia-perlavita.html\">ibid.</a></i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref13\" name=\"_ftn13\">[13]</a> Lett. enc. <i><a href=\"https://www.vatican.va/content/francesco/fr/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#27\">Fratelli tutti</a></i> (3 octobre 2020), n. 27.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref14\" name=\"_ftn14\">[14]</a>  <a href=\"https://www.vatican.va/content/francesco/fr/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#27\"><i>Ibid</i>.</a></p>\n<p><a class=\"cleaner\" href=\"#_ftnref15\" name=\"_ftn15\">[15]</a> Cf. <a href=\"https://www.vatican.va/content/francesco/fr/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#170\"><i>ibid</i>.</a>, nn. 170-175.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref16\" name=\"_ftn16\">[16]</a> Cf. lett. enc. <i><a href=\"https://www.vatican.va/content/francesco/fr/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#177.\">Laudato si’</a></i>, n. 177.</p>\n</hr></br></div><div class=\"clearfix\"></div></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>",
            "de": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p style=\"text-align: center;\"><span class=\"color-text\">BOTSCHAFT<br> SEINER HEILIGKEIT FRANZISKUS</br></span><br/> <b><span class=\"title-1-color\">ZUM 57. WELTFRIEDENSTAG</span></b></p>\n<p style=\"text-align: center;\"><span class=\"color-text\">1. JANUAR 2024</span></p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b><i>Künstliche Intelligenz und Frieden</i></b></p>\n<p>Zu Beginn des neuen Jahres, einer Zeit der Gnade, die der Herr jedem von uns gewährt, möchte ich mich an das Volk Gottes, an die Nationen, an die Staats- und Regierungschefs, an die Vertreter der verschiedenen Religionen und der Zivilgesellschaft sowie an alle Männer und Frauen unserer Zeit wenden, um ihnen meine besten Wünsche für den Frieden zu übermitteln.</p>\n<p>1. <i>Der Fortschritt von Wissenschaft und Technik als Weg zum Frieden</i></p>\n<p>Die Heilige Schrift bezeugt, dass Gott den Menschen seinen Geist gegeben hat, damit sie »mit Weisheit, Klugheit und Kenntnis für jegliche Arbeit« ausgestattet seien (<i>Ex</i> 35,31). Die Intelligenz ist Ausdruck der Würde, die uns der Schöpfer verliehen hat, der uns nach seinem Bild und Gleichnis geschaffen hat (vgl. <i>Gen</i> 1,26) und uns befähigt hat, auf seine Liebe frei und bewusst zu antworten. Wissenschaft und Technik verdeutlichen in besonderer Weise eine solche grundlegend relationale Beschaffenheit der menschlichen Intelligenz: Sie sind außergewöhnliche Ergebnisse ihres schöpferischen Potentials.</p>\n<p>In der Pastoralkonstitution <i><a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_ge.html\">Gaudium et Spes</a></i> hat das Zweite Vatikanische Konzil diese Wahrheit bekräftigt, indem es erklärte: »Durch Arbeit und Geisteskraft hat der Mensch immer versucht, sein Leben reicher zu entfalten« <a class=\"cleaner\" href=\"#_ftn1\" name=\"_ftnref1\">[1]</a>. Wenn die Menschen sich »mit Hilfe der Technik« darum bemühen, dass die Erde »eine würdige Wohnstätte für die gesamte menschliche Familie werde« <a class=\"cleaner\" href=\"#_ftn2\" name=\"_ftnref2\">[2]</a>, dann handeln sie nach dem Plan Gottes und arbeiten mit seinem Willen zusammen, um die Schöpfung zu vollenden und den Frieden unter den Völkern zu verbreiten. Auch der Fortschritt von Wissenschaft und Technik, soweit er zu einer besseren Ordnung der menschlichen Gesellschaft, zu wachsender Freiheit und geschwisterlicher Gemeinschaft beiträgt, führt also zur Besserung des Menschen und zur Umgestaltung der Welt.</p>\n<p>Wir freuen uns zu Recht über die außerordentlichen Errungenschaften von Wissenschaft und Technik und sind dankbar dafür, dass dadurch zahllose Übel, die das menschliche Leben heimsuchten und großes Leid verursachten, beseitigt werden konnten. Gleichzeitig legen die wissenschaftlichen und technischen Fortschritte, die eine noch nie dagewesene Kontrolle über die Wirklichkeit ermöglichen, eine Vielzahl von Möglichkeiten in die Hände der Menschen, von denen einige ein Risiko für das Überleben der Menschen und eine Gefahr für das gemeinsame Haus darstellen können <a class=\"cleaner\" href=\"#_ftn3\" name=\"_ftnref3\">[3]</a>.</p>\n<p>Die bemerkenswerten Fortschritte in den neuen Informationstechnologien, insbesondere im digitalen Bereich, bergen daher erstaunliche Möglichkeiten und ernsthafte Risiken, mit schwerwiegenden Auswirkungen auf das Streben nach Gerechtigkeit und Harmonie zwischen den Völkern. Es müssen daher einige dringende Fragen gestellt werden. Was sind die mittel- und langfristigen Folgen der neuen digitalen Technologien? Und welche Auswirkungen werden sie auf das Leben der Einzelnen und der Gesellschaft, auf die internationale Stabilität und den Frieden haben?</p>\n<p>2. <i>Die Zukunft der künstlichen Intelligenz zwischen Verheißung und Risiko</i></p>\n<p>Die Fortschritte in der Informationstechnologie und die Entwicklung digitaler Technologien in den letzten Jahrzehnten haben bereits zu tiefgreifenden Veränderungen in der globalen Gesellschaft und ihrer Dynamik geführt. Neue digitale Instrumente verändern das Gesicht der Kommunikation, der öffentlichen Verwaltung, der Bildung, des Konsums, des persönlichen Austauschs und unzähliger anderer Aspekte des täglichen Lebens.</p>\n<p>Darüber hinaus können Technologien, die eine Vielzahl von Algorithmen einsetzen, aus den digitalen Spuren, die im Internet hinterlassen werden, Daten extrahieren, die es ermöglichen, die Denk- und Beziehungsgewohnheiten der Menschen, oft ohne ihr Wissen, zu kommerziellen oder politischen Zwecken zu kontrollieren, wodurch die bewusste Ausübung der Entscheidungsfreiheit eingeschränkt wird. In einem Raum wie dem Internet, der durch eine Informationsflut gekennzeichnet ist, können sie nämlich den Datenfluss nach Auswahlkriterien strukturieren, die der Nutzer nicht immer wahrnimmt.</p>\n<p>Wir müssen daran erinnern, dass wissenschaftliche Forschung und technologische Innovationen nicht losgelöst von der Realität und „neutral“ <a class=\"cleaner\" href=\"#_ftn4\" name=\"_ftnref4\">[4]</a>, sondern kulturellen Einflüssen unterworfen sind. Insofern es sich um ganz und gar menschliche Tätigkeiten handelt, spiegeln die Richtungen, die sie einschlagen, Entscheidungen wider, die durch die persönlichen, sozialen und kulturellen Werte jeder Epoche bedingt sind. Dasselbe gilt für die Ergebnisse, die sie erzielen: Gerade weil sie die Frucht spezifisch menschlicher Zugänge zur sie umgebenden Welt sind, haben sie immer eine ethische Dimension, die eng mit den Entscheidungen derer verbunden sind, die Versuche durchführen und die Produktion auf bestimmte Ziele ausrichten.</p>\n<p>Dies gilt auch für die Formen künstlicher Intelligenz. Bis heute gibt es in der Welt der Wissenschaft und Technik keine einheitliche Definition dafür. Der Begriff selbst, der inzwischen in den allgemeinen Sprachgebrauch eingegangen ist, umfasst eine Vielzahl von Wissenschaften, Theorien und Techniken, die darauf abzielen, dass Maschinen in ihrer Funktionsweise die kognitiven Fähigkeiten des Menschen reproduzieren oder imitieren. Die Verwendung des Plurals „Formen der Intelligenz“ kann vor allem dazu beitragen, die unüberbrückbare Kluft zu betonen, die zwischen diesen Systemen, so erstaunlich und leistungsfähig sie auch sein mögen, und dem Menschen besteht: Sie sind letztlich „bruchstückhaft“ in dem Sinne, dass sie nur bestimmte Funktionen der menschlichen Intelligenz imitieren oder reproduzieren können. Die Verwendung des Plurals unterstreicht auch, dass diese untereinander sehr verschiedenen Geräte immer als „soziotechnische Systeme“ betrachtet werden sollten. In der Tat hängt ihre Wirkung – unabhängig von der zugrundeliegenden Technologie – nicht nur davon ab, wie sie konzipiert sind, sondern auch von den Zielen und Interessen derjenigen, die sie besitzen und entwickeln, sowie von den Situationen, in denen sie eingesetzt werden.</p>\n<p>Künstliche Intelligenz muss daher als eine Galaxie verschiedener Wirklichkeiten verstanden werden, und wir können nicht <i>a priori</i> davon ausgehen, dass ihre Entwicklung einen positiven Beitrag zur Zukunft der Menschheit und zum Frieden zwischen den Völkern leisten wird. Ein solches positives Ergebnis wird nur möglich sein, wenn wir uns als dazu fähig erweisen, verantwortungsbewusst zu handeln und grundlegende menschliche Werte wie »Inklusion, Transparenz, Sicherheit, Gerechtigkeit, Vertraulichkeit und Zuverlässigkeit« <a class=\"cleaner\" href=\"#_ftn5\" name=\"_ftnref5\">[5]</a> zu respektieren.</p>\n<p>Es reicht auch nicht aus, bei denjenigen, die Algorithmen und digitale Technologien entwickeln, eine Verpflichtung zu ethischem und verantwortungsvollem Handeln vorauszusetzen. Es müssen Organismen gestärkt oder gegebenenfalls geschaffen werden, die sich mit den neu auftretenden ethischen Fragen befassen und die Rechte derjenigen schützen, die Formen der künstlichen Intelligenz nutzen oder von ihnen beeinflusst werden <a class=\"cleaner\" href=\"#_ftn6\" name=\"_ftnref6\">[6]</a>.</p>\n<p>Die unermessliche Ausbreitung der Technologie muss daher mit einer angemessenen Heranbildung zur Verantwortung für ihre Entwicklung einhergehen. Freiheit und friedliche Koexistenz sind bedroht, wenn der Mensch der Versuchung von Egoismus, Eigennutz, Profitgier und Machtstreben erliegt. Wir haben daher die Pflicht, unseren Blick zu weiten und die technische und wissenschaftliche Forschung auf das Streben nach Frieden und Gemeinwohl auszurichten, im Dienste der ganzheitlichen Entwicklung des Menschen und der Gemeinschaft <a class=\"cleaner\" href=\"#_ftn7\" name=\"_ftnref7\">[7]</a>.</p>\n<p>Die einem jeden Menschen innewohnende Würde und die Geschwisterlichkeit, die uns als Glieder der einen Menschheitsfamilie verbindet, müssen die Grundlage für die Entwicklung neuer Technologien bilden und als unbestreitbare Kriterien für deren Bewertung noch vor ihrem Einsatz dienen, damit der digitale Fortschritt unter Wahrung der Gerechtigkeit stattfinden und zur Sache des Friedens beitragen kann. Technologische Entwicklungen, die nicht zu einer Verbesserung der Lebensqualität der gesamten Menschheit führen, sondern im Gegenteil Ungleichheiten und Konflikte verschärfen, können niemals als echter Fortschritt angesehen werden <a class=\"cleaner\" href=\"#_ftn8\" name=\"_ftnref8\">[8]</a>.</p>\n<p>Künstliche Intelligenz wird zunehmend an Bedeutung gewinnen. Die Herausforderungen, die sie mit sich bringt, sind technischer, aber auch anthropologischer, didaktischer, sozialer und politischer Natur. Sie verspricht zum Beispiel das Ersparen schwerer Arbeit, effizientere Produktion, einfacheren Transport und dynamischere Märkte ebenso wie eine Revolution bei der Datenerfassung, -organisation und -überprüfung. Wir müssen uns der rasanten Veränderungen, die jetzt stattfinden, bewusst sein und sie so steuern, dass die grundlegenden Menschenrechte gewahrt bleiben und die Institutionen und Gesetze, die eine ganzheitliche menschliche Entwicklung fördern, respektiert werden. Künstliche Intelligenz sollte dem besten menschlichen Potenzial und unseren höchsten Zielen dienen, nicht mit ihnen konkurrieren.</p>\n<p><i>3. Die Technologie der Zukunft: Maschinen, die von selbst lernen</i></p>\n<p>Künstliche Intelligenz, die auf maschinellen Lerntechniken basiert, befindet sich zwar noch in der Pionierphase, führt aber bereits in ihren vielfältigen Formen zu bedeutenden Veränderungen im gesellschaftlichen Gefüge und übt einen tiefgreifenden Einfluss auf Kulturen, soziales Verhalten und Friedensstiftung aus.</p>\n<p>Entwicklungen wie maschinelles Lernen oder <i>Deep Learning</i> werfen Fragen auf, die über den Bereich der Technologie und des Ingenieurwesens hinausgehen und mit einem Verständnis zu tun haben, das eng mit dem Sinn des menschlichen Lebens, den grundlegenden Prozessen des Wissens und der Fähigkeit des Geistes, zur Wahrheit zu gelangen, verbunden ist.</p>\n<p>Die Fähigkeit einiger Geräte, syntaktisch und semantisch kohärente Texte zu produzieren, ist zum Beispiel keine Garantie für Zuverlässigkeit. Man sagt ihnen nach, dass sie „halluzinieren“ können, d. h. Aussagen generieren können, die auf den ersten Blick plausibel erscheinen, in Wirklichkeit aber unbegründet sind oder Vorurteile weitertragen. Dies stellt ein ernstes Problem dar, wenn künstliche Intelligenz in Desinformationskampagnen eingesetzt wird, die falsche Nachrichten verbreiten und zu einem wachsenden Misstrauen gegenüber den Medien führen. Vertraulichkeit, Dateneigentum und geistiges Eigentum sind weitere Bereiche, in denen die betreffenden Technologien ernsthafte Risiken bergen, zu denen noch weitere negative Folgen ihres Missbrauchs hinzukommen, wie Diskriminierung, Einmischung in Wahlprozesse, das Aufkommen einer Überwachungsgesellschaft, digitale Ausgrenzung und die Verschärfung eines Individualismus, der sich zunehmend von der Gemeinschaft abkoppelt. All diese Faktoren bergen die Gefahr, Konflikte zu schüren und den Frieden zu behindern.</p>\n<p>4. <i>Das Gespür für Grenzen im technokratischen Paradigma</i></p>\n<p>Unsere Welt ist zu groß, zu vielfältig und zu komplex, um sie vollständig kennen und klassifizieren zu können. Der menschliche Verstand vermag ihren Reichtum niemals auszuschöpfen, auch nicht mit Hilfe der fortschrittlichsten Algorithmen. Diese bieten nämlich keine gesicherten Vorhersagen für die Zukunft, sondern nur statistische Annäherungen. Nicht alles lässt sich vorhersagen, nicht alles lässt sich berechnen; letztlich steht »die Wirklichkeit […] über der Idee« <a class=\"cleaner\" href=\"#_ftn9\" name=\"_ftnref9\">[9]</a>, und wie großartig unsere Rechenkapazität auch sein mag, es wird immer einen unzugänglichen Rest geben, der sich jedem Versuch der Quantifizierung entzieht.</p>\n<p>Außerdem ist die große Menge an Daten, die von künstlichen Intelligenzen analysiert werden, an sich noch keine Garantie für Unparteilichkeit. Wenn Algorithmen Informationen extrapolieren, laufen sie immer Gefahr, diese zu verzerren und die Ungerechtigkeiten und Vorurteile des Umfelds, aus dem sie stammen, zu reproduzieren. Je schneller und komplexer sie werden, desto schwieriger ist es zu verstehen, warum sie ein bestimmtes Ergebnis hervorgebracht haben.</p>\n<p>„Intelligente“ Maschinen mögen die ihnen zugewiesenen Aufgaben mit zunehmender Effizienz erfüllen, aber der Zweck und der Sinn ihrer Operationen werden weiterhin von Menschen, die ihr je persönliches Werteuniversum besitzen, bestimmt oder ermöglicht. Es besteht die Gefahr, dass die Kriterien, die bestimmten Entscheidungen zugrunde liegen, unklarer werden, dass die Verantwortung für Entscheidungen verschleiert wird und dass die Produzenten sich ihrer Verpflichtung entziehen, zum Wohle der Gemeinschaft zu handeln. In gewisser Weise wird dies durch das technokratische System begünstigt, das die Wirtschaft mit der Technologie verbindet und das Kriterium der Effizienz begünstigt, indem es dazu neigt, alles zu ignorieren, was nicht mit seinen unmittelbaren Interessen zu tun hat <a class=\"cleaner\" href=\"#_ftn10\" name=\"_ftnref10\">[10]</a>.</p>\n<p>Dies muss uns dazu veranlassen, über einen Aspekt nachzudenken, der in der heutigen technokratischen und effizienzorientierten Mentalität so oft vernachlässigt wird und dennoch für die persönliche und soziale Entwicklung entscheidend ist: das „Gespür für Grenzen“. Wenn der Mensch, der definitionsgemäß sterblich ist, nämlich meint, mit Hilfe der Technik jede Grenze zu überschreiten, läuft er durch die Besessenheit alles kontrollieren zu wollen Gefahr, die Kontrolle über sich selbst zu verlieren; auf der Suche nach absoluter Freiheit in die Spirale einer technologischen Diktatur zu geraten. Das Anerkennen und Akzeptieren der eigenen geschöpflichen Grenzen ist für den Menschen die unverzichtbare Bedingung, um die Fülle als Gabe zu erlangen, oder besser, anzunehmen. Stattdessen könnten im ideologischen Kontext eines technokratischen Paradigmas, das von der prometheischen Anmaßung der Autarkie beseelt ist, die Ungleichheiten ins Unermessliche wachsen und sich Wissen und Reichtum in den Händen einiger weniger anhäufen, was ernsthafte Risiken für die demokratischen Gesellschaften und das friedliche Zusammenleben mit sich bringt <a class=\"cleaner\" href=\"#_ftn11\" name=\"_ftnref11\">[11]</a>.</p>\n<p>5. <i>Brisante Themen für die Ethik</i></p>\n<p>In Zukunft könnte die Zuverlässigkeit eines Hypothekenbewerbers, die Eignung einer Person für eine Arbeit, die Wahrscheinlichkeit der Rückfälligkeit eines Verurteilten oder das Recht, politisches Asyl oder Sozialhilfe zu erhalten, von Systemen künstlicher Intelligenz bestimmt werden. Das Fehlen unterschiedlicher Vermittlungsebenen, das diese Systeme mit sich bringen, ist für bestimmte Formen von Vorurteilen und Diskriminierung besonders anfällig: Systemfehler können sich leicht vervielfachen und so nicht nur in Einzelfällen zu Ungerechtigkeiten, sondern durch einen Dominoeffekt auch zu echten Formen sozialer Ungleichheit führen.</p>\n<p>Darüber hinaus scheinen Formen künstlicher Intelligenz manchmal in der Lage zu sein, die Entscheidungen der Einzelnen durch vorgegebene Optionen, die mit Anreizen und Abschreckungen verbunden sind, oder durch Systeme zur Lenkung persönlicher Entscheidungen, die auf der Aufbereitung von Informationen beruhen, zu beeinflussen. Diese Formen der Manipulation oder sozialer Kontrolle bedürfen sorgfältiger Aufmerksamkeit und Überwachung und implizieren eine klare rechtliche Verantwortung seitens der Hersteller, der Nutzer und der Regierungsbehörden.</p>\n<p>Sich automatisierten Prozessen anzuvertrauen, die Individuen kategorisieren, zum Beispiel durch den allgegenwärtigen Einsatz von Überwachungssystemen oder die Einführung von Systemen zur Ermittlung sozialer Bonität, könnte auch tiefgreifende Auswirkungen auf das zivilgesellschaftliche Gefüge haben, indem unangemessene Rangordnungen unter den Bürgern aufgestellt werden. Und diese künstlichen Ranking-Prozesse könnten auch zu Machtkonflikten führen, da sie nicht nur virtuelle Adressaten betreffen, sondern Menschen aus Fleisch und Blut. Die grundlegende Achtung der Menschenwürde verlangt, die Gleichsetzung der Einzigartigkeit der Person mit einem Datensatz abzulehnen. Algorithmen darf nicht erlaubt werden, die Art und Weise zu bestimmen, wie wir die Menschenrechte verstehen, die Grundwerte des Mitgefühls, der Barmherzigkeit und der Vergebung beiseite zu schieben oder die Möglichkeit auszuschließen, dass ein Individuum sich ändert und die Vergangenheit hinter sich lässt.</p>\n<p>In diesem Zusammenhang kommen wir nicht umhin, über die Auswirkungen der neuen Technologien auf das Arbeitsleben nachzudenken: Tätigkeiten, die früher ausschließlich der menschlichen Arbeitskraft vorbehalten waren, werden rasch von industriellen Anwendungen der künstlichen Intelligenz übernommen. Auch in diesem Fall besteht das erhebliche Risiko eines unverhältnismäßigen Vorteils für einige wenige zum Preis der Verarmung vieler. Die Achtung der Würde der Arbeitnehmer und die Bedeutung der Beschäftigung für den wirtschaftlichen Wohlstand der Personen, der Familien und der Gesellschaften, die Sicherheit der Arbeitsplätze und faire Gehälter sollten für die internationale Gemeinschaft eine hohe Priorität darstellen, während diese Formen der Technologie immer tiefer in die Arbeitswelt eindringen.</p>\n<p>6.<b><i> </i></b><i>Werden wir Schwerter zu Pflugscharen machen?</i></p>\n<p>Wenn man heutzutage die Welt um uns herum betrachtet, kann man sich den ernsten ethischen Fragen im Zusammenhang mit der Rüstungsindustrie nicht entziehen. Die Möglichkeit, militärische Operationen mittels ferngesteuerter Systeme durchzuführen, hat zu einer verringerten Wahrnehmung der von ihnen verursachten Zerstörungen und der Verantwortung für ihren Einsatz geführt, was zu einer noch kälteren und distanzierteren Haltung gegenüber der gewaltigen Tragik des Krieges beiträgt. Die Forschung im Bereich neuer Technologien für die so genannten „tödlichen autonomen Waffensysteme“, einschließlich des Einsatzes von künstlicher Intelligenz im Krieg, ist ein ernster Grund für ethische Bedenken. Autonome Waffensysteme werden niemals moralisch verantwortliche Subjekte sein können: Die ausschließlich menschliche Fähigkeit zum moralischen Urteil und zur ethischen Entscheidungsfindung ist mehr als ein komplexer Satz von Algorithmen, und diese Fähigkeit kann nicht auf die Programmierung einer Maschine reduziert werden, die, wie „intelligent“ sie auch sein mag, doch immer eine Maschine bleibt. Aus diesem Grund ist es unerlässlich, eine sachgemäße, maßgebliche und kohärente menschliche Kontrolle der Waffensysteme zu garantieren.</p>\n<p>Wir können auch nicht die Möglichkeit vernachlässigen, dass hochentwickelte Waffen in die falschen Hände geraten und zum Beispiel Terroranschläge oder Einsätze zur Destabilisierung rechtmäßiger Regierungsinstitutionen erleichtern. Kurz gesagt, die Welt hat es wirklich nicht nötig, dass die neuen Technologien zu einer unfairen Entwicklung des Waffenmarktes und -handels beitragen und so den Wahnsinn des Krieges fördern. Auf diese Weise läuft nicht nur die Intelligenz des Menschen, sondern auch das Herz selbst Gefahr, immer „künstlicher“ zu werden. Die fortschrittlichsten technischen Anwendungen sind nicht einzusetzen, um gewaltsame Konfliktlösungen zu erleichtern, sondern um die Wege des Friedens zu ebnen.</p>\n<p>In einer positiveren Betrachtungsweise könnte künstliche Intelligenz, wenn sie zur Förderung einer ganzheitlichen menschlichen Entwicklung eingesetzt würde, wichtige Innovationen in der Landwirtschaft, der Bildung und der Kultur, eine Verbesserung des Lebensstandards ganzer Nationen und Völker sowie das Wachstum der menschlichen Geschwisterlichkeit und der sozialen Freundschaft bewirken. Letztlich ist die Art und Weise, wie wir sie nutzen, um die Geringsten einzubeziehen, d.h. unsere schwächsten und bedürftigsten Brüder und Schwestern, der Maßstab, der unsere Menschlichkeit aufzeigt.</p>\n<p>Eine menschliche Sichtweise und der Wunsch nach einer besseren Zukunft für unsere Welt führen zur Notwendigkeit eines interdisziplinären Dialogs, der auf ein ethisches Vorgehen für die Entwicklung von Algorithmen zielt – die <i>Algor-Ethik</i> –, bei der die Werte die Richtung für die neuen Technologien weisen <a class=\"cleaner\" href=\"#_ftn12\" name=\"_ftnref12\">[12]</a> <sup><sup>[2]</sup></sup>. Ethische Fragen sollten vom Beginn der Forschung an berücksichtigt werden, ebenso in den Phasen des Erprobens, des Entwickelns, der Produktion, der Logistik und der Vermarktung. Dies ist der Ansatz der <i>Ethics by Design</i>, bei der den Bildungseinrichtungen und den Verantwortlichen des Entscheidungsprozesses eine wesentliche Rolle zukommt.</p>\n<p>7. <i>Herausforderungen für die Bildung</i></p>\n<p>Die Entwicklung einer Technologie, die die Menschenwürde respektiert und ihr dient, hat deutliche Auswirkungen auf die Bildungseinrichtungen und die Welt der Kultur. Durch die Vervielfachung der Kommunikationsmöglichkeiten haben die digitalen Technologien neue Formen der Begegnung ermöglicht. Es besteht jedoch die Notwendigkeit, fortlaufend über die Art der Beziehungen nachzudenken, zu denen sie uns führen. Die jungen Menschen wachsen in einem kulturellen Umfeld auf, das von der Technologie durchdrungen ist, was unweigerlich einige Fragen bezüglich der Lehr- und Ausbildungsmethoden aufwirft.</p>\n<p>Zu lehren, Formen künstlicher Intelligenz zu nutzen, sollte vor allem darauf abzielen, das kritische Denken zu fördern. Es ist notwendig, dass die Nutzer aller Altersgruppen, vor allem aber junge Menschen, eine Fähigkeit entwickeln, Daten und Inhalte, die im Internet abgerufen wurden oder von Systemen der künstlichen Intelligenz erzeugt worden sind, kritisch zu verwenden. Die Schulen, die Universitäten und die wissenschaftlichen Gemeinschaften sind aufgerufen, den Studenten und Berufstätigen dabei zu helfen, sich die sozialen und ethischen Aspekte der Entwicklung und der Nutzung der Technologie anzueignen.</p>\n<p>Dazu auszubilden, die neuen Kommunikationsmittel zu verwenden, sollte nicht nur die Fehlinformation, die <i>Fake News</i> berücksichtigen, sondern auch das beunruhigende Zunehmen »angestammte[r] Ängste, […]. Sie haben sich […] zu verbergen gewusst und vermochten sich hinter neuen Technologien zu potenzieren« <a class=\"cleaner\" href=\"#_ftn13\" name=\"_ftnref13\">[13]</a> <sup><sup>[3]</sup></sup>. Leider müssen wir wieder einmal gegen die Versuchung ankämpfen, »eine Kultur der Mauern zu errichten, Mauern hochzuziehen, um [die] Begegnung mit anderen Kulturen, mit anderen Menschen« <a class=\"cleaner\" href=\"#_ftn14\" name=\"_ftnref14\">[14]</a> <sup><sup>[4]</sup></sup> und die Entwicklung eines friedlichen und geschwisterlichen Zusammenlebens zu verhindern.</p>\n<p>8. <i>Herausforderungen für die Entwicklung des Völkerrechts</i></p>\n<p>Die globale Reichweite der künstlichen Intelligenz macht deutlich, dass neben der Verantwortung der souveränen Staaten, deren Einsatz innerhalb ihres eigenen Hoheitsgebiets zu regeln, internationale Organisationen eine entscheidende Rolle beim Abschluss multilateraler Vereinbarungen spielen können und dabei, deren Anwendung und Umsetzung zu koordinieren <a class=\"cleaner\" href=\"#_ftn15\" name=\"_ftnref15\">[15]</a> <sup><sup>[5]</sup></sup>. In dieser Hinsicht fordere ich die Völkergemeinschaft auf, gemeinsam daran zu arbeiten, einen verbindlichen internationalen Vertrag zu schließen, der die Entwicklung und den Einsatz von künstlicher Intelligenz in ihren vielfältigen Formen regelt. Das Ziel der Regulierung sollte natürlich nicht nur die Verhinderung schädlicher Praktiken sein, sondern auch die Ermutigung zu einer guten Praxis, indem neue und kreative Ansätze angeregt sowie persönliche und gemeinschaftliche Initiativen erleichtert werden <a class=\"cleaner\" href=\"#_ftn16\" name=\"_ftnref16\">[16]</a> <sup><sup>[6]</sup></sup>.</p>\n<p>Letztlich ist es bei der Suche nach normativen Regelungen, die den Entwicklern digitaler Technologien eine ethische Orientierung bieten können, unerlässlich, die menschlichen Werte zu identifizieren, die den Bemühungen der Gesellschaften zugrunde liegen sollten, um die notwendigen gesetzlichen Rahmenbedingungen zu formulieren, zu beschließen und anzuwenden. Das Erarbeiten ethischer Richtlinien für die Entwicklung künstlicher Intelligenz kann nicht davon absehen, die tieferen Fragen nach dem Sinn der menschlichen Existenz, dem Schutz der grundlegenden Menschenrechte und dem Streben nach Gerechtigkeit und Frieden zu berücksichtigen. Dieser Prozess ethischer und rechtlicher Unterscheidung kann eine wertvolle Gelegenheit bieten, um gemeinsam darüber nachzudenken, welche Rolle die Technologie in unserem individuellen und gemeinschaftlichen Leben spielen sollte und wie ihr Einsatz zur Schaffung einer gerechteren und menschlicheren Welt beitragen kann. Aus diesem Grund sollten die Stimmen aller betroffenen Gruppen in den Debatten über die Regulierung der künstlichen Intelligenz berücksichtigt werden, auch die Armen, die Ausgegrenzten und andere, die in globalen Entscheidungsprozessen oft ungehört bleiben.</p>\n<p style=\"text-align: center;\">* * * * *</p>\n<p>Ich hoffe, dass diese Überlegungen dazu ermutigen, dafür zu sorgen, dass der Fortschritt bei der Entwicklung von Formen künstlicher Intelligenz letztlich der Sache der menschlichen Geschwisterlichkeit und des Friedens dient. Dies ist nicht die Verantwortung einiger weniger, sondern der gesamten Menschheitsfamilie. Der Friede ist nämlich die Frucht von Beziehungen, die den anderen in seiner unveräußerlichen Würde anerkennen und annehmen, sowie von Zusammenarbeit und Engagement bei der Suche nach der ganzheitlichen Entwicklung aller Menschen und aller Völker.</p>\n<p>Mein Gebet zu Beginn des neuen Jahres ist, dass die rapide Entwicklung von Formen künstlicher Intelligenz die vielen Ungleichheiten und Ungerechtigkeiten, die es in der Welt bereits gibt, nicht noch vergrößert, sondern dazu beiträgt, Kriege und Konflikte zu beenden und viele Formen des Leidens zu lindern, die die Menschheitsfamilie heimsuchen. Mögen die Christen, die Gläubigen der verschiedenen Religionen und die Männer und Frauen guten Willens in Harmonie zusammenarbeiten, um die Chancen zu nutzen und sich den durch die digitale Revolution verursachten Herausforderungen zu stellen und um den künftigen Generationen eine solidarischere, gerechtere und friedlichere Welt zu übergeben.</p>\n<p style=\"text-align: left;\">Aus dem Vatikan, am 8. Dezember 2023</p>\n<p style=\"text-align: center;\">FRANZISKUS</p>\n<p> </p>\n<hr align=\"left\" size=\"1\" width=\"33%\">\n<p><a class=\"cleaner\" href=\"#_ftnref1\" name=\"_ftn1\">[1]</a> Nr. 33.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref2\" name=\"_ftn2\">[2]</a> <i>Ebd., </i>Nr. 57.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref3\" name=\"_ftn3\">[3]</a> Vgl. Enzyklika <i><a href=\"https://www.vatican.va/content/francesco/de/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html\">Laudato si’</a> </i>(24. Mai 2015), 104.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref4\" name=\"_ftn4\">[4]</a> Vgl. <i>ebd.</i>, 114.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref5\" name=\"_ftn5\">[5]</a> <i><a href=\"https://www.vatican.va/content/francesco/de/speeches/2023/march/documents/20230327-minerva-dialogues.html\">Ansprache an die Teilnehmer der Begegnung der „Minerva Dialogues“</a></i> (27. März 2023).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref6\" name=\"_ftn6\">[6]</a> Vgl. <i><a href=\"https://www.vatican.va/content/francesco/de/speeches/2023/march/documents/20230327-minerva-dialogues.html\">ebd</a></i>.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref7\" name=\"_ftn7\">[7]</a> <i>Botschaft an den Vorstandsvorsitzenden des „World Economic Forum“ in Davos-Klosters</i> (12. Januar 2018).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref8\" name=\"_ftn8\">[8]</a> Vgl. Enzyklika <i><a href=\"https://www.vatican.va/content/francesco/de/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html\">Laudato si’</a></i>, 194; <i><a href=\"https://www.vatican.va/content/francesco/de/speeches/2019/september/documents/papa-francesco_20190927_eradigitale.html\">Ansprache an die Teilnehmer des Seminars „Das Gemeinwohl im digitalen Zeitalter“</a></i> (27. September 2019).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref9\" name=\"_ftn9\">[9]</a> Apostolisches Schreiben <i><a href=\"https://www.vatican.va/content/francesco/de/apost_exhortations/documents/papa-francesco_esortazione-ap_20131124_evangelii-gaudium.html#Die_Wirklichkeit_ist_wichtiger_als_die_Idee\">Evangelii gaudium</a></i> (24 Novembre 2013), 233.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref10\" name=\"_ftn10\">[10]</a> Vgl. Enzyklika <i><a href=\"https://www.vatican.va/content/francesco/de/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html\">Laudato si’</a></i>, 54.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref11\" name=\"_ftn11\">[11]</a> Vgl. <i><a href=\"https://www.vatican.va/content/francesco/de/speeches/2020/february/documents/papa-francesco_20200228_accademia-perlavita.html\">Ansprache an die Teilnehmer der Vollversammlung der Päpstlichen Akademie für das Leben</a></i> (28. Februar 2020).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref12\" name=\"_ftn12\">[12]</a> Vgl. <i><a href=\"https://www.vatican.va/content/francesco/de/speeches/2020/february/documents/papa-francesco_20200228_accademia-perlavita.html\">ebd</a></i>.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref13\" name=\"_ftn13\">[13]</a> Enzyklika <i><a href=\"https://www.vatican.va/content/francesco/de/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#27\">Fratelli tutti</a> </i>(3. Oktober 2020), 27.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref14\" name=\"_ftn14\">[14]</a> Vgl. <i><a href=\"https://www.vatican.va/content/francesco/de/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#27\">ebd</a>.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref15\" name=\"_ftn15\">[15]</a> Vgl. <i><a href=\"https://www.vatican.va/content/francesco/de/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#170\">ebd</a>.</i>, 170-175.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref16\" name=\"_ftn16\">[16]</a> Vgl. Enzyklika <i><a href=\"https://www.vatican.va/content/francesco/de/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html\">Laudato si’</a></i>, 177.</p>\n<p> </p><div class=\"clearfix\"></div></hr></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>",
            "it": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p style=\"text-align: center;\"><span class=\"color-text\">MESSAGGIO <br> DI SUA SANTITÀ<br/> <b>FRANCESCO</b><br/> PER LA LVII<br/> </br></span><b><span class=\"title-1-color\">GIORNATA MONDIALE DELLA PACE</span></b></p>\n<p style=\"text-align: center;\"><span class=\"color-text\">1° GENNAIO 2024</span></p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b><i>Intelligenza artificiale e pace</i></b></p>\n<p>All’inizio del nuovo anno, tempo di grazia che il Signore dona a ciascuno di noi, vorrei rivolgermi al Popolo di Dio, alle nazioni, ai Capi di Stato e di Governo, ai Rappresentanti delle diverse religioni e della società civile, a tutti gli uomini e le donne del nostro tempo per porgere i miei auguri di pace.</p>\n<p style=\"text-align: left;\">1. <i>Il progresso della scienza e della tecnologia come via verso la pace</i></p>\n<p>La Sacra Scrittura attesta che Dio ha donato agli uomini il suo Spirito affinché abbiano «saggezza, intelligenza e scienza in ogni genere di lavoro» (<i>Es</i> 35,31). L’intelligenza è espressione della dignità donataci dal Creatore, che ci ha fatti a sua immagine e somiglianza (cfr <i>Gen</i> 1,26) e ci ha messo in grado di rispondere al suo amore attraverso la libertà e la conoscenza. La scienza e la tecnologia manifestano in modo particolare tale qualità fondamentalmente relazionale dell’intelligenza umana: sono prodotti straordinari del suo potenziale creativo.</p>\n<p>Nella Costituzione Pastorale <i><a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_it.html\">Gaudium et spes</a></i>, il <a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/index_it.htm\">Concilio Vaticano II</a> ha ribadito questa verità, dichiarando che «col suo lavoro e col suo ingegno l’uomo ha cercato sempre di sviluppare la propria vita» <a class=\"cleaner\" href=\"#_ftn1\" name=\"_ftnref1\">[1]</a>. Quando gli esseri umani, «con l’aiuto della tecnica», si sforzano affinchè la terra «diventi una dimora degna di tutta la famiglia umana» <a class=\"cleaner\" href=\"#_ftn2\" name=\"_ftnref2\">[2]</a>, agiscono secondo il disegno di Dio e cooperano con la sua volontà di portare a compimento la creazione e di diffondere la pace tra i popoli. Anche il progresso della scienza e della tecnica, nella misura in cui contribuisce a un migliore ordine della società umana, ad accrescere la libertà e la comunione fraterna, porta dunque al miglioramento dell’uomo e <b></b>alla trasformazione del mondo.</p>\n<p>Giustamente ci rallegriamo e siamo riconoscenti per le straordinarie conquiste della scienza e della tecnologia, grazie alle quali si è posto rimedio a innumerevoli mali che affliggevano la vita umana e causavano grandi sofferenze. Allo stesso tempo, i progressi tecnico-scientifici, rendendo possibile l’esercizio di un controllo finora inedito sulla realtà, stanno mettendo nelle mani dell’uomo una vasta gamma di possibilità, alcune delle quali possono rappresentare un rischio per la sopravvivenza e un pericolo per la casa comune <a class=\"cleaner\" href=\"#_ftn3\" name=\"_ftnref3\">[3]</a>.</p>\n<p>I notevoli progressi delle nuove tecnologie dell’informazione, specialmente nella sfera digitale, presentano dunque entusiasmanti opportunità e gravi rischi, con serie implicazioni per il perseguimento della giustizia e dell’armonia tra i popoli. È pertanto necessario porsi alcune domande urgenti. Quali saranno le conseguenze, a medio e a lungo termine, delle nuove tecnologie digitali? E quale impatto avranno sulla vita degli individui e della società, sulla stabilità internazionale e sulla pace?</p>\n<p style=\"text-align: left;\">2. <i>Il futuro dell’intelligenza artificiale tra promesse e rischi</i></p>\n<p>I progressi dell’informatica e lo sviluppo delle tecnologie digitali negli ultimi decenni hanno già iniziato a produrre profonde trasformazioni nella società globale e nelle sue dinamiche. I nuovi strumenti digitali stanno cambiando il volto delle comunicazioni, della pubblica amministrazione, dell’istruzione, dei consumi, delle interazioni personali e di innumerevoli altri aspetti della vita quotidiana.</p>\n<p>Inoltre, le tecnologie che impiegano una molteplicità di algoritmi possono estrarre, dalle tracce digitali lasciate su <i>internet</i>, dati che consentono di controllare le abitudini mentali e relazionali delle persone a fini commerciali o politici, spesso a loro insaputa, limitandone il consapevole esercizio della libertà di scelta. Infatti, in uno spazio come il <i>web</i>, caratterizzato da un sovraccarico di informazioni, possono strutturare il flusso di dati secondo criteri di selezione non sempre percepiti dall’utente.</p>\n<p>Dobbiamo ricordare che la ricerca scientifica e le innovazioni tecnologiche non sono disincarnate dalla realtà e «neutrali» <a class=\"cleaner\" href=\"#_ftn4\" name=\"_ftnref4\">[4]</a>, ma soggette alle influenze culturali. In quanto attività pienamente umane, le direzioni che prendono riflettono scelte condizionate dai valori personali, sociali e culturali di ogni epoca. Dicasi lo stesso per i risultati che conseguono: essi, proprio in quanto frutto di approcci specificamente umani al mondo circostante, hanno sempre una dimensione etica, strettamente legata alle decisioni di chi progetta la sperimentazione e indirizza la produzione verso particolari obiettivi.</p>\n<p>Questo vale anche per le forme di intelligenza artificiale. Di essa, ad oggi, non esiste una definizione univoca nel mondo della scienza e della tecnologia. Il termine stesso, ormai entrato nel linguaggio comune, abbraccia una varietà di scienze, teorie e tecniche volte a far sì che le macchine riproducano o imitino, nel loro funzionamento, le capacità cognitive degli esseri umani. Parlare al plurale di “forme di intelligenza” può aiutare a sottolineare soprattutto il divario incolmabile che esiste tra questi sistemi, per quanto sorprendenti e potenti, e la persona umana: essi sono, in ultima analisi, “frammentari”, nel senso che possono solo imitare o riprodurre alcune funzioni dell’intelligenza umana. L’uso del plurale evidenzia inoltre che questi dispositivi, molto diversi tra loro, vanno sempre considerati come “sistemi socio-tecnici”. Infatti il loro impatto, al di là della tecnologia di base, dipende non solo dalla progettazione, ma anche dagli obiettivi e dagli interessi di chi li possiede e di chi li sviluppa, nonché dalle situazioni in cui vengono impiegati.</p>\n<p>L’intelligenza artificiale, quindi, deve essere intesa come una galassia di realtà diverse e non possiamo presumere a priori che il suo sviluppo apporti un contributo benefico al futuro dell’umanità e alla pace tra i popoli. Tale risultato positivo sarà possibile solo se ci dimostreremo capaci di agire in modo responsabile e di rispettare valori umani fondamentali come «l’inclusione, la trasparenza, la sicurezza, l’equità, la riservatezza e l’affidabilità» <a class=\"cleaner\" href=\"#_ftn5\" name=\"_ftnref5\">[5]</a>.</p>\n<p>Non è sufficiente nemmeno presumere, da parte di chi progetta algoritmi e tecnologie digitali, un impegno ad agire in modo etico e responsabile. Occorre rafforzare o, se necessario, istituire organismi incaricati di esaminare le questioni etiche emergenti e di tutelare i diritti di quanti utilizzano forme di intelligenza artificiale o ne sono influenzati <a class=\"cleaner\" href=\"#_ftn6\" name=\"_ftnref6\">[6]</a>.</p>\n<p>L’immensa espansione della tecnologia deve quindi essere accompagnata da un’adeguata formazione alla responsabilità per il suo sviluppo. La libertà e la convivenza pacifica sono minacciate quando gli esseri umani cedono alla tentazione dell’egoismo, dell’interesse personale, della brama di profitto e della sete di potere. Abbiamo perciò il dovere di allargare lo sguardo e di orientare la ricerca tecnico-scientifica al perseguimento della pace e del bene comune, al servizio dello sviluppo integrale dell’uomo e della comunità <a class=\"cleaner\" href=\"#_ftn7\" name=\"_ftnref7\">[7]</a>.</p>\n<p>La dignità intrinseca di ogni persona e la fraternità che ci lega come membri dell’unica famiglia umana devono stare alla base dello sviluppo di nuove tecnologie e servire come criteri indiscutibili per valutarle prima del loro impiego, in modo che il progresso digitale possa avvenire nel rispetto della giustizia e contribuire alla causa della pace. Gli sviluppi tecnologici che non portano a un miglioramento della qualità di vita di tutta l’umanità, ma al contrario aggravano le disuguaglianze e i conflitti, non potranno mai essere considerati vero progresso <a class=\"cleaner\" href=\"#_ftn8\" name=\"_ftnref8\">[8]</a>.</p>\n<p>L’intelligenza artificiale diventerà sempre più importante. Le sfide che pone sono tecniche, ma anche antropologiche, educative, sociali e politiche. Promette, ad esempio, un risparmio di fatiche, una produzione più efficiente, trasporti più agevoli e mercati più dinamici, oltre a una rivoluzione nei processi di raccolta, organizzazione e verifica dei dati. Occorre essere consapevoli delle rapide trasformazioni in atto e gestirle in modo da salvaguardare i diritti umani fondamentali, rispettando le istituzioni e le leggi che promuovono lo sviluppo umano integrale. L’intelligenza artificiale dovrebbe essere al servizio del migliore potenziale umano e delle nostre più alte aspirazioni, non in competizione con essi.</p>\n<p style=\"text-align: left;\">3. <i>La tecnologia del futuro: macchine che imparano da sole</i></p>\n<p>Nelle sue molteplici forme l’intelligenza artificiale, basata su tecniche di apprendimento automatico (<i>machine learning</i>), pur essendo ancora in fase pionieristica, sta già introducendo notevoli cambiamenti nel tessuto delle società, esercitando una profonda influenza sulle culture, sui comportamenti sociali e sulla costruzione della pace.</p>\n<p>Sviluppi come il <i>machine learning</i> o come l’apprendimento profondo (<i>deep learning</i>) sollevano questioni che trascendono gli ambiti della tecnologia e dell’ingegneria e hanno a che fare con una comprensione strettamente connessa al significato della vita umana, ai processi basilari della conoscenza e alla capacità della mente di raggiungere la verità.</p>\n<p>L’abilità di alcuni dispositivi nel produrre testi sintatticamente e semanticamente coerenti, ad esempio, non è garanzia di affidabilità. Si dice che possano “allucinare”, cioè generare affermazioni che a prima vista sembrano plausibili, ma che in realtà sono infondate o tradiscono pregiudizi. Questo pone un serio problema quando l’intelligenza artificiale viene impiegata in campagne di disinformazione che diffondono notizie false e portano a una crescente sfiducia nei confronti dei mezzi di comunicazione. La riservatezza, il possesso dei dati e la proprietà intellettuale sono altri ambiti in cui le tecnologie in questione comportano gravi rischi, a cui si aggiungono ulteriori conseguenze negative legate a un loro uso improprio, come la discriminazione, l’interferenza nei processi elettorali, il prendere piede di una società che sorveglia e controlla le persone, l’esclusione digitale e l’inasprimento di un individualismo sempre più scollegato dalla collettività. Tutti questi fattori rischiano di alimentare i conflitti e di ostacolare la pace.</p>\n<p style=\"text-align: left;\">4.<i> Il senso del limite nel paradigma tecnocratico</i></p>\n<p>Il nostro mondo è troppo vasto, vario e complesso per essere completamente conosciuto e classificato. La mente umana non potrà mai esaurirne la ricchezza, nemmeno con l’aiuto degli algoritmi più avanzati. Questi, infatti, non offrono previsioni garantite del futuro, ma solo approssimazioni statistiche. Non tutto può essere pronosticato, non tutto può essere calcolato; alla fine «la realtà è superiore all’idea» <a class=\"cleaner\" href=\"#_ftn9\" name=\"_ftnref9\">[9]</a>e, per quanto prodigiosa possa essere la nostra capacità di calcolo, ci sarà sempre un residuo inaccessibile che sfugge a qualsiasi tentativo di misurazione.</p>\n<p>Inoltre, la grande quantità di dati analizzati dalle intelligenze artificiali non è di per sé garanzia di imparzialità. Quando gli algoritmi estrapolano informazioni, corrono sempre il rischio di distorcerle, replicando le ingiustizie e i pregiudizi degli ambienti in cui esse hanno origine. Più diventano veloci e complessi, più è difficile comprendere perché abbiano prodotto un determinato risultato.</p>\n<p>Le macchine “intelligenti” possono svolgere i compiti loro assegnati con sempre maggiore efficienza, ma lo scopo e il significato delle loro operazioni continueranno a essere determinati o abilitati da esseri umani in possesso di un proprio universo di valori. Il rischio è che i criteri alla base di certe scelte diventino meno chiari, che la responsabilità decisionale venga nascosta e che i produttori possano sottrarsi all’obbligo di agire per il bene della comunità. In un certo senso, ciò è favorito dal sistema tecnocratico, che allea l’economia con la tecnologia e privilegia il criterio dell’efficienza, tendendo a ignorare tutto ciò che non è legato ai suoi interessi immediati <a class=\"cleaner\" href=\"#_ftn10\" name=\"_ftnref10\">[10]</a>.</p>\n<p>Questo deve farci riflettere su un aspetto tanto spesso trascurato nella mentalità attuale, tecnocratica ed efficientista, quanto decisivo per lo sviluppo personale e sociale: il “senso del limite”. L’essere umano, infatti, mortale per definizione, pensando di travalicare ogni limite in virtù della tecnica, rischia, nell’ossessione di voler controllare tutto, di perdere il controllo su sé stesso; nella ricerca di una libertà assoluta, di cadere nella spirale di una dittatura tecnologica. Riconoscere e accettare il proprio limite di creatura è per l’uomo condizione indispensabile per conseguire, o meglio, accogliere in dono la pienezza. Invece, nel contesto ideologico di un paradigma tecnocratico, animato da una prometeica presunzione di autosufficienza, le disuguaglianze potrebbero crescere a dismisura, e la conoscenza e la ricchezza accumularsi nelle mani di pochi, con gravi rischi per le società democratiche e la coesistenza pacifica <a class=\"cleaner\" href=\"#_ftn11\" name=\"_ftnref11\">[11]</a>.</p>\n<p>5. <i>Temi scottanti per l’etica</i></p>\n<p>In futuro, l’affidabilità di chi richiede un mutuo, l’idoneità di un individuo ad un lavoro, la possibilità di recidiva di un condannato o il diritto a ricevere asilo politico o assistenza sociale potrebbero essere determinati da sistemi di intelligenza artificiale. La mancanza di diversificati livelli di mediazione che questi sistemi introducono è particolarmente esposta a forme di pregiudizio e discriminazione: gli errori sistemici possono facilmente moltiplicarsi, producendo non solo ingiustizie in singoli casi ma anche, per effetto domino, vere e proprie forme di disuguaglianza sociale.</p>\n<p>Talvolta, inoltre, le forme di intelligenza artificiale sembrano in grado di influenzare le decisioni degli individui attraverso opzioni predeterminate associate a stimoli e dissuasioni, oppure mediante sistemi di regolazione delle scelte personali basati sull’organizzazione delle informazioni. Queste forme di manipolazione o di controllo sociale richiedono un’attenzione e una supervisione accurate, e implicano una chiara responsabilità legale da parte dei produttori, di chi le impiega e delle autorità governative.</p>\n<p>L’affidamento a processi automatici che categorizzano gli individui, ad esempio attraverso l’uso pervasivo della vigilanza o l’adozione di sistemi di credito sociale, potrebbe avere ripercussioni profonde anche sul tessuto civile, stabilendo improprie graduatorie tra i cittadini. E questi processi artificiali di classificazione potrebbero portare anche a conflitti di potere, non riguardando solo destinatari virtuali, ma persone in carne ed ossa. Il rispetto fondamentale per la dignità umana postula di rifiutare che l’unicità della persona venga identificata con un insieme di dati. Non si deve permettere agli algoritmi di determinare il modo in cui intendiamo i diritti umani, di mettere da parte i valori essenziali della compassione, della misericordia e del perdono o di eliminare la possibilità che un individuo cambi e si lasci alle spalle il passato.</p>\n<p>In questo contesto non possiamo fare a meno di considerare l’impatto delle nuove tecnologie<b> </b>in ambito lavorativo: mansioni che un tempo erano appannaggio esclusivo della manodopera umana vengono rapidamente assorbite dalle applicazioni industriali dell’intelligenza artificiale. Anche in questo caso, c’è il rischio sostanziale di un vantaggio sproporzionato per pochi a scapito dell’impoverimento di molti. Il rispetto della dignità dei lavoratori e l’importanza dell’occupazione per il benessere economico delle persone, delle famiglie e delle società, la sicurezza degli impieghi e l’equità dei salari dovrebbero costituire un’alta priorità per la Comunità internazionale, mentre queste forme di tecnologia penetrano sempre più profondamente nei luoghi di lavoro.</p>\n<p>6.<b><i> </i></b><i>Trasformeremo le spade in vomeri?</i></p>\n<p>In questi giorni, guardando il mondo che ci circonda, non si può sfuggire alle gravi questioni etiche legate al settore degli armamenti. La possibilità di condurre operazioni militari attraverso sistemi di controllo remoto ha portato a una minore percezione della devastazione da essi causata e della responsabilità del loro utilizzo, contribuendo a un approccio ancora più freddo e distaccato all’immensa tragedia della guerra. La ricerca sulle tecnologie emergenti nel settore dei cosiddetti “sistemi d’arma autonomi letali”, incluso l’utilizzo bellico dell’intelligenza artificiale, è un grave motivo di preoccupazione etica. I sistemi d’arma autonomi non potranno mai essere soggetti moralmente responsabili: l’esclusiva capacità umana di giudizio morale e di decisione etica è più di un complesso insieme di algoritmi, e tale capacità non può essere ridotta alla programmazione di una macchina che, per quanto “intelligente”, rimane pur sempre una macchina. Per questo motivo, è imperativo garantire una supervisione umana adeguata, significativa e coerente dei sistemi d’arma.</p>\n<p>Non possiamo nemmeno ignorare la possibilità che armi sofisticate finiscano nelle mani sbagliate, facilitando, ad esempio, attacchi terroristici o interventi volti a destabilizzare istituzioni di governo legittime. Il mondo, insomma, non ha proprio bisogno che le nuove tecnologie contribuiscano all’iniquo sviluppo del mercato e del commercio delle armi, promuovendo la follia della guerra. Così facendo, non solo l’intelligenza, ma il cuore stesso dell’uomo, correrà il rischio di diventare sempre più “artificiale”. Le più avanzate applicazioni tecniche non vanno impiegate per agevolare la risoluzione violenta dei conflitti, ma per pavimentare le vie della pace.</p>\n<p>In un’ottica più positiva, se l’intelligenza artificiale fosse utilizzata per promuovere lo sviluppo umano integrale, potrebbe introdurre importanti innovazioni nell’agricoltura, nell’istruzione e nella cultura, un miglioramento del livello di vita di intere nazioni e popoli, la crescita della fraternità umana e dell’amicizia sociale. In definitiva, il modo in cui la utilizziamo per includere gli ultimi, cioè i fratelli e le sorelle più deboli e bisognosi, è la misura rivelatrice della nostra umanità.</p>\n<p>Uno sguardo umano e il desiderio di un futuro migliore per il nostro mondo portano alla necessità di un dialogo interdisciplinare finalizzato a uno sviluppo etico degli algoritmi – <i>l’algor-etica –</i>, in cui siano i valori a orientare i percorsi delle nuove tecnologie <a class=\"cleaner\" href=\"#_ftn12\" name=\"_ftnref12\">[12]</a>. Le questioni etiche dovrebbero essere tenute in considerazione fin dall’inizio della ricerca, così come nelle fasi di sperimentazione, progettazione, produzione, distribuzione e commercializzazione. Questo è l’approccio dell’etica della progettazione, in cui le istituzioni educative e i responsabili del processo decisionale hanno un ruolo essenziale da svolgere.</p>\n<p style=\"text-align: left;\">7. <i>Sfide per l’educazione</i></p>\n<p>Lo sviluppo di una tecnologia che rispetti e serva la dignità umana ha chiare implicazioni per le istituzioni educative e per il mondo della cultura. Moltiplicando le possibilità di comunicazione, le tecnologie digitali hanno permesso di incontrarsi in modi nuovi. Tuttavia, rimane la necessità di una riflessione continua sul tipo di relazioni a cui ci stanno indirizzando. I giovani stanno crescendo in ambienti culturali pervasi dalla tecnologia e questo non può non mettere in discussione i metodi di insegnamento e formazione.</p>\n<p>L’educazione all’uso di forme di intelligenza artificiale dovrebbe mirare soprattutto a promuovere il pensiero critico. È necessario che gli utenti di ogni età, ma soprattutto i giovani, sviluppino una capacità di discernimento nell’uso di dati e contenuti raccolti sul <i>web</i> o prodotti da sistemi di intelligenza artificiale. Le scuole, le università e le società scientifiche sono chiamate ad aiutare gli studenti e i professionisti a fare propri gli aspetti sociali ed etici dello sviluppo e dell’utilizzo della tecnologia.</p>\n<p>La formazione all’uso dei nuovi strumenti di comunicazione dovrebbe tenere conto non solo della disinformazione, delle <i>fake news</i>, ma anche dell’inquietante recrudescenza di «paure ancestrali [...] che hanno saputo nascondersi e potenziarsi dietro nuove tecnologie» <a class=\"cleaner\" href=\"#_ftn13\" name=\"_ftnref13\">[13]</a>. Purtroppo, ancora una volta ci troviamo a dover combattere “la tentazione di fare una cultura dei muri, di alzare muri per impedire l’incontro con altre culture, con altra gente” <a class=\"cleaner\" href=\"#_ftn14\" name=\"_ftnref14\">[14]</a>e lo sviluppo di una coesistenza pacifica e fraterna.</p>\n<p style=\"text-align: left;\">8. <i>Sfide per lo sviluppo del diritto internazionale</i></p>\n<p>La portata globale dell’intelligenza artificiale rende evidente che, accanto alla responsabilità degli Stati sovrani di disciplinarne l’uso al proprio interno, le Organizzazioni internazionali possono svolgere un ruolo decisivo nel raggiungere accordi multilaterali e nel coordinarne l’applicazione e l’attuazione <a class=\"cleaner\" href=\"#_ftn15\" name=\"_ftnref15\">[15]</a>. A tale proposito, esorto la Comunità delle nazioni a lavorare unita al fine di adottare un trattato internazionale vincolante, che regoli lo sviluppo e l’uso dell’intelligenza artificiale nelle sue molteplici forme. L’obiettivo della regolamentazione, naturalmente, non dovrebbe essere solo la prevenzione delle cattive pratiche, ma anche l’incoraggiamento delle buone pratiche, stimolando approcci nuovi e creativi e facilitando iniziative personali e collettive <a class=\"cleaner\" href=\"#_ftn16\" name=\"_ftnref16\">[16]</a>.</p>\n<p>In definitiva, nella ricerca di modelli normativi che possano fornire una guida etica agli sviluppatori di tecnologie digitali, è indispensabile identificare i valori umani che dovrebbero essere alla base dell’impegno delle società per formulare, adottare e applicare necessari quadri legislativi. Il lavoro di redazione di linee guida etiche per la produzione di forme di intelligenza artificiale non può prescindere dalla considerazione di questioni più profonde riguardanti il significato dell’esistenza umana, la tutela dei diritti umani fondamentali, il perseguimento della giustizia e della pace. Questo processo di discernimento etico e giuridico può rivelarsi un’occasione preziosa per una riflessione condivisa sul ruolo che la tecnologia dovrebbe avere nella nostra vita individuale e comunitaria e su come il suo utilizzo possa contribuire alla creazione di un mondo più equo e umano. Per questo motivo, nei dibattiti sulla regolamentazione dell’intelligenza artificiale, si dovrebbe tenere conto della voce di tutte le parti interessate, compresi i poveri, gli emarginati e altri che spesso rimangono inascoltati nei processi decisionali globali.</p>\n<p style=\"text-align: center;\">* * *</p>\n<p>Spero che questa riflessione incoraggi a far sì che i progressi nello sviluppo di forme di intelligenza artificiale servano, in ultima analisi, la causa della fraternità umana e della pace. Non è responsabilità di pochi, ma dell’intera famiglia umana. La pace, infatti, è il frutto di relazioni che riconoscono e accolgono l’altro nella sua inalienabile dignità, e di cooperazione e impegno nella ricerca dello sviluppo integrale di tutte le persone e di tutti i popoli.</p>\n<p>La mia preghiera all’inizio del nuovo anno è che il rapido sviluppo di forme di intelligenza artificiale non accresca le troppe disuguaglianze e ingiustizie già presenti nel mondo, ma contribuisca a porre fine a guerre e conflitti, e ad alleviare molte forme di sofferenza che affliggono la famiglia umana. Possano i fedeli cristiani, i credenti di varie religioni e gli uomini e le donne di buona volontà collaborare in armonia per cogliere le opportunità e affrontare le sfide poste dalla rivoluzione digitale, e consegnare alle generazioni future un mondo più solidale, giusto e pacifico.</p>\n<p><i>Dal Vaticano, 8 dicembre 2023</i></p>\n<p style=\"text-align: center;\">FRANCESCO</p>\n<div>\n    \n <hr align=\"left\" size=\"1\" width=\"33%\">\n<div>\n     \n  <p><a class=\"cleaner\" href=\"#_ftnref1\" name=\"_ftn1\">[1]</a>  <a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_it.html#33\">N. 33</a>.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref2\" name=\"_ftn2\">[2]</a>  <i><a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_it.html#57\">Ibid</a>.</i>, 57.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref3\" name=\"_ftn3\">[3]</a> Cfr Lett. enc. <i><a href=\"https://www.vatican.va/content/francesco/it/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#104.\">Laudato si’</a> </i>(24 maggio 2015), 104.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref4\" name=\"_ftn4\">[4]</a> Cfr <i><a href=\"https://www.vatican.va/content/francesco/it/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#114.\">ibid</a>.</i>, 114.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref5\" name=\"_ftn5\">[5]</a>  <i><a href=\"https://www.vatican.va/content/francesco/it/speeches/2023/march/documents/20230327-minerva-dialogues.html\">Udienza ai partecipanti all’Incontro “Minerva Dialogues”</a></i> (27 marzo 2023).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref6\" name=\"_ftn6\">[6]</a> Cfr <i><a href=\"https://www.vatican.va/content/francesco/it/speeches/2023/march/documents/20230327-minerva-dialogues.html\">ibid</a>.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref7\" name=\"_ftn7\">[7]</a> Cfr <a href=\"https://www.vatican.va/content/francesco/it/messages/pont-messages/2018/documents/papa-francesco_20180112_messaggio-davos2018.html\"><i>Messaggio al Presidente Esecutivo del “World Economic Forum” a Davos-Klosters</i></a> (12 gennaio 2018).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref8\" name=\"_ftn8\">[8]</a> Cfr Lett. enc. <i><a href=\"https://www.vatican.va/content/francesco/it/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#194.\">Laudato si’</a></i>, 194; <i><a href=\"https://www.vatican.va/content/francesco/it/speeches/2019/september/documents/papa-francesco_20190927_eradigitale.html\">Discorso ai partecipanti al Seminario “Il bene comune nell’era digitale”</a></i> (27 settembre 2019).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref9\" name=\"_ftn9\">[9]</a> Esort. ap. <i><a href=\"https://www.vatican.va/content/francesco/it/apost_exhortations/documents/papa-francesco_esortazione-ap_20131124_evangelii-gaudium.html#La_realtà_è_più_importante_dell’idea\">Evangelii gaudium</a></i> (24 novembre 2013), 233.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref10\" name=\"_ftn10\">[10]</a> Cfr Lett. enc. <i><a href=\"https://www.vatican.va/content/francesco/it/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#54.\">Laudato si’</a></i>, 54.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref11\" name=\"_ftn11\">[11]</a> Cfr <i><a href=\"https://www.vatican.va/content/francesco/it/speeches/2020/february/documents/papa-francesco_20200228_accademia-perlavita.html\">Discorso ai partecipanti alla Plenaria della Pontificia Accademia per la Vita</a> </i>(28 febbraio 2020).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref12\" name=\"_ftn12\">[12]</a> Cfr <i><a href=\"https://www.vatican.va/content/francesco/it/speeches/2020/february/documents/papa-francesco_20200228_accademia-perlavita.html\">ibid</a>.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref13\" name=\"_ftn13\">[13]</a> Lett. enc. <i><a href=\"https://www.vatican.va/content/francesco/it/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#27\">Fratelli tutti</a> </i>(3 ottobre 2020), 27.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref14\" name=\"_ftn14\">[14]</a> Cfr <i><a href=\"https://www.vatican.va/content/francesco/it/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#27\">ibid</a>.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref15\" name=\"_ftn15\">[15]</a> Cfr <i><a href=\"https://www.vatican.va/content/francesco/it/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#170\">ibid</a>.</i>, 170-175.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref16\" name=\"_ftn16\">[16]</a> Cfr Lett. enc. <i><a href=\"https://www.vatican.va/content/francesco/it/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#177.\">Laudato si’</a></i>, 177.</p>\n</div>\n</hr></div><div class=\"clearfix\"></div></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>",
            "pl": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p style=\"text-align: center;\"><span class=\"color-text\">ORĘDZIE <br> JEGO ŚWIĄTOBLIWOŚCI <br/> FRANCISZKA</br></span></p>\n<p style=\"text-align: center;\"><b><span class=\"title-1-color\">NA 57. ŚWIATOWY DZIEŃ POKOJU</span></b></p>\n<p style=\"text-align: center;\"><span class=\"color-text\">1 STYCZNIA 2024 R.</span></p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b><i>Sztuczna inteligencja i pokój</i></b></p>\n<p> </p>\n<p>Na początku Nowego Roku, czasu łaski, który Pan daje każdemu z nas, chciałbym zwrócić się do Ludu Bożego, narodów, głów państw i rządów, przedstawicieli różnych religii i społeczeństwa obywatelskiego oraz wszystkich mężczyzn i kobiet naszych czasów, aby złożyć najlepsze życzenia pokoju.</p>\n<p style=\"text-align: left;\">1. <i>Postęp nauki i technologii jako droga do pokoju</i></p>\n<p>Pismo Święte zaświadcza, że Bóg dał ludziom swego Ducha, aby posiadali „mądrość, rozum, wiedzę i znajomość wszelkiego rzemiosła” (<i>Wj </i>35, 31). Rozum jest wyrazem godności nadanej nam przez Stwórcę, który stworzył nas na swój obraz i podobieństwo (por. <i>Rdz </i>1, 26) i umożliwił nam odpowiadanie na Jego miłość poprzez wolność i poznanie. Nauka i technologia w szczególny sposób ukazują tę fundamentalnie relacyjną właściwość ludzkiego rozumu: są one niezwykłymi wytworami jego potencjału twórczego.</p>\n<p>W Konstytucji duszpasterskiej <i>Gaudium et spes, </i>Sobór Watykański II potwierdził tę prawdę, oświadczając, że „człowiek zawsze starał się dynamiczniej rozwijać swoje życie dzięki własnej pracy i uzdolnieniom duchowym” <a class=\"cleaner\" href=\"#_ftn1\" name=\"_ftnref1\">[1]</a>. Kiedy ludzie, „za pomocą środków technicznych”, dążą do tego, aby ziemia „stawała się mieszkaniem godnym całej rodziny ludzkiej\" <a class=\"cleaner\" href=\"#_ftn2\" name=\"_ftnref2\">[2]</a>, działają zgodnie z planem Boga i współpracują z Jego wolą, aby dokończyć dzieło stworzenia i szerzyć pokój między narodami. Także postęp nauki i techniki, o ile przyczynia się do lepszego porządku społeczności ludzkiej, do rozwoju wolności i braterskiej komunii, prowadzi w ten sposób do udoskonalenia człowieka i przemiany świata.</p>\n<p>Słusznie cieszymy się i jesteśmy wdzięczni za niezwykłe zdobycze nauki i techniki, dzięki którym zażegnano niezliczone bolączki, które trapiły ludzkie życie i powodowały wielkie cierpienia. Jednocześnie postęp technologiczno-naukowy, umożliwiając sprawowanie niespotykanej dotąd kontroli nad rzeczywistością, oddaje w ludzkie ręce szeroki wachlarz możliwości, z których pewne mogą stanowić zagrożenie dla ludzkiego przetrwania i niebezpieczeństwo dla wspólnego domu <a class=\"cleaner\" href=\"#_ftn3\" name=\"_ftnref3\">[3]</a>.</p>\n<p>Znaczący postęp nowych technologii informacyjnych, zwłaszcza w sferze cyfrowej, stwarza zatem fascynujące szanse i poważne zagrożenia, z ogromnymi konsekwencjami dla dążenia do sprawiedliwości i zgody między ludźmi. Należy zatem zadać kilka pilnych pytań. Jakie będą średnio- i długoterminowe konsekwencje nowych technologii cyfrowych? I jaki wpływ będą one miały na życie jednostek i społeczeństwa, na międzynarodową stabilność i pokój?</p>\n<p style=\"text-align: left;\">2. <i>Przyszłość sztucznej inteligencji między obietnicami a zagrożeniami</i></p>\n<p>Postęp w informatyce i rozwój technologii cyfrowych, w minionych dekadach, już zaczęły powodować głębokie przemiany w globalnym społeczeństwie i jego dynamice. Nowe narzędzia cyfrowe zmieniają oblicze komunikacji, administracji publicznej, edukacji, konsumpcji, interakcji osobistych i niezliczonych innych aspektów codziennego życia.</p>\n<p>Ponadto, technologie wykorzystujące różnorodne algorytmy mogą wydobywać z cyfrowych śladów pozostawionych w <i>Internecie </i>dane, które pozwalają kontrolować nawyki mentalne i relacyjne ludzi w celach komercyjnych lub politycznych, często bez ich wiedzy, ograniczając ich świadome korzystanie z wolności wyboru. Rzeczywiście, w przestrzeni takiej jak <i>sieć</i>, charakteryzującej się nadmiarem informacji, mogą one kształtować przepływ danych zgodnie z kryteriami wyboru, które nie zawsze są zauważane przez użytkownika.</p>\n<p>Musimy pamiętać, że badania naukowe i innowacje technologiczne nie są oderwane od rzeczywistości i „neutralne” <a class=\"cleaner\" href=\"#_ftn4\" name=\"_ftnref4\">[4]</a>, lecz podlegają wpływom kulturowym. Jako że, są one w pełni działaniami ludzkimi, to obierane przez nie kierunki odzwierciedlają wybory uwarunkowane wartościami osobistymi, społecznymi i kulturowymi każdej epoki. Odnosi się to także do osiąganych przez nie rezultatów: właśnie dlatego, że są one wynikiem specyficznie ludzkiego podejścia do otaczającego świata, zawsze mają wymiar etyczny, ściśle związany z decyzjami tych, którzy projektują eksperymenty i ukierunkowują produkcję ku określonym celom.</p>\n<p>Dotyczy to również form sztucznej inteligencji. Jak dotąd, w świecie nauki i technologii nie ma jednoznacznej jej definicji. Sam termin, który wszedł już do języka potocznego, obejmuje różnorodność nauk, teorii i technik mających na celu sprawienie, by maszyny odtwarzały lub naśladowały w swoim działaniu zdolności poznawcze istot ludzkich. Mówienie w liczbie mnogiej o „formach inteligencji” może pomóc podkreślić nade wszystko niemożliwą do pokonania rozbieżność istniejącą między tymi systemami, niezależnie od tego, jak niesamowite i potężne mogą one być, a osobą ludzką: są one w ostatecznym rachunku „fragmentaryczne” w tym sensie, że mogą naśladować lub odtwarzać tylko niektóre funkcje ludzkiej inteligencji. Użycie liczby mnogiej podkreśla również, że te urządzenia, bardzo różniące się między sobą, powinny być zawsze traktowane jako „systemy socjotechniczne”. Istotnie, ich wpływ, niezależnie od technologii podstawowej, zależy nie tylko od ich zaprojektowania, lecz także od celów i interesów tych, którzy je posiadają, i tych, którzy je rozwijają, a także od sytuacji, w jakich są używane.</p>\n<p>Sztuczna inteligencja musi być zatem rozumiana jako plejada różnych rzeczywistości i nie możemy zakładać <i>a priori</i>, że jej rozwój wniesie dobroczynny wkład dla przyszłości ludzkości i dla pokoju między narodami. Taki pozytywny skutek będzie możliwy tylko wtedy, gdy okażemy się zdolni do odpowiedzialnego działania i poszanowania podstawowych wartości ludzkich, takich jak „inkluzywność, transparencja, bezpieczeństwo, bezstronność, poufność i rzetelność” <a class=\"cleaner\" href=\"#_ftn5\" name=\"_ftnref5\">[5]</a>.</p>\n<p>Nie wystarczy również zakładać, że osoby projektujące algorytmy i technologie cyfrowe będą działać w sposób etyczny i odpowiedzialny. Konieczne jest wzmocnienie lub, w razie potrzeby, utworzenie organów, powołanych do badania pojawiających się kwestii etycznych i ochrony praw osób korzystających z form sztucznej inteligencji lub znajdujących się pod ich wpływem <a class=\"cleaner\" href=\"#_ftn6\" name=\"_ftnref6\">[6]</a>.</p>\n<p>Ogromnej ekspansji technologii musi zatem towarzyszyć stosowna formacja w zakresie odpowiedzialności za jej rozwój. Wolność i pokojowe współistnienie są zagrożone wówczas, gdy ludzie ulegają pokusie egoizmu, korzyści osobistej, żądzy zysku i pragnienia władzy. Mamy zatem obowiązek poszerzyć nasze spojrzenie i ukierunkować badania techniczno-naukowe na dążenie do pokoju i dobra wspólnego, w służbie integralnego rozwoju człowieka i wspólnoty <a class=\"cleaner\" href=\"#_ftn7\" name=\"_ftnref7\">[7]</a>.</p>\n<p>Przyrodzona godność każdej osoby i braterstwo, które łączy nas jako członków jednej rodziny ludzkiej, muszą leżeć u podstaw rozwoju nowych technologii i służyć jako bezdyskusyjne kryteria ich oceny przed ich wykorzystaniem, tak aby postęp cyfrowy mógł odbywać się z poszanowaniem sprawiedliwości i przyczyniać się do sprawy pokoju. Rozwój technologiczny, który nie prowadzi do poprawy jakości życia całej ludzkości, a wręcz przeciwnie, pogłębia nierówności i konflikty, nigdy nie może być uznany za prawdziwy postęp <a class=\"cleaner\" href=\"#_ftn8\" name=\"_ftnref8\">[8]</a>.</p>\n<p>Sztuczna inteligencja będzie zyskiwać na znaczeniu. Wyzwania jakie stawia mają charakter techniczny, ale także antropologiczny, edukacyjny, społeczny i polityczny. Obiecuje ona na przykład oszczędność nakładów pracy, bardziej wydajną produkcję, sprawniejszy transport i bardziej dynamiczne rynki, a także rewolucję w gromadzeniu, organizacji i procesach weryfikacji danych. Musimy być świadomi zachodzących gwałtownych przemian i zarządzać nimi w sposób, który chroni podstawowe prawa człowieka, z poszanowaniem instytucji i przepisów, które promują jego integralny rozwój. Sztuczna inteligencja powinna służyć najlepszemu ludzkiemu potencjałowi i naszym najbardziej wzniosłym aspiracjom, a nie z nimi konkurować.</p>\n<p style=\"text-align: left;\">3. <i>Technologia przyszłości: maszyny, które same się uczą</i></p>\n<p>W swoich różnorodnych formach sztuczna inteligencja, oparta na technikach uczenia automatycznego (<i>machine learning</i>), choć wciąż znajduje się na etapie pionierskim, już wprowadza znaczące zmiany w tkance społeczeństw, wywierając głęboki wpływ na kultury, zachowania społeczne i budowanie pokoju.</p>\n<p>Rozwój, taki jak <i>machine learning</i> lub głębokie<i> </i>uczenie (<i>deep learning</i>), rodzi pytania, które wykraczają poza sferę technologii i inżynierii, i mają związek ze zrozumieniem, ściśle połączonym z sensem ludzkiego życia, podstawowymi procesami poznawczymi i zdolnością umysłu do dotarcia do prawdy.</p>\n<p>Na przykład, zdolność niektórych urządzeń do tworzenia spójnych składniowo i semantycznie tekstów nie jest gwarancją rzetelności. Mówi się, że są one w stanie „oszałamiać”, to znaczy generować stwierdzenia, które na pierwszy rzut oka wydają się wiarygodne, ale w rzeczywistości są bezpodstawne lub zdradzają uprzedzenia. Stanowi to poważny problem, gdy sztuczna inteligencja jest wykorzystywana w kampaniach dezinformacyjnych, które rozpowszechniają fałszywe wiadomości i prowadzą do rosnącej nieufności wobec środków przekazu. Poufność, posiadanie danych i własność intelektualna to inne obszary, w których omawiane technologie stwarzają poważne zagrożenia, do których dochodzą dalsze negatywne konsekwencje ich niewłaściwego wykorzystania, takie jak: dyskryminacja, ingerencja w procesy wyborcze, szerzenie się modelu społeczeństwa, które monitoruje i kontroluje ludzi, wykluczenie cyfrowe, i pogłębianie się indywidualizmu coraz bardziej oderwanego od zbiorowości. Wszystkie te czynniki mogą podsycać konflikty i utrudniać pokój.</p>\n<p style=\"text-align: left;\">4. <i>Znaczenie ograniczeń w paradygmacie technokratycznym</i></p>\n<p>Nasz świat jest zbyt rozległy, różnorodny i złożony, by można go było w pełni poznać i sklasyfikować. Ludzki umysł nigdy nie będzie w stanie wyczerpać jego bogactwa, nawet z pomocą najbardziej zaawansowanych algorytmów. Nie oferują one bowiem gwarantowanych prognoz przyszłości, a jedynie statystyczne przybliżenia. Nie wszystko można przewidzieć, nie wszystko można obliczyć; w końcu „rzeczywistość przewyższa ideę” <a class=\"cleaner\" href=\"#_ftn9\" name=\"_ftnref9\">[9]</a> i bez względu na to, jak wspaniałe mogą być nasze zdolności obliczeniowe, zawsze pozostanie niedostępna reszta, która wymyka się wszelkim próbom kwantyfikacji.</p>\n<p>Ponadto duża ilość danych analizowanych przez sztuczne inteligencje nie jest sama w sobie gwarancją bezstronności. Kiedy algorytmy ekstrapolują informacje, zawsze istnieje ryzyko, że je wypaczą, powielając niesprawiedliwości i uprzedzenia środowisk, z których pochodzą. Im bardziej stają się szybsze i złożone, tym trudniej zrozumieć, dlaczego wyprodukowały określony rezultat.</p>\n<p>Maszyny inteligentne mogą wykonywać przypisane im zadania z coraz większą wydajnością, ale cel i znaczenie ich działań będą nadal określane lub umożliwiane przez ludzi posiadających własny świat wartości. Istnieje ryzyko, że kryteria stojące za niektórymi wyborami staną się mniej jasne, że odpowiedzialność za podejmowanie decyzji zostanie ukryta, a producenci mogą uchylać się od obowiązku działania dla dobra wspólnoty. W pewnym sensie sprzyja temu system technokratyczny, który sprzymierza ekonomię z technologią i nadaje przywilej dla kryterium wydajności, ignorując wszystko, co nie jest związane z jego doraźnymi korzyściami <a class=\"cleaner\" href=\"#_ftn10\" name=\"_ftnref10\">[10]</a>.</p>\n<p>Powinno to nas skłonić do refleksji nad aspektem, który jest bardzo często pomijany w dzisiejszej mentalności technokratycznej i wydajnościowej, jako decydujący dla rozwoju osobistego i społecznego: „poczucie ograniczeń”. Istocie ludzkiej, z definicji śmiertelnej, gdy myśli o przekroczeniu, dzięki technologii, wszelkich ograniczeń, grozi, iż będąc ogarniętą obsesją kontrolowania wszystkiego, utraci kontrolę nad sobą; w poszukiwaniu absolutnej wolności, wpadnie w spiralę dyktatury technologicznej. Rozpoznanie i zaakceptowanie własnej ograniczoności jako stworzenia, jest dla człowieka niezbędnym warunkiem osiągnięcia pełni, a raczej przyjęcia jej w darze. Natomiast w ideologicznym kontekście paradygmatu technokratycznego, ożywionego prometejskim założeniem samowystarczalności, nierówności mogą rosnąć nieproporcjonalnie, a wiedza i bogactwo gromadzić się w rękach nielicznych, z poważnym zagrożeniem dla społeczeństw demokratycznych i pokojowego współistnienia <a class=\"cleaner\" href=\"#_ftn11\" name=\"_ftnref11\">[11]</a>.</p>\n<p>5. <i>Gorące tematy dla etyki</i></p>\n<p>W przyszłości, wiarygodność osoby ubiegającej się o kredyt, przydatność danej osoby do pracy, prawdopodobieństwo recydywy osoby skazanej, lub prawo do otrzymania azylu politycznego, lub pomocy społecznej, mogą być determinowane przez systemy sztucznej inteligencji. Brak zróżnicowanych poziomów mediacji, które wprowadzają te systemy, jest szczególnie narażony na formy uprzedzeń i dyskryminacji: błędy systemowe mogą się łatwo mnożyć, powodując nie tylko niesprawiedliwość w indywidualnych przypadkach, ale także, poprzez efekt domina, rzeczywiste formy nierówności społecznej.</p>\n<p>Co więcej, czasami formy sztucznej inteligencji wydają się zdolne do wpływania na decyzje jednostek, poprzez z góry określone opcje związane z bodźcami i środkami odstraszającymi lub poprzez systemy regulujące osobiste wybory w oparciu o organizację informacji. Te formy manipulacji lub kontroli społecznej wymagają uwagi i starannego nadzoru, oraz pociągają za sobą wyraźną odpowiedzialność prawną ze strony producentów, tych, którzy je stosują, oraz władz rządowych.</p>\n<p>Poleganie na procesach automatycznych, które kategoryzują jednostki, na przykład poprzez wszechobecne wykorzystanie nadzoru lub przyjęcie systemów kredytu społecznego, może mieć również głębokie reperkusje dla tkanki obywatelskiej, ustanawiając niewłaściwe klasyfikacje wśród obywateli. Te sztuczne procesy klasyfikacji mogą również prowadzić do konfliktów władzy, ponieważ dotyczą nie tylko odbiorców wirtualnych, ale także osób z krwi i kości. Fundamentalny szacunek dla godności ludzkiej postuluje odrzucenie tego, aby utożsamiano wyjątkowość osoby ze zbiorem danych. Nie można pozwolić algorytmom: określać sposobu, w jaki rozumiemy prawa człowieka, odkładać na bok podstawowych wartości współczucia, miłosierdzia i przebaczenia lub eliminować możliwość, aby jednostka się zmieniła i pozostawiła przeszłość za sobą.</p>\n<p>W tym kontekście nie możemy nie rozważyć wpływu nowych technologii w sferze zatrudnienia: prace, które kiedyś były wyłączną domeną siły roboczej, są szybko wchłaniane przez przemysłowe zastosowania sztucznej inteligencji. Również w tym przypadku istnieje znaczne ryzyko nieproporcjonalnej przewagi nielicznych, kosztem zubożenia wielu. Poszanowanie godności pracowników i znaczenie zatrudnienia dla dobrobytu ekonomicznego osób, rodzin i społeczeństw, bezpieczeństwo pracy i sprawiedliwe płace, powinny być wysokim priorytetem dla wspólnoty międzynarodowej, ponieważ te formy technologii przenikają coraz głębiej do miejsc pracy.</p>\n<p>6. <i>Czy przekujemy miecze na lemiesze?</i></p>\n<p>W dzisiejszych czasach, patrząc na otaczający nas świat, nie sposób uciec od poważnych kwestii etycznych związanych z przemysłem zbrojeniowym. Możliwość prowadzenia operacji wojskowych za pomocą systemów zdalnie sterowanych doprowadziła do zmniejszenia percepcji zniszczeń, jakie one powodują i odpowiedzialności za ich użycie, przyczyniając się do jeszcze zimniejszego i bardziej oderwanego podejścia do ogromnej tragedii wojny. Badania nad nowymi technologiami w dziedzinie tak zwanych „śmiercionośnych autonomicznych systemów uzbrojenia”, w tym nad wykorzystaniem wojennym sztucznej inteligencji, stanowią poważny problem etyczny. Autonomiczne systemy uzbrojenia nigdy nie mogą być podmiotami odpowiedzialnymi moralnie: unikalna ludzka zdolność do moralnej oceny i etycznego podejmowania decyzji jest czymś więcej niż złożonym zestawem algorytmów, a zdolności tej nie można sprowadzać do programowania maszyny, która, choć „inteligentna”, nadal jest maszyną. Z tego powodu konieczne jest zapewnienie odpowiedniego, znaczącego i spójnego ludzkiego nadzoru nad systemami uzbrojenia.</p>\n<p>Nie możemy również lekceważyć potencjalnego ryzyka, że wyrafinowana broń wpadnie w niepowołane ręce, ułatwiając na przykład ataki terrorystyczne lub ingerencje mające na celu destabilizację prawowitych instytucji rządowych. Krótko mówiąc, świat naprawdę nie potrzebuje nowych technologii przyczyniających się do nieuczciwego rozwoju rynku i handlu bronią, promujących szaleństwo wojny. Czyniąc w ten sposób, nie tylko inteligencja, ale samo serce człowieka będzie narażone na ryzyko, że stanie się coraz bardziej „sztuczne”. Najbardziej zaawansowane aplikacje techniczne nie powinny być wykorzystywane do ułatwiania brutalnego rozwiązywania konfliktów, lecz do przygotowywania drogi do pokoju.</p>\n<p>Z bardziej pozytywnej perspektywy, gdyby sztuczna inteligencja została wykorzystana do promowania integralnego rozwoju człowieka, mogłaby wprowadzić znaczące innowacje w rolnictwie, edukacji i kulturze, poprawić standardy życia całych narodów i ludów oraz przyczynić się do wzrostu ludzkiego braterstwa i przyjaźni społecznej. Ostatecznie, to, w jaki sposób wykorzystamy ją do włączenia najmniejszych, czyli naszych najsłabszych i najbardziej potrzebujących braci i sióstr, jest miarą ukazującą nasze człowieczeństwo.</p>\n<p>Ludzkie spojrzenie i pragnienie lepszej przyszłości dla naszego świata prowadzą do potrzeby interdyscyplinarnego dialogu, mającego na celu etyczny rozwój algorytmów – <i>algor-etykę </i>– w którym wartości kierowałyby drogami nowych technologii <a class=\"cleaner\" href=\"#_ftn12\" name=\"_ftnref12\">[12]</a>. Kwestie etyczne powinny być brane pod uwagę od samego początku badań, a także na etapie testowania, projektowania, produkcji, dystrybucji i wprowadzenia na rynek. Jest to podejście etyki projektowania, w którym instytucje edukacyjne i decydenci mają do odegrania istotną rolę.</p>\n<p style=\"text-align: left;\">7. <i>Wyzwania dla edukacji</i></p>\n<p>Rozwój technologii, która szanuje i służy ludzkiej godności, ma wyraźne implikacje dla instytucji edukacyjnych i świata kultury. Zwielokrotniając możliwości komunikacji, technologie cyfrowe umożliwiły spotkania na nowe sposoby. Istnieje jednak potrzeba stałej refleksji nad rodzajem relacji, do których nas kierują. Młodzi dorastają w środowiskach kulturowych przenikniętych technologią, co nie może nie budzić wątpliwości w zakresie metod nauczania i formacji.</p>\n<p>Edukacja w zakresie korzystania z form sztucznej inteligencji powinna mieć na celu przede wszystkim promowanie krytycznego myślenia. Konieczne jest, aby użytkownicy w każdym wieku, a zwłaszcza ludzie młodzi, rozwijali umiejętność świadomego i wnikliwego korzystania z danych i treści gromadzonych w <i>sieci </i>lub tworzonych przez systemy sztucznej inteligencji. Szkoły, uniwersytety i towarzystwa naukowe są wezwane do pomocy studentom i profesjonalistom w uwzględnieniu społecznych i etycznych aspektów rozwoju i wykorzystania technologii.</p>\n<p>Formacja, w zakresie korzystania z nowych narzędzi komunikacji, powinna uwzględniać nie tylko dezinformację, fałszywe wiadomości <i></i>(tzw. <i>fake news</i>), ale także niepokojące odradzanie się „dawnych obaw, które [...] potrafiły się ukryć i umocnić swoją pozycję za nowymi technologiami” <a class=\"cleaner\" href=\"#_ftn13\" name=\"_ftnref13\">[13]</a>. Niestety, po raz kolejny musimy walczyć z „pokusą tworzenia kultury murów, wznoszenia murów [...], aby uniemożliwić [...] spotkanie z innymi kulturami, z innymi ludźmi” <a class=\"cleaner\" href=\"#_ftn14\" name=\"_ftnref14\">[14]</a>,oraz rozwój pokojowego i braterskiego współistnienia.</p>\n<p style=\"text-align: left;\">8. <i>Wyzwania dla rozwoju prawa międzynarodowego</i></p>\n<p>Globalny zasięg sztucznej inteligencji jasno pokazuje, że oprócz odpowiedzialności suwerennych państw za regulowanie jej wykorzystania we własnym kraju, decydującą rolę w zawieraniu porozumień wielostronnych oraz koordynowaniu ich stosowania i wdrażania mogą odegrać organizacje międzynarodowe <a class=\"cleaner\" href=\"#_ftn15\" name=\"_ftnref15\">[15]</a>. W związku z tym, zachęcam Wspólnotę Narodów, aby – zjednoczona – pracowała w celu przyjęcia wiążącego traktatu międzynarodowego, regulującego rozwój i wykorzystanie sztucznej inteligencji w jej różnorodnych formach. Celem regulacji powinno być, oczywiście, nie tylko zapobieganie złym praktykom, ale także zachęcanie do dobrych praktyk, stymulowanie nowych i kreatywnych koncepcji oraz ułatwianie inicjatyw osobistych i zbiorowych <a class=\"cleaner\" href=\"#_ftn16\" name=\"_ftnref16\">[16]</a>.</p>\n<p>W ostatecznym rachunku, w poszukiwaniu modeli regulacyjnych, które mogłyby zapewnić twórcom technologii cyfrowych pewien przewodnik etyczny, konieczne jest wskazanie ludzkich wartości, które powinny leżeć u podstaw wysiłków społeczeństw na rzecz sformułowania, przyjęcia i zastosowania niezbędnych ram prawnych. Prace redakcyjne nad wytycznymi w zakresie etyki, dotyczącymi produkcji form sztucznej inteligencji, nie mogą pomijać głębszych kwestii odnoszących się do sensu ludzkiego istnienia, ochrony podstawowych praw człowieka oraz dążenia do sprawiedliwości i pokoju. Ten proces etycznego i prawnego rozeznania może okazać się cenną okazją do wspólnej refleksji nad rolą, jaką technologia powinna odgrywać w naszym życiu indywidualnym i wspólnotowym, oraz w jaki sposób jej wykorzystanie może przyczynić się do stworzenia bardziej sprawiedliwego i humanitarnego świata. Z tego powodu, w debatach na temat regulacji sztucznej inteligencji powinny być brane pod uwagę głosy wszystkich zainteresowanych stron, w tym ubogich, wykluczonych i innych, którzy często pozostają nieusłyszani w globalnych procesach decyzyjnych.</p>\n<p style=\"text-align: center;\">* * * </p>\n<p>Mam nadzieję, że ta refleksja zachęci, do uczynienia wszystkiego, aby postępy w rozwoju form sztucznej inteligencji w ostateczności służyły sprawie ludzkiego braterstwa i pokoju. Nie jest to odpowiedzialność nielicznych, lecz całej rodziny ludzkiej. Pokój jest bowiem owocem relacji, które uznają i akceptują drugiego człowieka w jego niezbywalnej godności, a także owocem współpracy i zaangażowania w dążeniu do integralnego rozwoju wszystkich osób i wszystkich narodów.</p>\n<p>Na początku Nowego Roku modlę się, aby szybki rozwój form sztucznej inteligencji nie powiększył zbyt wielu nierówności i niesprawiedliwości już obecnych na świecie, ale przyczynił się do zakończenia wojen i konfliktów oraz złagodzenia wielu form cierpienia, które dotykają rodzinę ludzką. Oby chrześcijanie, wyznawcy różnych religii, oraz mężczyźni i kobiety dobrej woli, zgodnie współpracowali, żeby wykorzystać szanse i sprostać wyzwaniom stawianym przez rewolucję cyfrową, oraz przekazać przyszłym pokoleniom bardziej solidarny, sprawiedliwy i pokojowy świat.</p>\n<p><i>Watykan, 8 grudnia 2023 r.</i></p>\n<p style=\"text-align: center;\">FRANCISZEK</p>\n<p> </p>\n<hr align=\"left\" size=\"1\" width=\"33%\">\n<p> </p>\n<p><a class=\"cleaner\" href=\"#_ftnref1\" name=\"_ftn1\">[1]</a> Sobór Wat. II, Konstytucja duszp. o Kościele w świecie współczesnym, <i>Gaudium et spes</i>, 33.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref2\" name=\"_ftn2\">[2]</a> <i> Tamże</i>, 57.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref3\" name=\"_ftn3\">[3]</a> Por. Enc. <i><a href=\"https://www.vatican.va/content/francesco/pl/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#104\">Laudato si'</a> </i>(24 maja 2015), 104.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref4\" name=\"_ftn4\">[4]</a>  <i><a href=\"https://www.vatican.va/content/francesco/pl/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#114\">Tamże</a></i>, 114.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref5\" name=\"_ftn5\">[5]</a> <i> Udienza ai partecipanti all’Incontro “Minerva Dialogues”</i> (27 marzo 2023).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref6\" name=\"_ftn6\">[6]</a> Por. <i>tamże.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref7\" name=\"_ftn7\">[7]</a> Por. <a href=\"https://www.vatican.va/content/francesco/it/messages/pont-messages/2018/documents/papa-francesco_20180112_messaggio-davos2018.html\"><i>Messaggio al Presidente Esecutivo del “World Economic Forum” a Davos-Klosters</i></a> (12 gennaio 2018).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref8\" name=\"_ftn8\">[8]</a> Por. Enc. <i><a href=\"https://www.vatican.va/content/francesco/pl/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#19454\">Laudato si'</a></i>, 194; <i>Discorso ai partecipanti al Seminario “Il bene comune nell’era digitale”</i> (27 settembre 2019).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref9\" name=\"_ftn9\">[9]</a> Adhort. apost. <i><a href=\"https://www.vatican.va/content/francesco/pl/apost_exhortations/documents/papa-francesco_esortazione-ap_20131124_evangelii-gaudium.html#Rzeczywistość_jest_ważniejsza_od_idei\">Evangelii gaudium</a> </i>(24 listopada 2013), 233.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref10\" name=\"_ftn10\">[10]</a> Por. Enc. <i><a href=\"https://www.vatican.va/content/francesco/pl/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#54\">Laudato si'</a></i>, 54.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref11\" name=\"_ftn11\">[11]</a> Por. <i>Discorso ai partecipanti alla Plenaria della Pontificia Accademia per la Vita </i>(28 febbraio 2020).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref12\" name=\"_ftn12\">[12]</a> Por. <i>tamże.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref13\" name=\"_ftn13\">[13]</a> Enc. <i><a href=\"https://www.vatican.va/content/francesco/pl/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html\">Fratelli tutti</a> </i>(3 października 2020), 27.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref14\" name=\"_ftn14\">[14]</a>  <i><a href=\"https://www.vatican.va/content/francesco/pl/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html\">Tamże</a>.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref15\" name=\"_ftn15\">[15]</a> Por. <i><a href=\"https://www.vatican.va/content/francesco/pl/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html\">tamże</a></i>, 170-175.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref16\" name=\"_ftn16\">[16]</a> Por. Enc. <i><a href=\"https://www.vatican.va/content/francesco/pl/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#177\">Laudato si'</a></i>, 177.</p><div class=\"clearfix\"></div></hr></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>",
            "pt": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p style=\"text-align: center;\"><span class=\"color-text\">MENSAGEM DO SANTO PADRE<br> <b>FRANCISCO<br/> </b>PARA A CELEBRAÇÃO DO</br></span><br/> <b><span class=\"title-1-color\">DIA MUNDIAL DA PAZ</span></b></p>\n<p style=\"text-align: center;\"><span class=\"color-text\">1º DE JANEIRO DE 2024</span></p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b><i>INTELIGÊNCIA ARTIFICIAL E PAZ</i></b></p>\n<p>No início do novo ano, tempo de graça concedido pelo Senhor a cada um de nós, quero dirigir-me ao Povo de Deus, às nações, aos Chefes de Estado e de Governo, aos Representantes das diversas religiões e da sociedade civil, a todos os homens e mulheres do nosso tempo para lhes expressar os meus votos de paz.</p>\n<p>1. <i>O progresso da ciência e da tecnologia como caminho para a paz</i></p>\n<p>A Sagrada Escritura atesta que Deus deu aos homens o seu Espírito a fim de terem «sabedoria, inteligência e capacidade para toda a espécie de trabalho» (<i>Ex</i> 35, 31). A inteligência é expressão da dignidade que nos foi dada pelo Criador, que nos fez à sua imagem e semelhança (cf. <i>Gn</i> 1, 26) e nos tornou capazes, através da liberdade e do conhecimento, de responder ao seu amor. Esta qualidade fundamentalmente relacional da inteligência humana manifesta-se de modo particular na ciência e na tecnologia, que são produtos extraordinários do seu potencial criativo.</p>\n<p>Na Constituição pastoral <i><a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_po.html\">Gaudium et spes</a></i>, o Concílio Vaticano II reafirmou esta verdade, declarando que «sempre o homem procurou, com o seu trabalho e engenho, desenvolver mais a própria vida». <a class=\"cleaner\" href=\"#_ftn1\" name=\"_ftnref1\">[1]</a> Quando os seres humanos, «recorrendo à técnica», se esforçam por que a terra «se torne habitação digna para toda a humanidade», <a class=\"cleaner\" href=\"#_ftn2\" name=\"_ftnref2\">[2]</a> agem segundo o desígnio divino e cooperam com a vontade que Deus tem de levar à perfeição a criação e difundir a paz entre os povos. Assim o próprio progresso da ciência e da técnica – na medida em que contribui para uma melhor organização da sociedade humana, para o aumento da liberdade e da comunhão fraterna – leva ao aperfeiçoamento do homem e à transformação do mundo.</p>\n<p>Justamente nos alegramos e sentimos reconhecidos pelas extraordinárias conquistas da ciência e da tecnologia, graças às quais se pôs remédio a inúmeros males que afligiam a vida humana e causavam grandes sofrimentos. Ao mesmo tempo, os progressos técnico-científicos, que permitem exercer um controle – até agora inédito – sobre a realidade, colocam nas mãos do homem um vasto leque de possibilidades, algumas das quais podem constituir um risco para a sobrevivência humana e um perigo para a casa comum. <a class=\"cleaner\" href=\"#_ftn3\" name=\"_ftnref3\">[3]</a></p>\n<p>Deste modo os progressos notáveis das novas tecnologias da informação, sobretudo na esfera digital, apresentam oportunidades entusiasmantes mas também graves riscos, com sérias implicações na prossecução da justiça e da harmonia entre os povos. Por isso torna-se necessário interrogar-nos sobre algumas questões urgentes: quais serão as consequências, a médio e longo prazo, das novas tecnologias digitais? E que impacto terão elas sobre a vida dos indivíduos e da sociedade, sobre a estabilidade e a paz?</p>\n<p>2. <i>O futuro da inteligência artificial, por entre promessas e riscos</i></p>\n<p>Os progressos da informática e o desenvolvimento das tecnologias digitais, nas últimas décadas, começaram já a produzir profundas transformações na sociedade global e nas suas dinâmicas. Os novos instrumentos digitais estão a mudar a fisionomia das comunicações, da administração pública, da instrução, do consumo, dos intercâmbios pessoais e de inúmeros outros aspetos da vida diária.</p>\n<p>Além disso as tecnologias que se servem duma multiplicidade de algoritmos podem, dos vestígios digitais deixados na <i>internet</i>, extrair dados que permitem controlar os hábitos mentais e relacionais das pessoas para fins comerciais ou políticos, muitas vezes sem o seu conhecimento, limitando o exercício consciente da sua liberdade de escolha. De facto, num espaço como a <i>web</i> caraterizado por uma sobrecarga de informações, pode-se compor o fluxo de dados segundo critérios de seleção nem sempre enxergados pelo utente.</p>\n<p>Devemos recordar-nos de que a pesquisa científica e as inovações tecnológicas não estão desencarnadas da realidade nem são «neutrais», <a class=\"cleaner\" href=\"#_ftn4\" name=\"_ftnref4\">[4]</a> mas estão sujeitas às influências culturais. Sendo atividades plenamente humanas, os rumos que tomam refletem opções condicionadas pelos valores pessoais, sociais e culturais de cada época. E o mesmo se diga dos resultados que alcançam: enquanto fruto de abordagens especificamente humanas do mundo envolvente, têm sempre uma dimensão ética, intimamente ligada às decisões de quem projeta a experimentação e orienta a produção para objetivos particulares.</p>\n<p>Isto aplica-se também às formas de inteligência artificial. Desta, até ao momento, não existe uma definição unívoca no mundo da ciência e da tecnologia. A própria designação, que já entrou na linguagem comum, abrange uma variedade de ciências, teorias e técnicas destinadas a fazer com que as máquinas, no seu funcionamento, reproduzam ou imitem as capacidades cognitivas dos seres humanos. Falar de «formas de inteligência», no plural, pode ajudar sobretudo a assinalar o fosso intransponível existente entre estes sistemas, por mais surpreendentes e poderosos que sejam, e a pessoa humana: em última análise, aqueles são «fragmentários» já que têm possibilidades de imitar ou reproduzir apenas algumas funções da inteligência humana. Além disso o uso do plural destaca que tais dispositivos, muito diferentes entre si, devem ser sempre considerados como «sistemas sociotécnicos». Com efeito o seu impacto, independentemente da tecnologia de base, depende não só da projetação, mas também dos objetivos e interesses de quem os possui e de quem os desenvolve, bem como das situações em que são utilizados.</p>\n<p>Por conseguinte a inteligência artificial deve ser entendida como uma galáxia de realidades diversas e não podemos presumir a priori que o seu desenvolvimento traga um contributo benéfico para o futuro da humanidade e para a paz entre os povos. O resultado positivo só será possível se nos demonstrarmos capazes de agir de maneira responsável e respeitar valores humanos fundamentais como «a inclusão, a transparência, a segurança, a equidade, a privacidade e a fiabilidade». <a class=\"cleaner\" href=\"#_ftn5\" name=\"_ftnref5\">[5]</a></p>\n<p>E não é suficiente presumir, por parte de quem projeta algoritmos e tecnologias digitais, um empenho por agir de modo ético e responsável. É preciso reforçar ou, se necessário, instituir organismos encarregados de examinar as questões éticas emergentes e tutelar os direitos de quantos utilizam formas de inteligência artificial ou são influenciados por ela. <a class=\"cleaner\" href=\"#_ftn6\" name=\"_ftnref6\">[6]</a></p>\n<p>Assim, a imensa expansão da tecnologia deve ser acompanhada por uma adequada formação da responsabilidade pelo seu desenvolvimento. A liberdade e a convivência pacífica ficam ameaçadas, quando os seres humanos cedem à tentação do egoísmo, do interesse próprio, da ânsia de lucro e da sede de poder. Por isso temos o dever de alargar o olhar e orientar a pesquisa técnico-científica para a prossecução da paz e do bem comum, ao serviço do desenvolvimento integral do homem e da comunidade. <a class=\"cleaner\" href=\"#_ftn7\" name=\"_ftnref7\">[7]</a></p>\n<p>A dignidade intrínseca de cada pessoa e a fraternidade que nos une como membros da única família humana devem estar na base do desenvolvimento de novas tecnologias e servir como critérios indiscutíveis para as avaliar antes da sua utilização, para que o progresso digital possa verificar-se no respeito pela justiça e contribuir para a causa da paz. Os avanços tecnológicos que não conduzem a uma melhoria da qualidade de vida da humanidade inteira, antes pelo contrário agravam as desigualdades e os conflitos, nunca poderão ser considerados um verdadeiro progresso. <a class=\"cleaner\" href=\"#_ftn8\" name=\"_ftnref8\">[8]</a></p>\n<p>A inteligência artificial tornar-se-á cada vez mais importante. Os desafios que coloca não são apenas de ordem técnica, mas também antropológica, educacional, social e política. Deixa esperar, por exemplo, poupança de esforços, produção mais eficiente, transportes mais fáceis e mercados mais dinâmicos, bem como uma revolução nos processos de recolha, organização e verificação de dados. Precisamos de estar conscientes das rápidas transformações em curso e geri-las de forma a salvaguardar os direitos humanos fundamentais, respeitando as instituições e as leis que promovem o progresso humano integral. A inteligência artificial deveria estar ao serviço dum melhor potencial humano e das nossas mais altas aspirações, e não em competição com eles.</p>\n<p>3. <i>A tecnologia do futuro: máquinas que aprendem sozinhas</i></p>\n<p>Nas suas múltiplas formas, a inteligência artificial, baseada em técnicas de aprendizagem automática (<i>machine learning</i>), embora ainda numa fase pioneira, já está a introduzir mudanças notáveis no tecido das sociedades, exercendo uma influência profunda nas culturas, nos comportamentos sociais e na construção da paz.</p>\n<p>Desenvolvimentos como a aprendizagem automática (<i>machine learning</i>) ou a aprendizagem profunda (<i>deep learning</i>) levantam questões que transcendem os âmbitos da tecnologia e da engenharia e têm a ver com uma compreensão intimamente ligada ao significado da vida humana, aos processos basilares do conhecimento e à capacidade que tem a mente de alcançar a verdade.</p>\n<p>A capacidade de alguns dispositivos produzirem textos sintática e semanticamente coerentes, por exemplo, não é garantia de fiabilidade. Diz-se que podem «alucinar», isto é, gerar afirmações que à primeira vista parecem plausíveis, mas na realidade são infundadas ou preconceituosas. Isto coloca um sério problema quando a inteligência artificial é utilizada em campanhas de desinformação que espalham notícias falsas e levam a uma desconfiança crescente relativamente aos meios de comunicação. A confidencialidade, a posse dos dados e a propriedade intelectual são outros âmbitos em que as tecnologias em questão comportam graves riscos, aos quais se vêm juntar outras consequências negativas ligadas a um uso indevido, como a discriminação, a interferência nos processos eleitorais, a formação duma sociedade que vigia e controla as pessoas, a exclusão digital e a exacerbação dum individualismo cada vez mais desligado da coletividade. Todos estes fatores correm o risco de alimentar os conflitos e obstaculizar a paz.</p>\n<p>4. <i>O sentido do limite, no paradigma tecnocrático</i></p>\n<p>O nosso mundo é demasiado vasto, variado e complexo para ser completamente conhecido e classificado. A mente humana nunca poderá esgotar a sua riqueza, nem sequer com a ajuda dos algoritmos mais avançados. De facto, estes não oferecem previsões garantidas do futuro, mas apenas aproximações estatísticas. Nem tudo pode ser previsto, nem tudo pode ser calculado; no fim de contas, «a realidade é superior à ideia» <a class=\"cleaner\" href=\"#_ftn9\" name=\"_ftnref9\">[9]</a> e, por mais prodigiosa que seja a nossa capacidade de calcular, haverá sempre um resíduo inacessível que escapa a qualquer tentativa de quantificação.</p>\n<p>Além disso, a grande quantidade de dados analisados pelas inteligências artificiais não é, por si só, garantia de imparcialidade. Quando os algoritmos extrapolam informações, correm sempre o risco de as distorcer, replicando as injustiças e os preconceitos dos ambientes onde têm origem. Quanto mais rápidos e complexos eles se tornam, mais difícil é compreender por que produziram um determinado resultado.</p>\n<p>As máquinas inteligentes podem desempenhar as tarefas que lhes são atribuídas com uma eficiência cada vez maior, mas a finalidade e o significado das suas operações continuarão a ser determinados ou capacitados por seres humanos com o seu próprio universo de valores. O risco é que os critérios subjacentes a certas escolhas se tornem menos claros, que a responsabilidade de decisão seja ocultada e que os produtores possam subtrair-se à obrigação de agir para o bem da comunidade. Em certo sentido, isto é favorecido pelo sistema tecnocrático, que alia a economia à tecnologia e privilegia o critério da eficiência, tendendo a ignorar tudo o que não esteja ligado aos seus interesses imediatos. <a class=\"cleaner\" href=\"#_ftn10\" name=\"_ftnref10\">[10]</a></p>\n<p>Isto deve fazer-nos refletir sobre um aspeto transcurado frequentemente na atual mentalidade tecnocrática e eficientista, mas decisivo para o desenvolvimento pessoal e social: o «sentido do limite». Com efeito o ser humano, mortal por definição, pensando em ultrapassar todo o limite mediante a técnica, corre o risco, na obsessão de querer controlar tudo, de perder o controle sobre si mesmo; na busca duma liberdade absoluta, de cair na espiral duma ditadura tecnológica. Reconhecer e aceitar o próprio limite de criatura é condição indispensável para que o homem alcance ou, melhor, acolha a plenitude como uma dádiva; ao passo que, no contexto ideológico dum paradigma tecnocrático animado por uma prometeica presunção de autossuficiência, as desigualdades poderiam crescer sem medida, e o conhecimento e a riqueza acumular-se nas mãos de poucos, com graves riscos para as sociedades democráticas e uma coexistência pacífica. <a class=\"cleaner\" href=\"#_ftn11\" name=\"_ftnref11\">[11]</a></p>\n<p>5. <i>Temas quentes para a ética</i></p>\n<p>No futuro, a fiabilidade de quem solicita um mútuo, a idoneidade dum indivíduo para determinado emprego, a possibilidade de reincidência dum condenado ou o direito a receber asilo político ou assistência social poderão ser determinados por sistemas de inteligência artificial. A falta de níveis diversificados de mediação que tais sistemas introduzem está particularmente exposta a formas de preconceito e discriminação: os erros do sistema podem multiplicar-se facilmente, gerando não só injustiças em casos individuais, mas também, por efeito dominó, verdadeiras formas de desigualdade social.</p>\n<p>Além disso, por vezes, as formas de inteligência artificial parecem capazes de influenciar as decisões dos indivíduos através de opções predeterminadas associadas a estímulos e dissuasões, ou então através de sistemas de regulação das opções pessoais baseados na organização das informações. Estas formas de manipulação ou controle social requerem atenção e vigilância cuidadosas, implicando uma clara responsabilidade legal por parte dos produtores, de quem os contrata e das autoridades governamentais.</p>\n<p>O ato de se confiar a processos automáticos que dispõem os indivíduos por categorias, por exemplo, através dum uso invasivo da vigilância ou da adoção de sistemas de crédito social, poderia ter repercussões profundas também no tecido civil, estabelecendo classificações inadequadas entre os cidadãos. E estes processos artificiais de classificação poderiam levar também a conflitos de poder, envolvendo não apenas destinatários virtuais, mas também pessoas de carne e osso. O respeito fundamental pela dignidade humana requer a rejeição de que a unicidade da pessoa seja identificada com um conjunto de dados. Não se deve permitir que os algoritmos determinem o modo como entendemos os direitos humanos, ponham de lado os valores essenciais da compaixão, da misericórdia e do perdão, ou eliminem a possibilidade de um indivíduo mudar e deixar para trás o passado.</p>\n<p>Neste contexto, não podemos deixar de considerar o impacto das novas tecnologias no âmbito laboral: trabalhos, que outrora eram prerrogativa exclusiva da mão-de-obra humana, acabam rapidamente absorvidos pelas aplicações industriais da inteligência artificial. Também neste caso, há substancialmente o risco duma vantagem desproporcionada para poucos à custa do empobrecimento de muitos.  A Comunidade Internacional, ao ver como tais formas de tecnologia penetram cada vez mais profundamente nos locais de trabalho, deveria considerar como alta prioridade o respeito pela dignidade dos trabalhadores e a importância do emprego para o bem-estar económico das pessoas, das famílias e das sociedades, a estabilidade dos empregos e a equidade dos salários.</p>\n<p>6. <i>Transformaremos as espadas em relhas de arado?</i></p>\n<p>Nestes dias, contemplando o mundo que nos rodeia, não se pode ignorar as graves questões éticas relacionadas com o setor dos armamentos. A possibilidade de efetuar operações militares através de sistemas de controle remoto levou a uma perceção menor da devastação por eles causada e da responsabilidade da sua utilização, contribuindo para uma abordagem ainda mais fria e destacada da imensa tragédia da guerra. A pesquisa sobre as tecnologias emergentes no setor dos chamados «sistemas de armas letais autónomas», incluindo a utilização bélica da inteligência artificial, é um grave motivo de preocupação ética. Os sistemas de armas autónomos nunca poderão ser sujeitos moralmente responsáveis: a exclusiva capacidade humana de julgamento moral e de decisão ética é mais do que um conjunto complexo de algoritmos, e tal capacidade não pode ser reduzida à programação duma máquina que, por mais «inteligente» que seja, permanece sempre uma máquina. Por esta razão, é imperioso garantir uma supervisão humana adequada, significativa e coerente dos sistemas de armas.</p>\n<p>Também não podemos ignorar a possibilidade de armas sofisticadas caírem em mãos erradas, facilitando, por exemplo, ataques terroristas ou intervenções visando desestabilizar instituições legítimas de Governo. Em resumo, o mundo não precisa realmente que as novas tecnologias contribuam para o iníquo desenvolvimento do mercado e do comércio das armas, promovendo a loucura da guerra. Ao fazê-lo, não só a inteligência, mas também o próprio coração do homem, correrá o risco de se tornar cada vez mais «artificial». As aplicações técnicas mais avançadas não devem ser utilizadas para facilitar a resolução violenta dos conflitos, mas para pavimentar os caminhos da paz.</p>\n<p>Numa ótica mais positiva, se a inteligência artificial fosse utilizada para promover o desenvolvimento humano integral, poderia introduzir inovações importantes na agricultura, na instrução e na cultura, uma melhoria do nível de vida de inteiras nações e povos, o crescimento da fraternidade humana e da amizade social. Em última análise, a forma como a utilizamos para incluir os últimos, isto é, os irmãos e irmãs mais frágeis e necessitados, é a medida reveladora da nossa humanidade.</p>\n<p>Um olhar humano e o desejo dum futuro melhor para o nosso mundo levam à necessidade dum diálogo interdisciplinar voltado para um desenvolvimento ético dos algoritmos – a <i>algor-etica</i> -, em que sejam os valores a orientar os percursos das novas tecnologias. <a class=\"cleaner\" href=\"#_ftn12\" name=\"_ftnref12\">[12]</a> As questões éticas deveriam ser tidas em consideração desde o início da pesquisa, bem como nas fases de experimentação, projetação, produção, distribuição e comercialização. Esta é a abordagem da ética da projetação, na qual as instituições educativas e os responsáveis pelo processo de decisão têm um papel essencial a desempenhar.</p>\n<p>7. <i>Desafios para a educação</i></p>\n<p>O desenvolvimento duma tecnologia que respeite e sirva a dignidade humana tem implicações claras para as instituições educativas e para o mundo da cultura. Ao multiplicar as possibilidades de comunicação, as tecnologias digitais permitiram encontrar-se de novas formas. Todavia continua a ser necessária uma reflexão contínua sobre o tipo de relações para onde nos estão encaminhando. Os jovens estão a crescer em ambientes culturais impregnados de tecnologia, o que não pode deixar de pôr em causa os métodos de ensino e formação.</p>\n<p>A educação para o uso de formas de inteligência artificial deveria visar sobretudo a promoção do pensamento crítico. É necessário que os utentes das várias idades, mas principalmente os jovens, desenvolvam uma capacidade de discernimento no uso de dados e conteúdos recolhidos na <i>web</i> ou produzidos por sistemas de inteligência artificial. As escolas, as universidades e as sociedades científicas são chamadas a ajudar os estudantes e profissionais a assumir os aspetos sociais e éticos do progresso e da utilização da tecnologia.</p>\n<p>A formação no uso dos novos instrumentos de comunicação deveria ter em conta não só a desinformação, as notícias falsas, mas também a recrudescência preocupante de «medos ancestrais (...) que souberam esconder-se e revigorar-se por detrás das novas tecnologias». <a class=\"cleaner\" href=\"#_ftn13\" name=\"_ftnref13\">[13]</a> Infelizmente, encontramo-nos mais uma vez a combater «a tentação de fazer uma cultura dos muros, de erguer os muros (…), para impedir este encontro com outras culturas, com outras pessoas» <a class=\"cleaner\" href=\"#_ftn14\" name=\"_ftnref14\">[14]</a> e o desenvolvimento duma coexistência pacífica e fraterna.</p>\n<p>8. <i>Desafios para o desenvolvimento do direito internacional</i></p>\n<p>O alcance global da inteligência artificial deixa claro que, juntamente com a responsabilidade dos Estados soberanos de regular a sua utilização internamente, as Organizações Internacionais podem desempenhar um papel decisivo na obtenção de acordos multilaterais e na coordenação da sua aplicação e implementação. <a class=\"cleaner\" href=\"#_ftn15\" name=\"_ftnref15\">[15]</a> A este respeito, exorto a Comunidade das Nações a trabalhar unida para adotar um tratado internacional vinculativo, que regule o desenvolvimento e o uso da inteligência artificial nas suas variadas formas. Naturalmente o objetivo da regulamentação não deveria ser apenas a prevenção de más aplicações, mas também o incentivo às boas aplicações, estimulando abordagens novas e criativas e facilitando iniciativas pessoais e coletivas. <a class=\"cleaner\" href=\"#_ftn16\" name=\"_ftnref16\">[16]</a></p>\n<p>Em última análise, na busca de modelos normativos que possam fornecer uma orientação ética aos criadores de tecnologias digitais, é indispensável identificar os valores humanos que deveriam estar na base dos esforços das sociedades para formular, adotar e aplicar os quadros legislativos necessários. O trabalho de elaboração de diretrizes éticas para a produção de formas de inteligência artificial não pode prescindir da consideração de questões mais profundas relativas ao significado da existência humana, à proteção dos direitos humanos fundamentais, à busca da justiça e da paz. Este processo de discernimento ético e jurídico pode revelar-se preciosa ocasião para uma reflexão compartilhada sobre o papel que a tecnologia deveria ter na nossa vida individual e comunitária e sobre a forma como a sua utilização possa contribuir para a criação dum mundo mais equitativo e humano. Por este motivo, nos debates sobre a regulamentação da inteligência artificial, dever-se-ia ter em conta as vozes de todas as partes interessadas, incluindo os pobres, os marginalizados e outros que muitas vezes permanecem ignorados nos processos de decisão globais.</p>\n<p style=\"text-align: center;\">* * *</p>\n<p>Espero que esta reflexão encoraje a fazer com que os progressos no desenvolvimento de formas de inteligência artificial sirvam, em última análise, a causa da fraternidade humana e da paz. Não é responsabilidade de poucos, mas da família humana inteira. De facto, a paz é fruto de relações que reconhecem e acolhem o outro na sua dignidade inalienável, e de cooperação e compromisso na busca do desenvolvimento integral de todas as pessoas e de todos os povos.</p>\n<p>No início do novo ano, a minha oração é que o rápido desenvolvimento de formas de inteligência artificial não aumente as já demasiadas desigualdades e injustiças presentes no mundo, mas contribua para pôr fim às guerras e conflitos e para aliviar muitas formas de sofrimento que afligem a família humana. Possam os fiéis cristãos, os crentes das várias religiões e os homens e mulheres de boa vontade colaborar harmoniosamente para aproveitar as oportunidades e enfrentar os desafios colocados pela revolução digital, e entregar às gerações futuras um mundo mais solidário, justo e pacífico.</p>\n<p>Vaticano, 8 de dezembro de 2023.</p>\n<p style=\"text-align: center;\"><i>Francisco</i></p>\n<p> </p>\n<p> </p>\n<hr align=\"left\" size=\"1\" width=\"33%\">\n<p><a class=\"cleaner\" href=\"#_ftnref1\" name=\"_ftn1\">[1]</a>N. 33.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref2\" name=\"_ftn2\">[2]</a> <i>Ibid.</i>, 57.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref3\" name=\"_ftn3\">[3]</a>Cf. Francisco, Carta enc. <i><a href=\"https://www.vatican.va/content/francesco/pt/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#104\">Laudato si’</a></i> (24/V/2015), 104.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref4\" name=\"_ftn4\">[4]</a>Cf. <i><a href=\"https://www.vatican.va/content/francesco/pt/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#114\">ibid</a>.</i>, 114.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref5\" name=\"_ftn5\">[5]</a>Francisco,  <i><a href=\"https://www.vatican.va/content/francesco/pt/speeches/2023/march/documents/20230327-minerva-dialogues.html\">Discurso aos participantes no Encontro dos «Minerva Dialogues»</a></i> (27/III/2023).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref6\" name=\"_ftn6\">[6]</a>Cf. <i>ibid.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref7\" name=\"_ftn7\">[7]</a>Cf. Francisco, <a href=\"https://www.vatican.va/content/francesco/it/messages/pont-messages/2018/documents/papa-francesco_20180112_messaggio-davos2018.html\"><i>Mensagem ao Presidente Executivo do «</i>World Economic Forum<i>» em Davos-Klosters</i></a> (12/I/2018).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref8\" name=\"_ftn8\">[8]</a>Cf. Carta enc. <i><a href=\"https://www.vatican.va/content/francesco/pt/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#194\">Laudato si’</a></i>, 194; Francisco,  <i><a href=\"https://www.vatican.va/content/francesco/pt/speeches/2019/september/documents/papa-francesco_20190927_eradigitale.html\">Discurso aos participantes no Seminário «O bem comum na era digital»</a></i> (27/IX/2019).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref9\" name=\"_ftn9\">[9]</a>Francisco,Exort. ap. <i>Evangelii gaudium</i> (24/XI/2013), 233.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref10\" name=\"_ftn10\">[10]</a>Cf. Carta enc. <i><a href=\"https://www.vatican.va/content/francesco/pt/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#54\">Laudato si’</a></i>, 54.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref11\" name=\"_ftn11\">[11]</a>Cf. Francisco, <i><a href=\"https://www.vatican.va/content/francesco/pt/speeches/2020/february/documents/papa-francesco_20200228_accademia-perlavita.html\">Discurso aos participantes na Plenária da Pontifícia Academia em prol da Vida</a> </i>(28/II/2020).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref12\" name=\"_ftn12\">[12]</a>Cf. <i>ibid.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref13\" name=\"_ftn13\">[13]</a>Francisco, Carta enc. <i><a href=\"https://www.vatican.va/content/francesco/pt/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#27\">Fratelli tutti</a> </i>(03/X/2020), 27.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref14\" name=\"_ftn14\">[14]</a>Cf. <i><a href=\"https://www.vatican.va/content/francesco/pt/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#27\">ibid</a>.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref15\" name=\"_ftn15\">[15]</a>Cf. <i><a href=\"https://www.vatican.va/content/francesco/pt/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#170\">ibid</a>.</i>, 170-175.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref16\" name=\"_ftn16\">[16]</a>Cf. Carta enc. <i><a href=\"https://www.vatican.va/content/francesco/pt/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#177\">Laudato si’</a></i>, 177.</p>\n<p> </p><div class=\"clearfix\"></div></hr></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>",
            "ru": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p style=\"text-align: center;\">ПОСЛАНИЕ<br/>\n<b>СВЯТЕЙШЕГО ОТЦА ФРАНЦИСКА</b><br/>\n<b><span class=\"title-1-color\">НА LVII ВСЕМИРНЫЙ ДЕНЬ МИРА</span></b></p>\n<p style=\"text-align: center;\"><span class=\"color-text\">1 ЯНВАРЯ 2024 ГОДА</span></p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b><i>Искусственный интеллект и мир</i></b></p>\n<p>В начале нового года, времени благодати, которое Господь дарует каждому из нас, я хочу обратиться к Народу Божьему, нациям, главам государств и правительств, представителям различных религий и гражданского общества, а также ко всем людям нашего времени с наилучшими пожеланиями мира.</p>\n<p style=\"text-align: left;\">1.   <i>Научно-технический прогресс как путь к миру </i> </p>\n<p>Священное Писание свидетельствует, что Бог наделил людей Своим Духом, дабы они обладали «мудростью, разумением и ведением и всяким искусством» (Исх 35,31). Разум есть выражение достоинства, дарованного нам Творцом, Который создал нас по Своему образу и подобию (см. Быт 1,26) и позволил свободно и сознательно отвечать на Его любовь. Наука и техника особым образом проявляют это главным образом межличностное качество человеческого интеллекта: они являются выдающимися плодами его творческого потенциала.</p>\n<p>В пастырской конституции <i>Gaudium et Spes</i> Второй Ватиканский собор подтвердил эту истину, заявив, что «своим трудом и дарованием человек всегда старался расширить рамки собственной жизни» <a class=\"cleaner\" href=\"#_ftn1\" name=\"_ftnref1\">[1]</a>. Когда люди «с помощью технологий» стремятся сделать землю «достойным местом обитания всей человеческой семьи» <a class=\"cleaner\" href=\"#_ftn2\" name=\"_ftnref2\">[2]</a>, они действуют согласно замыслу Бога и сотрудничают с Его волей, чтобы довести творение до конца и установить мир между народами. Также научно-технический прогресс – в той мере, в какой он способствует благоустройству человеческого общества, росту свободы и братского общения, – ведёт к совершенствованию человека и преобразованию мира.</p>\n<p>Мы по праву радуемся и признательны за впечатляющие достижения науки и техники, благодаря которым были устранены неисчислимые беды, причинявшие человеческой жизни тяжкие страдания. В то же время научно-технический прогресс, позволяя осуществлять беспрецедентный доселе контроль над реальностью, вручает человеку огромное количество возможностей, некоторые из которых могут представлять опасность для нашего выживания и угрозу для общего дома <a class=\"cleaner\" href=\"#_ftn3\" name=\"_ftnref3\">[3]</a>.</p>\n<p>Поразительные достижения новых информационных технологий, особенно в цифровой сфере, открывают захватывающие возможности и таят в себе серьёзные риски, значительно влияя на стремление к справедливости и гармонии между народами. Поэтому необходимо задать ряд неотложных вопросов. Каковы будут среднесрочные и долгосрочные последствия новых цифровых технологий? Какое влияние они окажут на жизнь отдельных людей и общества, на международную стабильность и мир?</p>\n<p style=\"text-align: left;\">2.   <i>Будущее искусственного интеллекта: между перспективами и риском</i></p>\n<p>Прогресс в области информатики и развитие цифровых технологий в последние десятилетия уже привели к глубоким преобразованиям в глобальном обществе и его динамике. Новые цифровые инструменты меняют облик коммуникаций, государственного управления, образования, потребления, взаимоотношений и бесчисленных других аспектов повседневной жизни.</p>\n<p>Кроме того, технологии, использующие множество алгоритмов, могут извлекать из цифровых следов в <i>Интернете</i> данные, которые позволяют контролировать мыслительные и межличностные привычки людей в коммерческих или политических целях, часто без их ведома, тем самым ограничивая их сознательное осуществление свободы выбора. Действительно, в таком пространстве, как <i>Интернет</i>, характеризующемся информационной перегрузкой, они могут структурировать поток данных согласно критериям отбора, не всегда осознаваемым пользователем.</p>\n<p>Необходимо помнить, что научные исследования и технологические инновации не оторваны от реальности и «не нейтральны» <a class=\"cleaner\" href=\"#_ftn4\" name=\"_ftnref4\">[4]</a>,а подвержены культурному влиянию. Являясь целиком человеческой деятельностью, направления их развития отражают выбор, обусловленный личными, социальными и культурными ценностями той или иной эпохи. То же самое относится к их достижениям: являясь результатом специфически человеческого подхода к окружающему миру, они всегда имеют этическое измерение, тесно связанное с решениями тех, кто разрабатывает эксперименты и направляет производство к определённым целям.</p>\n<p>Это относится и к разновидностям искусственного интеллекта. На сегодняшний день в мире науки и техники не существует единого определения данного понятия. Сам термин, уже вошедший в обиход, охватывает целый ряд наук, теорий и методов, направленных на то, чтобы машины воспроизводили или имитировали в своей работе когнитивные способности человека. Выражение «формы интеллекта» во множественном числе помогает прежде всего подчеркнуть непреодолимый разрыв, существующий между этими системами – какими бы удивительными и мощными они ни были – и человеческой личностью: в конечном итоге они «фрагментарны» в том смысле, что могут лишь имитировать или воспроизводить определённые функции человеческого интеллекта. Использование множественного числа также подчёркивает, что эти весьма разные устройства всегда нужно рассматривать как «социотехнические системы». Ведь влияние любого устройства искусственного интеллекта, независимо от лежащей в его основе технологии, зависит не только от его проектирования, но и от целей и интересов его владельцев и разработчиков, а также от ситуаций, в которых он будет применяться.</p>\n<p>Таким образом, искусственный интеллект следует воспринимать как галактику различных реалий, и мы не можем априори считать, что его развитие внесёт благотворный вклад в будущее человечества и в мир между народами. Такой положительный результат будет возможен лишь в том случае, если мы будем действовать ответственно и уважать такие фундаментальные человеческие ценности, как «инклюзивность, прозрачность, безопасность, справедливость, конфиденциальность и надёжность» <a class=\"cleaner\" href=\"#_ftn5\" name=\"_ftnref5\">[5]</a>.</p>\n<p>Недостаточно также полагать, что разработчики алгоритмов и цифровых технологий будут действовать этично и ответственно. Необходимо укрепить или, при необходимости, создать органы для изучения возникающих этических проблем и защиты прав тех, кто использует формы искусственного интеллекта или подвергается их влиянию <a class=\"cleaner\" href=\"#_ftn6\" name=\"_ftnref6\">[6]</a>.</p>\n<p>Поэтому колоссальное распространение технологий должно сопровождаться надлежащей подготовкой к ответственности за их развитие. Свобода и мирное сосуществование оказываются под угрозой, когда люди поддаются соблазну эгоизма, корысти, стремления к прибыли и жажды власти. Поэтому необходимо расширить взгляд и направить научно-технические исследования на достижение мира и общего блага, в интересах целостного развития человека и общества <a class=\"cleaner\" href=\"#_ftn7\" name=\"_ftnref7\">[7]</a>.</p>\n<p>Неотъемлемое достоинство каждого человека и братство, связывающее нас как членов единой человеческой семьи, должны лежать в основе развития новых технологий и служить неоспоримыми критериями их оценки перед использованием, чтобы цифровой прогресс происходил с соблюдением справедливости и способствовал делу мира. Технические разработки, которые не ведут к улучшению качества жизни всего человечества, а, напротив, усугубляют неравенство и конфликты, никогда не смогут считаться подлинным прогрессом <a class=\"cleaner\" href=\"#_ftn8\" name=\"_ftnref8\">[8]</a>.</p>\n<p>Искусственный интеллект будет приобретать всё большее значение. Вызовы, которые он ставит перед собой, носят не только технический, но и антропологический, образовательный, социальный и политический характер. Он обещает, например, освобождение от рутинной работы, более эффективное производство, облегчённую транспортировку и более динамичные рынки, а также революцию в процессах сбора, организации и проверки данных. Мы должны осознавать стремительность происходящих преобразований и управлять ими таким образом, чтобы обеспечить защиту основных прав человека, уважая институты и законы, способствующие целостному развитию человечества. Искусственный интеллект призван служить лучшему человеческому потенциалу и нашим самым высоким устремлениям, а не конкурировать с ними.</p>\n<p style=\"text-align: left;\">3.   <i>Технология будущего: самообучающиеся машины</i></p>\n<p>В своих многочисленных формах искусственный интеллект, основанный на методах машинного обучения (<i>machine learning</i>), хотя и находится на этапе становления, уже вносит значительные изменения в структуру общества, оказывая глубокое влияние на культуру, социальное поведение и миростроительство.</p>\n<p>Такие разработки, как машинное обучение (<i>machine learning)</i> или глубокое обучение (<i>deep learning</i>), поднимают вопросы, которые выходят за рамки технологий и инженерии и тесно связаны с пониманием смысла человеческой жизни, основными процессами познания и способностью разума постигать истину.</p>\n<p>Например, умение некоторых устройств создавать синтаксически и семантически связные тексты не является гарантией их надёжности. Считается, что они могут «галлюцинировать», то есть генерировать утверждения, которые на первый взгляд кажутся правдоподобными, но на самом деле являются необоснованными или содержат предвзятость. Создаёт серьёзную проблему использование искусственного интеллекта в кампаниях по дезинформации, распространяющих фальшивые новости и умножающих недоверие к СМИ. Конфиденциальность, владение данными и интеллектуальная собственность являются следующими областями, где технологии могут представлять потенциальную опасность. К ним добавляются и другие негативные последствия их неправильного использования, такие как дискриминация, вмешательство в избирательные процессы, слежка и контроль за населением, цифровая изоляция и обострение индивидуализма, всё больше оторванного от общества. Все эти факторы могут подпитывать конфликты и препятствовать установлению мира.</p>\n<p style=\"text-align: left;\">4.<i>   Чувство предела в технократической парадигме</i></p>\n<p>Наш мир слишком огромен, разнообразен и сложен, чтобы его можно было полностью познать и классифицировать. Человеческий разум никогда не сможет исчерпать его богатства, даже с помощью наиболее продвинутых алгоритмов. Они, по сути, не дают гарантированных прогнозов на будущее, а лишь статистические упрощения. Не всё можно предсказать, не всё можно просчитать; в конце концов, «реальность выше идеи» <a class=\"cleaner\" href=\"#_ftn9\" name=\"_ftnref9\">[9]</a> <sup><sup>[]</sup></sup>, и какими бы выдающимися ни были наши вычислительные способности, всегда существует недоступный остаток, который ускользнёт от любых попыток количественной оценки.</p>\n<p>Кроме того, гигантский объём данных, анализируемых искусственными интеллектами, сам по себе не является гарантией беспристрастности. Когда алгоритмы экстраполируют информацию, они всегда рискуют исказить её, воспроизводя несправедливость и предрассудки среды, в которой они зародились. Чем быстрее и сложнее они становятся, тем труднее понять, почему они выдают тот или иной результат.</p>\n<p>«Умные» машины могут выполнять поставленные перед ними задачи с прогрессирующей эффективностью, но цель и смысл их деятельности по-прежнему будут определяться или обеспечиваться людьми, обладающими собственной системой ценностей. Риск заключается в том, что критерии, лежащие в основе определённых решений, станут менее ясными, ответственность за их принятие будет скрыта, а производители могут уклониться от обязательств работать на благо общества. В каком-то смысле этому благоприятствует технократическая система, которая объединяет экономику с технологией и отдаёт предпочтение критерию эффективности, при этом склоняясь к игнорированию всего, что не связано с её прямыми интересами <a class=\"cleaner\" href=\"#_ftn10\" name=\"_ftnref10\">[10]</a>.</p>\n<p>Это должно заставить задуматься о том, что часто упускается из виду в современном технократическом и ориентированном на эффективность менталитете: о «чувстве предела», поскольку оно имеет решающее значение для личного и общественного развития. Человек, смертный по определению, намереваясь выйти за любые пределы с помощью технологий, рискует потерять контроль над собой в навязчивом желании контролировать всё; в поисках абсолютной свободы мы рискуем попасть в спираль «диктатуры технологии». Признание и принятие собственной ограниченности как существ – необходимое условие для достижения, а точнее, принятия самореализации как дара. Однако в идеологическом контексте технократической парадигмы, вдохновлённой прометеевой презумпцией самодостаточности, неравенство может вырасти запредельно, а знания и богатство – скопиться в руках немногих, что чревато серьёзными рисками для демократических обществ и мирного сосуществования <a class=\"cleaner\" href=\"#_ftn11\" name=\"_ftnref11\">[11]</a>.</p>\n<p>5. <i>Насущные вопросы этики</i></p>\n<p>В будущем надёжность претендента на ипотеку, пригодность человека для трудоустройства, вероятность рецидива у осуждённого, право на получение политического убежища или социальной помощи смогут определяться системами искусственного интеллекта. Отсутствие различных уровней посредничества, которое вводят эти системы, особенным образом приводит к риску предвзятости и дискриминации: системные ошибки могут легко множиться, порождая не только несправедливость в отдельных случаях, но и – в силу эффекта домино – реальные формы социального неравенства.</p>\n<p>Кроме того, порой формы искусственного интеллекта способны повлиять на решения людей с помощью заранее определённых вариантов, связанных со стимулами и сдерживающими факторами, или действуя через систему регулирования личного выбора, основанную на организации информации. Такие формы манипулирования или социального контроля требуют пристального внимания и надзора, а также предполагают чёткую юридическую ответственность со стороны их разработчиков, заказчиков и государственных органов.</p>\n<p>Полагаясь на автоматические процессы классификации людей, например, путём повсеместного наблюдения или через системы социального кредитования, можно также серьёзно повлиять на социальную структуру, устанавливая рейтинг среди граждан. Кроме того, эти искусственные процессы ранжирования могут привести к конфликтам власти, поскольку они касаются не только виртуальных пользователей, но и реальных людей. Фундаментальное уважение к человеческому достоинству требует, чтобы мы не отождествляли уникальность человека с набором данных. Нельзя допустить, чтобы алгоритмы определяли наше понимание прав человека, отбрасывали такие важнейшие человеческие ценности, как сострадание, милосердие и прощение, или исключали возможность того, что человек может измениться и оставить прошлое позади.</p>\n<p>В этом контексте нельзя не отметить влияние новых технологий на трудовые условия: рабочие места, которые раньше были прерогативой исключительно человеческого труда, быстро поглощаются промышленными приложениями искусственного интеллекта. В этом случае также существует значительный риск получения непропорционально больших выгод немногими за счет обнищания многих. Уважение достоинства трудящихся и важность занятости для экономического благосостояния отдельных людей, семей и обществ, гарантии занятости и справедливой заработной платы должны стать приоритетными для международного сообщества по мере того, как эти формы технологии всё глубже проникают на рабочие места.</p>\n<p>6.<b><i> </i></b><i>Перекуём ли мы мечи на лемехи плугов?</i></p>\n<p>В наши дни при взгляде на окружающий мир не избежать серьёзных этических вопросов, связанных с индустрией вооружений. Возможность проведения военных операций с помощью дистанционно управляемых систем привела к снижению восприятия наносимых ими разрушений, к снижению ответственности за их использование, способствуя ещё более холодному и отстранённому подходу к огромной трагедии войны. Серьёзную этическую озабоченность вызывают исследования новых технологий в области так называемых «смертоносных автономных систем вооружения», включая военное использование искусственного интеллекта. Автономные системы оружия никогда не смогут стать морально ответственными субъектами: уникальная человеческая способность к нравственному суждению и принятию этических решений – это нечто большее, чем сложный набор алгоритмов, и эта способность не может быть сведена к программированию машины, которая, какой бы «умной» она ни была, всё равно остаётся машиной. По этой причине крайне важно обеспечить адекватный, полный и последовательный человеческий надзор за системами вооружений.</p>\n<p>Также нельзя игнорировать вероятность того, что сложное оружие попадёт в чужие руки, способствуя, например, террористическим атакам или интервенциям, направленным на дестабилизацию законных государственных институтов. Одним словом, миру не нужны новые технологии, способствующие несправедливому развитию рынка оружия и торговли им, поощряющие безумие войны. При этом не только интеллект, но и само человеческое сердце рискует стать всё более «искусственным». Самые передовые технические разработки должны использоваться не для продвижения насильственного разрешения конфликтов, а чтобы прокладывать путь к миру.</p>\n<p>В более позитивной перспективе использование искусственного интеллекта для целостного развития человечества может привести к значительным инновациям в сельском хозяйстве, образовании и культуре, к повышению уровня жизни целых стран и народов, росту человеческого братства и социальной дружбы. В конечном счёте то, как мы используем искусственный интеллект в пользу наименьших, то есть наших самых слабых и нуждающихся братьев и сестёр, является показателем нашей человечности.</p>\n<p>Гуманное мировоззрение и стремление к лучшему будущему нашего мира приводят к необходимости междисциплинарного диалога, направленного на этическое развитие алгоритмов, – <i>алгорэтику</i>, – в котором именно ценности направляют пути новых технологий <a class=\"cleaner\" href=\"#_ftn12\" name=\"_ftnref12\">[12]</a>. Этические соображения должны приниматься во внимание с самого начала исследований, а также на этапах тестирования, проектирования, производства, дистрибуции и маркетинга. Таков подход этики проектирования, в котором образовательные учреждения и лица, принимающие решения, должны сыграть ключевую роль.</p>\n<p style=\"text-align: left;\">7.   <i>Вызовы для образования</i></p>\n<p>Развитие технологий, которые уважают человеческое достоинство и служат ему, имеет очевидные последствия для учебных заведений и для мира культуры. Умножая возможности коммуникации, цифровые технологии позволяют по-новому встречаться друг с другом. Однако по-прежнему необходимо размышлять о том, к каким отношениям они приводят. Молодёжь растёт в культурной среде, пронизанной технологиями, и это не может не бросать вызов методам преподавания, воспитания и обучения.</p>\n<p>Образование в области использования форм искусственного интеллекта должно быть направлено прежде всего на развитие критического мышления. Пользователям всех возрастов, особенно молодёжи, необходимо развивать способность к анализу при использовании данных и контента, собранных в <i>Интернете</i> или созданных системами искусственного интеллекта. Школы, университеты и научные сообщества призваны помочь студентам и специалистам осознать социальные и этические аспекты развития и использования технологий.</p>\n<p>Подготовка к использованию новых средств коммуникации должна учитывать не только дезинформацию, <i>фейковые новости</i>, но и тревожное возрождение «унаследованных от предков страхов, которые так и не были преодолены техническим прогрессом» <a class=\"cleaner\" href=\"#_ftn13\" name=\"_ftnref13\">[13]</a>.К сожалению, нам снова приходится бороться с «соблазном построить культуру стен и возводить стены, которые препятствуют встрече с другими культурами, с другими людьми» <a class=\"cleaner\" href=\"#_ftn14\" name=\"_ftnref14\">[14]</a>и развитию мирного и братского сосуществования.</p>\n<p style=\"text-align: left;\">8. <i>Вызовы для развития международного права</i></p>\n<p>Глобальный масштаб искусственного интеллекта делает очевидным, что, наряду с ответственностью суверенных государств за регулирование его использования внутри страны, международные организации могут сыграть решающую роль в достижении многосторонних соглашений и координации их применения и реализации <a class=\"cleaner\" href=\"#_ftn15\" name=\"_ftnref15\">[15]</a>. В связи с этим я призываю сообщество наций к совместной работе по принятию обязательного к исполнению международного договора, регулирующего разработку и использование искусственного интеллекта в его многочисленных формах. Целью такого регулирования, разумеется, должно быть не только предотвращение неудачных практик, но и поощрение эффективных практик, стимулирование новых, креативных подходов и содействие личным и коллективным инициативам <a class=\"cleaner\" href=\"#_ftn16\" name=\"_ftnref16\">[16]</a>.</p>\n<p>В поисках нормативных моделей, которые могли бы стать этическим руководством для разработчиков цифровых технологий, следует определить человеческие ценности, которые должны лежать в основе усилий общества по разработке, принятию и соблюдению необходимых законодательных рамок. Составление этических рекомендаций по созданию форм искусственного интеллекта не может обойтись без рассмотрения более глубоких вопросов о смысле человеческого существования, о защите основных прав человека, о стремлении к справедливости и миру. Этот процесс этического и правового распознания может стать ценной возможностью для совместных размышлений о том, какую роль должны играть технологии в нашей индивидуальной и общественной жизни и как их использование может способствовать созиданию более справедливого и гуманного мира. По этой причине при обсуждении вопросов регулирования искусственного интеллекта нужно учитывать мнения всех заинтересованных сторон, включая неимущих, обездоленных и других, которые часто остаются неуслышанными в глобальных процессах принятия решений.</p>\n<p style=\"text-align: center;\">* * * * *</p>\n<p>Я надеюсь, что эти размышления побудят к тому, чтобы прогресс в развитии форм искусственного интеллекта в конечном итоге послужил делу человеческого братства и мира. За это отвечают не единицы, а вся человеческая семья. Мир, по сути, является плодом отношений, в которых признаётся и приветствуется достоинство другого человека; он – плод сотрудничества и стремления к целостному развитию всех людей и народов.</p>\n<p>В начале нового года я молюсь, дабы стремительное развитие форм искусственного интеллекта не привело к умножению существующего неравенства и несправедливости, но помогло положить конец войнам и конфликтам и облегчить многие формы страданий, угнетающих человеческую семью. Пусть христиане, верующие различных религий, люди доброй воли сообща и в гармонии воспользуются возможностями и справятся с вызовами, которые бросает цифровая революция, и таким образом передадут грядущим поколениям более солидарный, справедливый и мирный мир.</p>\n<p>Из Ватикана, 8 декабря 2023 года.</p>\n<p style=\"text-align: center;\">ФРАНЦИСК</p>\n<p> </p>\n<p> </p>\n<hr align=\"left\" size=\"1\" width=\"33%\">\n<p><a class=\"cleaner\" href=\"#_ftnref1\" name=\"_ftn1\">[1]</a>N. 33.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref2\" name=\"_ftn2\">[2]</a>  <i>Там же</i>, n. 57.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref3\" name=\"_ftn3\">[3]</a>См. Энциклика <i>Laudato si'</i> (24 мая 2015 г.), 104.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref4\" name=\"_ftn4\">[4]</a>  <i>Там же</i>, 114.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref5\" name=\"_ftn5\">[5]</a>  <i>Аудиенция участникам симпозиума Minerva Dialogues </i>(27 марта 2023 г.).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref6\" name=\"_ftn6\">[6]</a> См. <i>там же.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref7\" name=\"_ftn7\">[7]</a> См. <i>Послание исполнительному президенту World Economic Forum </i>в Давосе (12 января 2018 г.).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref8\" name=\"_ftn8\">[8]</a> См. Энциклика <i>Laudato si’</i>, <i></i>194; <i>Обращение к участникам семинара «Общее благо в цифровую эпоху»</i> (27 сентября 2019 г.).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref9\" name=\"_ftn9\">[9]</a>Апост. посл. <i>Evangelii gaudium</i> (24 ноября 2013 г.), 233.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref10\" name=\"_ftn10\">[10]</a>См. Энциклика <i>Laudato si’</i>, <i></i>54.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref11\" name=\"_ftn11\">[11]</a> См. <i>Обращение к участникам пленарного заседания Папской академии защиты жизни </i>(28 февраля 2020 г.).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref12\" name=\"_ftn12\">[12]</a> См. <i>там же.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref13\" name=\"_ftn13\">[13]</a> Энциклика <i>Fratelli tutti</i> (3 октября 2020 г.), <i></i>27.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref14\" name=\"_ftn14\">[14]</a> См. <i>там же.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref15\" name=\"_ftn15\">[15]</a> См. <i>там же</i>, 170-175.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref16\" name=\"_ftn16\">[16]</a>См. Энциклика <i>Laudato si’</i>, 177.</p>\n<p> </p>\n<p> </p><div class=\"clearfix\"></div></hr></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>",
            "sl": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b><span class=\"title-1-color\"><i>Poslanica svetega očeta Frančiška<br> za 57. svetovni dan miru</br></i></span></b></p>\n<p style=\"text-align: center;\"><span class=\"color-text\">1. januar 2024</span></p>\n<p> </p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b><i>Umetna inteligenca in mir</i></b></p>\n<p> </p>\n<p>Na začetku novega leta, časa milosti, ki ga Gospod podarja vsakemu izmed nas, bi rad nagovoril Božje ljudstvo, narode, voditelje držav in vlad, predstavnike različnih verstev in civilne družbe, vse može in žene našega časa ter jim izrazil svoje voščilo miru.</p>\n<p><i>1. Napredek znanosti in tehnologije kot pot k miru</i></p>\n<p>Sveto pismo potrjuje, da je Bog ljudem dal svojega Duha, da bi imeli »modrost, razumnost in vednost za vsakršno delo« (2 Mz 35,31). Razumnost je izraz dostojanstva, ki nam ga je podaril Stvarnik, ko nas je ustvaril po svoji podobi in podobnosti (prim. 1 Mz 1,26) in nam omogočil, da na njegovo ljubezen odgovorimo s svobodo in spoznanjem. Znanost in tehnologija na poseben način kažeta na to temeljno kakovost odnosne narave človekovega razuma: sta izreden sad njegovih ustvarjalnih sposobnosti.</p>\n<p>Drugi vatikanski koncil je v Pastoralni konstituciji <i>Gaudium et spe</i>s <i> </i>to <i> </i>resnico poudaril in izjavil, da je »človek s svojim delom in duhovno močjo vedno skušal razvijati svoje življenje«. <a class=\"cleaner\" href=\"#_ftn1\" name=\"_ftnref1\">[1]</a> Ko si ljudje »s pomočjo tehnike« prizadevajo, da bi zemlja »postajala dostojno bivališče za celotno človeško družino«, <a class=\"cleaner\" href=\"#_ftn2\" name=\"_ftnref2\">[2]</a> delujejo po Božjem načrtu in sodelujejo z njegovo voljo pri dovršitvi stvarstva in širjenju miru med narodi. Tudi napredek znanosti in tehnike, kolikor prispeva k boljši urejenosti človeške družbe ter k rasti svobode in bratskega občestva, torej vodi k izboljšanju človeka in preobrazbi sveta.</p>\n<p>Upravičeno se veselimo in smo hvaležni za izredne dosežke znanosti in tehnologije, ki so pripomogli k odpravi mnogoterega zla, ki je prizadelo človeško življenje in povzročalo veliko trpljenje. Istočasno tehnološko-znanstveni napredek, ki omogoča doslej še neviden nadzor nad resničnostjo, v človekove roke polaga široko paleto možnosti, med katerimi nekatere lahko predstavljajo tveganje za preživetje in nevarnost za skupni dom. <a class=\"cleaner\" href=\"#_ftn3\" name=\"_ftnref3\">[3]</a></p>\n<p>Izjemen napredek novih informacijskih tehnologij, zlasti na digitalnem področju, predstavlja torej navdušujoče priložnosti in resna tveganja s pomembnimi posledicami za dosego  pravičnosti in za harmonijo med ljudstvi. Zato si moramo nujno postaviti nekaj vprašanj. Kakšne bodo srednjeročne in dolgoročne posledice novih digitalnih tehnologij? In kakšen vpliv bodo imele na življenje posameznikov in družbe, na mednarodno stabilnost in mir?</p>\n<p>2. <i>Prihodnost umetne inteligence med obljubami in tveganji</i></p>\n<p>Napredek informatike in razvoj digitalnih tehnologij v zadnjih desetletjih sta že začela povzročati globoke spremembe v globalnih družbah in v njenih dinamikah. Nova digitalna orodja spreminjajo podobo komunikacij, javne uprave, izobraževanja, potrošnje, medosebnih odnosov in neštetih drugih vidikov vsakdanjega življenja.</p>\n<p>Poleg tega lahko tehnologije, ki uporabljajo številne algoritme, iz digitalnih sledi, puščenih na internetu, pridobijo podatke, ki omogočajo nadzor mentalnih in odnosnostnih navad ljudi v komercialne ali politične namene, pogosto brez njihove vednosti, kar omejuje njihovo zavestno udejanjanje svobode odločanja. V spletnem prostoru, za katerega je značilna preobremenjenost z informacijami, se dejansko lahko oblikuje tok podatkov glede na izbire, ki jih uporabnik ne zazna vedno.</p>\n<p>Ne smemo pozabiti, da znanstvene raziskave in tehnološke inovacije niso vedno »nevtralne«, ločene od stvarnosti, <a class=\"cleaner\" href=\"#_ftn4\" name=\"_ftnref4\">[4]</a> ampak so podvržene kulturnim vplivom. Gre za povsem človeške dejavnosti, zato sprejete usmeritve odražajo odločitve, ki jih pogojujejo osebne, družbene in kulturne vrednote posameznega obdobja. Enako lahko rečemo za rezultate, ki jih dosegajo: kot rezultat specifično človeških pristopov do okolja, v katerem nastajajo, imajo vedno etično razsežnost, ki je tesno povezana z odločitvami tistih, ki načrtujejo poizkuse in usmerjajo proizvodnjo k določenim ciljem.</p>\n<p>To velja tudi za oblike umetne inteligence. Do danes v svetu znanosti in tehnologije nimamo enoznačne definicije zanjo. Sam pojem, ki je že stopil v splošno rabo, zajema različne znanosti, teorije in tehnike, ki so usmerjene k temu, da bi stroji pri svojem delovanju reproducirali ali posnemali spoznavne sposobnosti ljudi. Uporaba množine, torej »oblike inteligence« lahko služi temu, da poudarimo predvsem nepremostljivo razliko med temi sistemi, pa naj bodo še tako presenetljivi in vplivni, in človekom: navsezadnje so »fragmentarni«, ker lahko samo posnemajo ali reproducirajo nekatere funkcije človeške inteligence. Uporaba množine poleg tega poudarja tudi, da je treba te naprave, ki se med seboj zelo razlikujejo, vedno obravnavati kot »družbeno-tehnične sisteme«. Njihov vpliv dejansko poleg temeljne tehnologije ni odvisen samo od načrtovanja, ampak tudi od ciljev in interesov tistega, ki jih ima v lasti in jih razvija, pa tudi od situacij, v katerih se uporabljajo.</p>\n<p>Umetno inteligenco moramo torej razumeti kot galaksijo različnih resničnosti in ne moremo vnaprej predvidevati, da bo njen razvoj sam po sebi blagodejno prispeval k prihodnosti človeštva in miru med narodi. Takšen pozitiven izid bo mogoč samo, če bomo dokazali, da smo sposobni delovati odgovorno in spoštovati temeljne človeške vrednote, kot so »vključenost, preglednost, varnost, pravičnost, diskretnost in zanesljivost«. <a class=\"cleaner\" href=\"#_ftn5\" name=\"_ftnref5\">[5]</a></p>\n<p>Poleg tega ni dovolj niti predpostavljati, da bodo tisti, ki načrtujejo algoritme in digitalne tehnologije, ravnali etično in odgovorno. Treba je okrepiti ali, če je to potrebno, oblikovati organizme, pristojne za preučevanje etičnih vprašanj, ki se bodo pojavljala, in za zaščito pravic tistih, ki uporabljajo oblike umetne inteligence ali so pod njenim vplivom. <a class=\"cleaner\" href=\"#_ftn6\" name=\"_ftnref6\">[6]</a></p>\n<p>Izjemen razmah tehnologije mora zato spremljati ustrezna vzgoja k odgovornosti za njen razvoj. Svoboda in mirno sožitje sta ogrožena, kadar ljudje popustijo skušnjavi sebičnosti, osebnega interesa, želji po dobičku in žeji po oblasti. Zato smo dolžni razširiti pogled in tehnično-znanstveno raziskovanje usmeriti k prizadevanju za mir in skupno dobro, k služenju celostnemu razvoju človeka in skupnosti. <a class=\"cleaner\" href=\"#_ftn7\" name=\"_ftnref7\">[7]</a></p>\n<p>Dostojanstvo, ki je lastno vsakemu človeku, in bratstvo, ki nas povezuje kot člane ene same človeške družine, morata biti temelj razvoja novih tehnologij in služiti kot nesporni merili za njihovo ocenjevanje pred njihovo uporabo, da bo digitalni napredek lahko spoštoval pravičnost in prispeval k miru. Tehnološkega razvoja, ki ne vodi k izboljšanju kakovosti življenja vsega človeštva, ampak nasprotno povečuje neenakosti in konflikte, nikoli ne moremo imeti za pravi napredek. <a class=\"cleaner\" href=\"#_ftn8\" name=\"_ftnref8\">[8]</a></p>\n<p>Umetna inteligenca bo postajala vedno bolj pomembna. Njeni izzivi so tako tehnični, kot antropološki, vzgojni, družbeni in politični. Obljublja na primer prihranek napora, učinkovitejšo proizvodnjo, lažji transport in bolj dinamične trge, pa tudi revolucijo v procesih zbiranja, organiziranja in preverjanja podatkov. Zavedati se moramo hitrih sprememb, ki se dogajajo, in jih usmerjati tako, da bomo zavarovali temeljne človekove pravice ob spoštovanju ustanov in zakonov, ki spodbujajo celovit človekov razvoj. Umetna inteligenca mora služiti najboljšim človekovim zmožnostim in našim najvišjim pričakovanjem, ne pa tekmovati z njimi.</p>\n<p style=\"text-align: left;\">3. <i>Tehnologija prihodnosti: stroji, ki se učijo sami</i></p>\n<p>V svojih številnih oblikah umetna inteligenca, ki temelji na tehnikah samodejnega učenja [<i>machine learning</i>] in je šele v pionirski fazi, že uvaja izjemne spremembe v tkivo družb, saj globoko vpliva na kulture, družbeno ravnanje in graditev miru.</p>\n<p>Razvoj, kot sta strojno učenje<i> </i>in globoko učenje [<i>deep learning</i>], odpira vprašanja, ki presegajo področji tehnologije in inženiringa ter segajo na področje razumevanja, ki je tesno povezano s pomenom človeškega življenja, z osnovnimi procesi spoznavanja in sposobnostjo uma, da doseže resnico.</p>\n<p>Sposobnost nekaterih naprav, da na primer proizvedejo skladenjsko in pomensko dosledna besedila, ni zagotovilo zanesljivosti. Pravijo, da lahko »halucinirajo«, se pravi, da ustvarjajo trditve, ki se na prvi pogled zdijo sprejemljive, a so v resnici neutemeljene ali izražajo predsodke. To predstavlja resen problem, kadar se umetna inteligenca uporablja v dezinformacijskih kampanjah, ki širijo lažne novice in vodijo k vedno večjemu nezaupanju do medijev. Zaupnost, posedovanje podatkov in intelektualna lastnina so naslednja področja, za katera navedene tehnologije predstavljajo resna tveganja. Tem se pridružujejo negativne posledice, povezane z njihovo neprimerno uporabo, kot so diskriminacija, vmešavanje v volilne procese, krepitev družbe, ki  nadzira in kontrolira ljudi, digitalna izključenost, poglabljanje individualizma, ki  vedno bolj ločuje od skupnosti. Vsi ti dejavniki predstavljajo tveganje za podžiganje konfliktov in ovirajo mir.</p>\n<p style=\"text-align: left;\">4.<i> Občutek za mejo v tehnokratski paradigmi</i></p>\n<p>Naš svet je preobsežen, raznolik in zapleten, da bi ga lahko v celoti poznali in opredeljevali. Človeški um ne bo mogel nikoli izčrpati njegovega bogastva, tudi s pomočjo najbolj naprednih algoritmov ne. Ti namreč ne zagotavljajo točnih napovedi prihodnosti, ampak samo statistične približke. Vsega ni mogoče napovedati, vsega ni mogoče izračunati; na koncu »resničnost presega idejo« <a class=\"cleaner\" href=\"#_ftn9\" name=\"_ftnref9\">[9]</a> in ne glede na to, kako izredna je lahko naša sposobnost računanja, bo vedno obstajal nek nedosegljiv ostanek, ki se izogne vsakemu poskusu merjenja.</p>\n<p>Poleg tega velika količina podatkov, ki jih analizira umetna inteligenca, sama po sebi ni zagotovilo nepristranskosti. Ko algoritmi ekstrapolirajo informacije, so vedno v nevarnosti, da jih popačijo in s tem  ponavljajo krivice in predsodke okolij, iz katerih izvirajo. Bolj kot postajajo hitri in zapleteni, težje je razumeti, zakaj so prišli do nekega določenega rezultata.</p>\n<p>»Pametni« stroji lahko vse učinkoviteje opravljajo naloge, ki so jim dodeljene, cilj in pomen njihovega delovanja pa bodo še vedno določali ali omogočali ljudje s svojim vesoljem vrednot. Obstaja tveganje, da merila, na katerih temeljijo nekatere izbire, postanejo manj jasna, da se odgovornost za odločanje skrije in da se proizvajalci izognejo obveznosti delovanja v dobro skupnosti. V določenem smislu to podpira tehnokratski sistem, za katerega je gospodarstvo zaveznik tehnologije in ki daje prednost kriteriju učinkovitosti, pri čemer teži k neupoštevanju vsega, kar ni povezano z njegovimi neposrednimi interesi. <a class=\"cleaner\" href=\"#_ftn10\" name=\"_ftnref10\">[10]</a></p>\n<p>To nas mora spodbuditi k razmišljanju o vidiku, ki je v sedanji tehnokratski in učinkovitostni miselnosti zelo pogosto prezrt, a je odločilen za osebni in družbeni razvoj: »občutek za mejo«. Človek, ki je po definiciji umrljiv, a misli, da bo s tehniko prekoračil vsako mejo, je namreč v nevarnosti, da bo zaradi obsedenosti z željo imeti nadzor nad vsem, izgubil nadzor nad samim seboj; da bo v iskanju absolutne svobode padel v spiralo neke tehnološke diktature. Prepoznanje in sprejetje lastne meje, meje ustvarjenega bitja, je za človeka nujen pogoj za dosego ali bolje sprejetje daru polnosti. Nasprotno pa bi v ideološkem okviru tehnokratske paradigme, ki jo spodbuja prometejska prevzetnost glede samozadostnosti, neenakosti lahko čezmerno narasle, znanje in bogastvo pa bi se kopičila v rokah peščice, z velikim tveganjem za demokratične družbe in za mirno sobivanje. <a class=\"cleaner\" href=\"#_ftn11\" name=\"_ftnref11\">[11]</a></p>\n<p>5. Vroče etične teme</p>\n<p>V prihodnosti bi lahko zanesljivost posojilojemalca, primernost posameznika za določeno delo, možnost, da obsojenec ponovi kaznivo dejanje, pravico do političnega azila ali do socialne pomoči določali sistemi umetne inteligence. Pomanjkanje različnih stopenj posredovanja, ki jih ti sistemi uvajajo, je še posebej izpostavljeno različnim oblikam predsodkov in diskriminacije: sistemske napake se zlahka pomnožijo in s tem ne povzročajo samo krivice v posameznih primerih, ampak po učinku verižne reakcije tudi resnične oblike družbene neenakosti.</p>\n<p>Poleg tega se včasih zdi, da so oblike umetne inteligence sposobne vplivati na odločitve posameznikov po vnaprej določenih možnostih, ki so povezane s spodbudami in svarili, ali po sistemih za uravnavanje osebnih odločitev, ki temeljijo na organiziranju informacij. Te oblike manipulacije ali družbenega nadzora zahtevajo pozornost in skrben nadzor ter vključujejo jasno zakonsko odgovornost proizvajalcev, uporabnikov in državnih oblasti.</p>\n<p>Zanašanje na samodejne procese, ki razvrščajo posameznike, na primer z vsesplošno uporabo nadzora ali s sprejetjem sistemov družbenih bonitetnih ocen, bi lahko imelo globoke učinke tudi na družbeno tkivo in bi vzpostavilo neprimerne lestvice razvrščanja državljanov. Ti umetni procesi razvrščanja bi lahko vodili tudi do konfliktov moči, ki ne bi zadevali samo virtualnih naslovnikov, ampak realne ljudi. Temeljno spoštovanje človekovega dostojanstva zahteva zavrnitev istovetenja enkratnosti osebe zgolj s skupkom podatkov. Algoritmom ne smemo dovoliti, da bi določali, kako razumemo človekove pravice, da bi zanemarjali bistvene vrednote sočutja, usmiljenja in odpuščanja ali da bi odpravili možnost, da se posameznik lahko spremeni in pusti za seboj svojo preteklost.</p>\n<p>V tem okviru ne moremo izpustiti presoje vpliva novih tehnologij na področje dela: opravila, ki so bila nekoč izključna domena človeške delovne sile, hitro posrkajo industrijske aplikacije umetne inteligence. Tudi v tem primeru obstaja temeljna nevarnost nesorazmerne koristi za peščico na račun osiromašenja mnogih. V času, ko te oblike tehnologije prodirajo vse globlje na področje dela, bi moralo spoštovanje dostojanstva delavcev in pomembnost zaposlitve za ekonomsko blaginjo ljudi, družin in družbe, varnost zaposlitve in pravičnost plač predstavljati visoko prednostno nalogo mednarodne skupnosti.</p>\n<p>6.<b><i> </i></b><i>Bomo meče prekovali v lemeže?</i></p>\n<p>Ko v teh dneh gledamo svet okrog nas, ne moremo ubežati resnim etičnim vprašanjem, ki so povezana s panogo oboroževanja. Možnost vodenja vojaških operacij po sistemih za daljinsko vodenje je privedla do manjšega dojemanja opustošenja, ki ga povzročajo, in odgovornosti za njihovo uporabo, kar prispeva k hladnejšemu in še bolj odmaknjenemu odnosu do neizmerne tragedije vojne. Raziskovanje  tehnologij, ki se pojavljajo na področju »smrtonosnih avtonomnih oborožitvenih sistemov«, vključno z uporabo umetne inteligence v vojskovanju, so resen razlog za etično zaskrbljenost. Avtomatski oborožitveni sistemi ne bodo mogli biti nikoli moralno odgovorni subjekti: izključno človeška sposobnost moralnega presojanja in etičnega odločanja je več kot zapleten skupek algoritmov in te sposobnosti ne moremo omejiti na programiranje nekega stroja, ki ne glede na to, kako »pameten« je, še vedno ostaja zgolj stroj. Zato je treba nujno zagotoviti primeren, pomenljiv in dosleden človeški nadzor oborožitvenih sistemov.</p>\n<p>Prav tako ne smemo prezreti možnosti, da skrajno izpopolnjeno orožje konča v napačnih rokah in omogoči na primer teroristične napade ali posege, ki so namenjeni destabilizaciji zakonitih vladnih ustanov. Svet res nima nobene potrebe, da bi nove tehnologije prispevale k nepravičnemu razvoju trga in trgovine z orožjem ter spodbujale norost vojne. S takšnim ravnanjem ni v nevarnosti le človekova inteligenca, ampak tudi njegovo srce, ki tako postaja vse bolj »umetno«. Najbolj naprednih tehničnih aplikacij ne bi smeli uporabljati za omogočanje nasilnega reševanje konfliktov, ampak za tlakovanje poti miru.</p>\n<p>Če pogledamo s pozitivnega vidika, bi umetno inteligenco lahko uporabljali za spodbujanje celostnega človekovega razvoja, kar bi uvedlo pomembne izboljšave v kmetijstvu, izobraževanju in kulturi, izboljšalo življenjsko raven celotnih narodov in ljudstev, omogočilo rast človeškega bratstva in družbenega prijateljstva. Način, kako umetno inteligenco uporabimo za vključevanje najmanjših, to je najslabotnejših in najbolj potrebnih bratov in sester, kaže na stopnjo naše človečnosti.</p>\n<p>Človeški pogled in želja po boljši prihodnosti našega sveta vodita do potrebe po interdisciplinarnem dialogu, usmerjenem v etični razvoj algoritmov – k <i>algor-etiki –</i>, v kateri bodo vrednote usmerjale poti novih tehnologij. <a class=\"cleaner\" href=\"#_ftn12\" name=\"_ftnref12\">[12]</a> Etična vprašanja bomo morali upoštevati tako na začetku raziskovanja kot tudi v fazi poizkusov, načrtovanja, proizvodnje, distribucije in trženja. Gre za etični pristop k načrtovanju, v katerem imajo bistveno vlogo vzgojne ustanove in odgovorni v procesu odločanja.</p>\n<p style=\"text-align: left;\">7. <i>Izzivi na področju vzgoje</i></p>\n<p>Razvoj tehnologije, ki spoštuje človekovo dostojanstvo in mu služi, ima jasne posledice za vzgojne ustanove in svet kulture. Digitalne tehnologije so s pomnožitvijo možnosti komuniciranja omogočile nove načine srečevanja. Vendarle pa ostaja potreba po nenehnem razmisleku o načinu odnosov, h katerim nas usmerjajo. Mladi rastejo v kulturnih okoljih, ki so prežeta s tehnologijo, zato se ne moramo ne zamisliti nad metodami poučevanja in izobraževanja.</p>\n<p>Vzgoja za uporabo oblik umetne inteligence bi morala biti usmerjena predvsem v spodbujanje kritičnega mišljenja. Nujno je, da uporabniki vseh starosti, predvsem pa mladi, razvijejo sposobnost razločevanja pri uporabi podatkov in vsebin, ki so zbrani na spletu ali jih proizvajajo sistemi umetne inteligence. Šole, univerze in znanstveniki so poklicani, da pomagajo študentom in strokovnjakom usvojiti družbene in etične vidike razvoja ter uporabe tehnologije.</p>\n<p>Usposabljanje za uporabo novih komunikacijskih orodij bi moralo upoštevati ne le dezinformacije, lažne novice, ampak tudi zaskrbljujočo razširitev »atavističnih strahov« […], ki so se prikrili »in se ob novih tehnologijah okrepili«. <a class=\"cleaner\" href=\"#_ftn13\" name=\"_ftnref13\">[13]</a> Žal se moramo ponovno boriti »s skušnjavo po oblikovanju kulture zidov, zidanja zidov, s katerimi bi preprečevali srečanje z drugimi kulturami, z drugim ljudstvom« <a class=\"cleaner\" href=\"#_ftn14\" name=\"_ftnref14\">[14]</a> ter za razvijanje mirnega in bratskega sobivanja.</p>\n<p style=\"text-align: left;\">8. <i>Izzivi za razvoj mednarodnega prava</i></p>\n<p>Globalni doseg umetne inteligence jasno kaže, da imajo poleg odgovornosti suverenih držav za njeno urejanje znotraj sebe tudi mednarodne organizacije odločilno vlogo pri doseganju večstranskih dogovorov ter usklajevanju njihove uporabe in izvajanja. <a class=\"cleaner\" href=\"#_ftn15\" name=\"_ftnref15\">[15]</a> V zvezi s tem spodbujam Skupnost narodov, naj sodeluje pri sprejemanju zavezujoče mednarodne pogodbe, ki bi urejala razvoj in uporabo umetne inteligence v njenih številnih oblikah. Cilj predpisov pa seveda ne bi smel biti samo preprečevanje slabih praks, ampak tudi spodbujanje dobrih, novih in ustvarjalnih pristopov ter omogočanje osebnih in kolektivnih pobud. <a class=\"cleaner\" href=\"#_ftn16\" name=\"_ftnref16\">[16]</a></p>\n<p>Končno, v iskanju normativnih modelov, ki razvijalcem digitalnih tehnologij lahko nudijo etične smernice, je nujno določiti človeške vrednote, ki morajo biti v temelju prizadevanja družbe za oblikovanje, sprejetje in uporabo potrebnih zakonodajnih okvirov. Delo za urejanje etičnih smernic za proizvodnjo oblik umetne inteligence ne more zanemariti upoštevanja globljih vprašanj, ki zadevajo pomen človeškega bivanja, varovanje temeljnih človekovih pravic, prizadevanje za pravičnost in mir. Ta proces etičnega in pravnega razločevanja se lahko izkaže kot dragocena priložnost za skupen razmislek o vlogi, ki bi jo tehnologija morala imeti v življenju posameznika in skupnosti, in o tem, kako njena uporaba lahko prispeva k ustvarjanju bolj pravičnega in človeškega sveta. Zato bi morali v razpravah o urejanju umetne inteligence upoštevati glas vseh strani, ki jih to zadeva, vključno z ubogimi, obrobnimi in drugimi, ki v globalnih procesih odločanja pogosto ostajajo neslišani.</p>\n<p style=\"text-align: center;\">* * * * *</p>\n<p>Upam, da nas bo to razmišljanje spodbudilo k skrbi, da bo napredek v razvoju oblik umetne inteligence služil človeškemu bratstvu in miru. Ne gre samo za odgovornost nekaterih, ampak za odgovornost celotne človeške družine. Mir je namreč sad odnosov, ki priznavajo in sprejmejo bližnjega v njegovem neodtujljivem dostojanstvu, ter sodelovanja in zavzetosti pri iskanju celostnega razvoja vseh ljudi in vseh ljudstev.</p>\n<p>Na začetku novega leta molim, da hiter razvoj oblik umetne inteligence ne bi povečal v svetu že tako prevelikih neenakosti in krivic, ampak bi prispeval h končanju vojn in spopadov ter olajšanju številnih oblik trpljenja, ki pestijo človeško družino. Naj verni kristjani, verniki različnih verstev ter možje in žene dobre volje usklajeno sodelujejo, da bodo izkoristili priložnosti in se spoprijeli z izzivi, ki jih prinaša digitalna revolucija, ter prihodnjim rodovom izročili bolj solidaren, pravičen in miroljuben svet.</p>\n<p><i>Vatikan, 8. decembra 2023</i></p>\n<p style=\"text-align: center;\">FRANČIŠEK</p>\n<p> </p>\n<hr align=\"left\" size=\"1\" width=\"33%\">\n<p><a class=\"cleaner\" href=\"#_ftnref1\" name=\"_ftn1\">[1]</a> Št. 33.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref2\" name=\"_ftn2\">[2]</a> Prav tam, št.  57.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref3\" name=\"_ftn3\">[3]</a> Prim. Okrožnica <i> <a href=\"https://www.vatican.va/content/francesco/sl/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html\">Hvaljen, moj Gospod</a> </i>(24. maja 2015), št. 104.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref4\" name=\"_ftn4\">[4]</a> Prim. <i><a href=\"https://www.vatican.va/content/francesco/sl/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html\">Prav tam</a></i>, št. 114.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref5\" name=\"_ftn5\">[5]</a> <i> Avdienca za udeležence srečanja “Minerva Dialogues”</i> (27. marca 2023).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref6\" name=\"_ftn6\">[6]</a> Prim. <i>Prav tam</i>.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref7\" name=\"_ftn7\">[7]</a> Prim. <i>Pismo izvršnemu predsedniku „World Economic Forum” v Davos-Klosters</i> (12. januarja 2018).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref8\" name=\"_ftn8\">[8]</a> Prim. Okrožnica <i><a href=\"https://www.vatican.va/content/francesco/sl/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html\">Hvaljen, moj Gospod</a></i>, št. 194; Nagovor udeležencem na seminarju <i>  Skupno dobro v digitalni dobi</i> (27. septembra 2019).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref9\" name=\"_ftn9\">[9]</a> Apostolska spodbuda <i>Veselje evangelija </i>(24. novembra 2013), št. 233.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref10\" name=\"_ftn10\">[10]</a> Prim. Okrožnica <i><a href=\"https://www.vatican.va/content/francesco/sl/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html\">Hvaljen, moj Gospod</a></i>, št. 54.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref11\" name=\"_ftn11\">[11]</a> Prim. Nagovor udeležencem plenarnega zasejdana Papeške akademije za življenje <i> </i>(28. februarja 2020).</p>\n<p><a class=\"cleaner\" href=\"#_ftnref12\" name=\"_ftn12\">[12]</a> Prim. <i>Prav tam.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref13\" name=\"_ftn13\">[13]</a> Okrožnica <i><a href=\"https://www.vatican.va/content/francesco/sl/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html\">Vsi smo bratje</a> </i>(3. oktobra 2020), št. 27.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref14\" name=\"_ftn14\">[14]</a> Prim. <i><a href=\"https://www.vatican.va/content/francesco/sl/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html\">Prav tam</a>.</i></p>\n<p><a class=\"cleaner\" href=\"#_ftnref15\" name=\"_ftn15\">[15]</a> Prim. <i><a href=\"https://www.vatican.va/content/francesco/sl/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html\">Prav tam</a></i>, št. 170–175.</p>\n<p><a class=\"cleaner\" href=\"#_ftnref16\" name=\"_ftn16\">[16]</a> Prim. Okrožnica <i><a href=\"https://www.vatican.va/content/francesco/sl/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html\">Hvaljen, moj Gospod</a></i>, št. 177.</p>\n<p> </p><div class=\"clearfix\"></div></hr></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>",
            "es": "<div class=\"documento\">\n<!-- CONTENUTO DOCUMENTO -->\n<!-- TITOLO -->\n<!-- /TITOLO -->\n<!-- TESTO -->\n<div class=\"testo\">\n<div class=\"abstract text parbase vaticanrichtext\"><p style=\"text-align: center;\"><span class=\"color-text\">MENSAJE <br/>\n DE SU SANTIDAD <br/>\n<b>FRANCISCO </b><br/>\n PARA LA CELEBRACIÓN DE LA<br/>\n</span><b><span class=\"title-1-color\">57 JORNADA MUNDIAL DE LA PAZ</span></b></p>\n<p style=\"text-align: center;\"><span class=\"color-text\">1 DE ENERO DE 2024</span></p><div class=\"clearfix\"></div></div>\n<div class=\"text parbase vaticanrichtext\"><p style=\"text-align: center;\"><b><i>Inteligencia artificial y paz</i></b></p>\n<p>Al iniciar el año nuevo, tiempo de gracia que el Señor nos da a cada uno de nosotros, quisiera dirigirme al Pueblo de Dios, a las naciones, a los Jefes de Estado y de Gobierno, a los Representantes de las distintas religiones y de la sociedad civil, y a todos los hombres y mujeres de nuestro tiempo para expresarles mis mejores deseos de paz.</p>\n<p>1. <i>El progreso de la ciencia y de la tecnología como camino hacia la paz</i></p>\n<p>La Sagrada Escritura atestigua que Dios ha dado a los hombres su Espíritu para que tengan «habilidad, talento y experiencia en la ejecución de toda clase de trabajos» (<i>Ex </i>35,31). La inteligencia es expresión de la dignidad que nos ha dado el Creador al hacernos a su imagen y semejanza (cf. <i>Gn </i>1,26) y nos ha hecho capaces de responder a su amor a través de la libertad y del conocimiento. La ciencia y la tecnología manifiestan de modo particular esta cualidad fundamentalmente relacional de la inteligencia humana, ambas son producto extraordinario de su potencial creativo.</p>\n<p>En la Constitución pastoral <i><a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_sp.html\">Gaudium et spes</a></i>, <i></i>el <a href=\"https://www.vatican.va/archive/hist_councils/ii_vatican_council/index_sp.htm\">Concilio Vaticano II</a> ha insistido en esta verdad, declarando que «siempre se ha esforzado el hombre con su trabajo y con su ingenio en perfeccionar su vida». <a name=\"_ftnref1\"></a>[1] Cuando los seres humanos, «con ayuda de los recursos técnicos», se esfuerzan para que la tierra «llegue a ser morada digna de toda la familia humana», <a name=\"_ftnref2\"></a>[2] actúan según el designio de Dios y cooperan con su voluntad de llevar a cumplimiento la creación y difundir la paz entre los pueblos. Asimismo, el progreso de la ciencia y de la técnica, en la medida en que contribuye a un mejor orden de la sociedad humana y a acrecentar la libertad y la comunión fraterna, lleva al perfeccionamiento del hombre y a la transformación del mundo.</p>\n<p>Nos alegramos justamente y agradecemos las extraordinarias conquistas de la ciencia y de la tecnología, gracias a las cuales se ha podido poner remedio a innumerables males que afectaban a la vida humana y causaban grandes sufrimientos. Al mismo tiempo, los progresos técnico-científicos, haciendo posible el ejercicio de un control sobre la realidad, nunca visto hasta ahora, están poniendo en las manos del hombre una vasta gama de posibilidades, algunas de las cuales representan un riesgo para la supervivencia humana y un peligro para la casa común. <a name=\"_ftnref3\"></a>[3]</p>\n<p>Los notables progresos de las nuevas tecnologías de la información, especialmente en la esfera digital, presentan, por tanto, entusiasmantes oportunidades y graves riesgos, con serias implicaciones para la búsqueda de la justicia y de la armonía entre los pueblos. Por consiguiente, es necesario plantearse algunas preguntas urgentes. ¿Cuáles serán las consecuencias, a medio y a largo plazo, de las nuevas tecnologías digitales? ¿Y qué impacto tendrán sobre la vida de los individuos y de la sociedad, sobre la estabilidad internacional y sobre la paz?</p>\n<p>2. <i>El futuro de la inteligencia artificial entre promesas y riesgos</i></p>\n<p>Los progresos de la informática y el desarrollo de las tecnologías digitales en los últimos decenios ya han comenzado a producir profundas transformaciones en la sociedad global y en sus dinámicas. Los nuevos instrumentos digitales están cambiando el rostro de las comunicaciones, de la administración pública, de la instrucción, del consumo, de las interacciones personales y de otros innumerables aspectos de la vida cotidiana.</p>\n<p>Además, las tecnologías que usan un gran número de algoritmos pueden extraer, de los rastros digitales dejados en internet, datos que permiten controlar los hábitos mentales y relacionales de las personas con fines comerciales o políticos, frecuentemente sin que ellos lo sepan, limitándoles el ejercicio consciente de la libertad de elección. De hecho, en un espacio como la web, caracterizado por una sobrecarga de información, se puede estructurar el flujo de datos según criterios de selección no siempre percibidos por el usuario.</p>\n<p>Debemos recordar que la investigación científica y las innovaciones tecnológicas no están desencarnadas de la realidad ni son «neutrales», <a name=\"_ftnref4\"></a>[4] sino que están sujetas a las influencias culturales. En cuanto actividades plenamente humanas, las direcciones que toman reflejan decisiones condicionadas por los valores personales, sociales y culturales de cada época. Lo mismo se diga de los resultados que consiguen. Estas, precisamente en cuanto fruto de planteamientos específicamente humanos hacia el mundo circunstante, tienen siempre una dimensión ética, estrictamente ligada a las decisiones de quien proyecta la experimentación y enfoca la producción hacia objetivos particulares.</p>\n<p>Esto vale también para las formas de inteligencia artificial, para la cual, hasta hoy, no existe una definición unívoca en el mundo de la ciencia y de la tecnología. El término mismo, que ha entrado ya en el lenguaje común, abraza una variedad de ciencias, teorías y técnicas dirigidas a hacer que las máquinas reproduzcan o imiten, en su funcionamiento, las capacidades cognitivas de los seres humanos. Hablar en plural de “formas de inteligencia” puede ayudar a subrayar sobre todo la brecha infranqueable que existe entre estos sistemas y la persona humana, por más sorprendentes y potentes que sean. Estos son, a fin de cuentas, “fragmentarios”, en el sentido de que sólo pueden imitar o reproducir algunas funciones de la inteligencia humana. El uso del plural pone en evidencia además que estos dispositivos, muy distintos entre sí, se deben considerar siempre como “sistemas socio-técnicos”. En efecto, su impacto, independientemente de la tecnología de base, no sólo depende del proyecto, sino también de los objetivos y de los intereses del que los posee y del que los desarrolla, así como de las situaciones en las que se usan.</p>\n<p>La inteligencia artificial, por tanto, debe ser entendida como una galaxia de realidades distintas y no podemos presumir <i>a priori </i>que su desarrollo aporte una contribución benéfica al futuro de la humanidad y a la paz entre los pueblos. Tal resultado positivo sólo será posible si somos capaces de actuar de forma responsable y de respetar los valores humanos fundamentales como «la inclusión, la transparencia, la seguridad, la equidad, la privacidad y la responsabilidad». <a name=\"_ftnref5\"></a>[5]</p>\n<p>No basta ni siquiera suponer, de parte de quien proyecta algoritmos y tecnologías digitales, un compromiso de actuar de forma ética y responsable. Es preciso reforzar o, si es necesario, instituir organismos encargados de examinar las cuestiones éticas emergentes y de tutelar los derechos de los que utilizan formas de inteligencia artificial o reciben su influencia. <a name=\"_ftnref6\"></a>[6]</p>\n<p>La inmensa expansión de la tecnología, por consiguiente, debe ser acompañada, para su desarrollo, por una adecuada formación en la responsabilidad. La libertad y la convivencia pacífica están amenazadas cuando los seres humanos ceden a la tentación del egoísmo, del interés personal, del afán de lucro y de la sed de poder. Tenemos por ello el deber de ensanchar la mirada y de orientar la búsqueda técnico-científica hacia la consecución de la paz y del bien común, al servicio del desarrollo integral del hombre y de la comunidad. <a name=\"_ftnref7\"></a>[7]</p>\n<p>La dignidad intrínseca de cada persona y la fraternidad que nos vincula como miembros de una única familia humana, deben estar en la base del desarrollo de las nuevas tecnologías y servir como criterios indiscutibles para valorarlas antes de su uso, de modo que el progreso digital pueda realizarse en el respeto de la justicia y contribuir a la causa de la paz. Los desarrollos tecnológicos que no llevan a una mejora de la calidad de vida de toda la humanidad, sino que, por el contrario, agravan las desigualdades y los confictos, no podrán ser considerados un verdadero progreso. <a name=\"_ftnref8\"></a>[8]</p>\n<p>La inteligencia artificial será cada vez más importante. Los desafíos que plantea no son sólo técnicos, sino también antropológicos, educativos, sociales y políticos. Promete, por ejemplo, un ahorro de esfuerzos, una producción más eficiente, transportes más ágiles y mercados más dinámicos, además de una revolución en los procesos de recopilación, organización y verificación de los datos. Es necesario ser conscientes de las rápidas transformaciones que están ocurriendo y gestionarlas de modo que se puedan salvaguardar los derechos humanos fundamentales, respetando las instituciones y las leyes que promueven el desarrollo humano integral. La inteligencia artificial debería estar al servicio de un mejor potencial humano y de nuestras más altas aspiraciones, no en competencia con ellos.</p>\n<p>3. <i>La tecnología del futuro: máquinas que aprenden solas</i></p>\n<p>En sus múltiples formas la inteligencia artificial, basada en técnicas de aprendizaje automático (<i>machine learning</i>), aunque se encuentre todavía en una fase pionera, ya está introduciendo cambios notables en el tejido de las sociedades, ejercitando una profunda influencia en las culturas, en los comportamientos sociales y en la construcción de la paz.</p>\n<p>Desarrollos como el <i>machine learning </i>o como el aprendizaje profundo (<i>deep learning</i>) plantean cuestiones que trascienden los ámbitos de la tecnología y de la ingeniería y tienen que ver con una comprensión estrictamente conectada con el significado de la vida humana, los procesos básicos del conocimiento y la capacidad de la mente de alcanzar la verdad.</p>\n<p>La habilidad de algunos dispositivos para producir textos sintáctica y semánticamente coherentes, por ejemplo, no es garantía de confiabilidad. Se dice que pueden “alucinar”, es decir, generar afirmaciones que a primera vista parecen plausibles, pero que en realidad son infundadas o delatan prejuicios. Esto crea un serio problema cuando la inteligencia artificial se emplea en campañas de desinformación que difunden noticias falsas y llevan a una creciente desconfianza hacia los medios de comunicación. La confidencialidad, la posesión de datos y la propiedad intelectual son otros ámbitos en los que las tecnologías en cuestión plantean graves riesgos, a los que se añaden ulteriores consecuencias negativas unidas a su uso impropio, como la discriminación, la interferencia en los procesos electorales, la implantación de una sociedad que vigila y controla a las personas, la exclusión digital y la intensificación de un individualismo cada vez más desvinculado de la colectividad. Todos estos factores corren el riesgo de alimentar los conflictos y de obstaculizar la paz.</p>\n<p class=\"MsoNormal\" style=\"text-align: left;\">4.<i> El sentido del límite en el paradigma tecnocrático</i></p>\n<p>Nuestro mundo es demasiado vasto, variado y complejo para poder ser completamente conocido y clasificado. La mente humana nunca podrá agotar su riqueza, ni siquiera con la ayuda de los algoritmos más avanzados. Estos, de hecho, no ofrecen previsiones garantizadas del futuro, sino sólo aproximaciones estadísticas. No todo puede ser pronosticado, no todo puede ser calculado; al final «la realidad es superior a la idea» <a name=\"_ftnref9\"></a>[9] y, por más prodigiosa que pueda ser nuestra capacidad de cálculo, habrá siempre un residuo inaccesible que escapa a cualquier intento de cuantificación.</p>\n<p>Además, la gran cantidad de datos analizados por las inteligencias artificiales no es de por sí garantía de imparcialidad. Cuando los algoritmos extrapolan informaciones, siempre corren el riesgo de distorsionarlas, reproduciendo las injusticias y los prejuicios de los ambientes en los que se originan. Cuanto más veloces y complejos se vuelven, más difícil es comprender porqué han generado un determinado resultado.</p>\n<p>Las máquinas inteligentes pueden efectuar las tareas que se les asignan cada vez con mayor eficiencia, pero el fin y el significado de sus operaciones continuarán siendo determinadas o habilitadas por seres humanos que tienen un propio universo de valores. El riesgo es que los criterios que están en la base de ciertas decisiones se vuelvan menos transparentes, que la responsabilidad decisional se oculte y que los productores puedan eludir la obligación de actuar por el bien de la comunidad. En cierto sentido, esto es favorecido por el sistema tecnocrático, que alía la economía con la tecnología y privilegia el criterio de la eficiencia, tendiendo a ignorar todo aquello que no está vinculado con sus intereses inmediatos. <a name=\"_ftnref10\"></a>[10]</p>\n<p>Esto debe hacernos reflexionar sobre el “sentido del límite”, un aspecto a menudo descuidado en la mentalidad actual, tecnocrática y eficientista, y sin embargo decisivo para el desarrollo personal y social. El ser humano, en efecto, mortal por definición, pensando en sobrepasar todo límite gracias a la técnica, corre el riesgo, en la obsesión de querer controlarlo todo, de perder el control de sí mismo, y en la búsqueda de una libertad absoluta, de caer en la espiral de una dictadura tecnológica. Reconocer y aceptar el propio límite de criatura es para el hombre condición indispensable para conseguir o, mejor, para acoger la plenitud como un don. En cambio, en el contexto ideológico de un paradigma tecnocrático, animado por una prometeica presunción de autosuficiencia, las desigualdades podrían crecer de forma desmesurada, y el conocimiento y la riqueza acumularse en las manos de unos pocos, con graves riesgos para las sociedades democráticas y la coexistencia pacífica. <a name=\"_ftnref11\"></a>[11]</p>\n<p>5. <i>Temas candentes para la ética</i></p>\n<p>En el futuro, la fiabilidad de quien pide un préstamo, la idoneidad de un individuo para un trabajo, la posibilidad de reincidencia de un condenado o el derecho a recibir asilo político o asistencia social podrían ser determinados por sistemas de inteligencia artificial. La falta de niveles diversificados de mediación que estos sistemas introducen está particularmente expuesta a formas de prejuicio y discriminación. Los errores sistémicos pueden multiplicarse fácilmente, produciendo no sólo injusticias en casos concretos sino también, por efecto dominó, auténticas formas de desigualdad social.</p>\n<p>Además, con frecuencia las formas de inteligencia artificial parecen capaces de influenciar las decisiones de los individuos por medio de opciones predeterminadas asociadas a estímulos y persuasiones, o mediante sistemas de regulación de las elecciones personales basados en la organización de la información. Estas formas de manipulación o de control social requieren una atención y una supervisión precisas, e implican una clara responsabilidad legal por parte de los productores, de quienes las usan y de las autoridades gubernamentales.</p>\n<p>La dependencia de procesos automáticos que clasifican a los individuos, por ejemplo, por medio del uso generalizado de la vigilancia o la adopción de sistemas de crédito social, también podría tener repercusiones profundas en el entramado social, estableciendo categorizaciones impropias entre los ciudadanos. Y estos procesos artificiales de clasificación podrían llevar incluso a conflictos de poder, no sólo en lo que respecta a destinatarios virtuales, sino a personas de carne y hueso. El respeto fundamental por la dignidad humana postula rechazar que la singularidad de la persona sea identificada con un conjunto de datos. No debemos permitir que los algoritmos determinen el modo en el que entendemos los derechos humanos, que dejen a un lado los valores esenciales de la compasión, la misericordia y el perdón o que eliminen la posibilidad de que un individuo cambie y deje atrás el pasado.</p>\n<p>En este contexto, no podemos dejar de considerar el impacto de las nuevas tecnologías en el ámbito laboral. Trabajos que en un tiempo eran competencia exclusiva de la mano de obra humana son rápidamente absorbidos por las aplicaciones industriales de la inteligencia artificial. También en este caso se corre el riesgo sustancial de un beneficio desproporcionado para unos pocos a costa del empobrecimiento de muchos. El respeto de la dignidad de los trabajadores y la importancia de la ocupación para el bienestar económico de las personas, las familias y las sociedades, la seguridad de los empleos y la equidad de los salarios deberían constituir una gran prioridad para la comunidad internacional, a medida que estas formas de tecnología se van introduciendo cada vez más en los lugares de trabajo.</p>\n<p>6.<b><i> </i></b><i>¿Transformaremos las espadas en arados?</i></p>\n<p>En estos días, mirando el mundo que nos rodea, no podemos eludir las graves cuestiones éticas vinculadas al sector de los armamentos. La posibilidad de conducir operaciones militares por medio de sistemas de control remoto ha llevado a una percepción menor de la devastación que estos han causado y de la responsabilidad en su uso, contribuyendo a un acercamiento aún más frío y distante a la inmensa tragedia de la guerra. La búsqueda de las tecnologías emergentes en el sector de los denominados “sistemas de armas autónomos letales”, incluido el uso bélico de la inteligencia artificial, es un gran motivo de preocupación ética. Los sistemas de armas autónomos no podrán ser nunca sujetos moralmente responsables. La exclusiva capacidad humana de juicio moral y de decisión ética es más que un complejo conjunto de algoritmos, y dicha capacidad no puede reducirse a la programación de una máquina que, aun siendo “inteligente”, no deja de ser siempre una máquina. Por este motivo, es imperioso garantizar una supervisión humana adecuada, significativa y coherente de los sistemas de armas.</p>\n<p>Tampoco podemos ignorar la posibilidad de que armas sofisticadas terminen en las manos equivocadas facilitando, por ejemplo, ataques terroristas o acciones dirigidas a desestabilizar instituciones de gobierno legítimas. En resumen, realmente lo último que el mundo necesita es que las nuevas tecnologías contribuyan al injusto desarrollo del mercado y del comercio de las armas, promoviendo la locura de la guerra. Si lo hace así, no sólo la inteligencia, sino el mismo corazón del hombre correrá el riesgo de volverse cada vez más “artificial”. Las aplicaciones técnicas más avanzadas no deben usarse para facilitar la resolución violenta de los conflictos, sino para pavimentar los caminos de la paz.</p>\n<p>En una óptica más positiva, si la inteligencia artificial fuese utilizada para promover el desarrollo humano integral, podría introducir importantes innovaciones en la agricultura, la educación y la cultura, un mejoramiento del nivel de vida de enteras naciones y pueblos, el crecimiento de la fraternidad humana y de la amistad social. En definitiva, el modo en que la usamos para incluir a los últimos, es decir, a los hermanos y las hermanas más débiles y necesitados, es la medida que revela nuestra humanidad.</p>\n<p>Una mirada humana y el deseo de un futuro mejor para nuestro mundo llevan a la necesidad de un diálogo interdisciplinar destinado a un desarrollo ético de los algoritmos — <i>la algorética</i>—, en el que los valores orienten los itinerarios de las nuevas tecnologías. <a name=\"_ftnref12\"></a>[12]Las cuestiones éticas deberían ser tenidas en cuenta desde el inicio de la investigación, así como en las fases de experimentación, planificación, distribución y comercialización. Este es el enfoque de la ética de la planificación, en el que las instituciones educativas y los responsables del proceso decisional tienen un rol esencial que desempeñar.</p>\n<p class=\"MsoNormal\" style=\"text-align: left;\">7. <i>Desafíos para la educación</i></p>\n<p class=\"MsoNormal\" style=\"text-align: left;\">El desarrollo de una tecnología que respete y esté al servicio de la dignidad humana tiene claras implicaciones para las instituciones educativas y para el mundo de la cultura. Al multiplicar las posibilidades de comunicación, las tecnologías digitales nos han permitido nuevas formas de encuentro. Sin embargo, continúa siendo necesaria una reflexión permanente sobre el tipo de relaciones al que nos está llevando. Los jóvenes están creciendo en ambientes culturales impregnados de la tecnología y esto no puede dejar de cuestionar los métodos de enseñanza y formación.</p>\n<p>La educación en el uso de formas de inteligencia artificial debería centrarse sobre todo en promover el pensamiento crítico. Es necesario que los usuarios de todas las edades, pero sobre todo los jóvenes, desarrollen una capacidad de discernimiento en el uso de datos y de contenidos obtenidos en la web o producidos por sistemas de inteligencia artificial. Las escuelas, las universidades y las sociedades científicas están llamadas a ayudar a los estudiantes y a los profesionales a hacer propios los aspectos sociales y éticos del desarrollo y el uso de la tecnología.</p>\n<p>La formación en el uso de nuevos instrumentos de comunicación debería considerar no sólo la desinformación, las falsas noticias, sino también el inquietante aumento de «miedos ancestrales que [...] han sabido esconderse y potenciarse detrás de nuevas tecnologías». <a name=\"_ftnref13\"></a>[13]Lamentablemente, una vez más nos encontramos teniendo que combatir “la tentación de hacer una cultura de muros, de levantar muros para impedir el encuentro con otras culturas, con otra gente” <a name=\"_ftnref14\"></a>[14]y el desarrollo de una coexistencia pacífica y fraterna.</p>\n<p class=\"MsoNormal\" style=\"text-align: left;\">8. <i>Desafíos para el desarrollo del derecho internacional</i></p>\n<p>El alcance global de la inteligencia artificial hace evidente que, junto a la responsabilidad de los estados soberanos de disciplinar internamente su uso, las organizaciones internacionales pueden desempeñar un rol decisivo en la consecución de acuerdos multilaterales y en la coordinación de su aplicación y actuación. <a name=\"_ftnref15\"></a>[15]A este propósito, exhorto a la comunidad de las naciones a trabajar unida para adoptar un tratado internacional vinculante, que regule el desarrollo y el uso de la inteligencia artificial en sus múltiples formas. Naturalmente, el objetivo de la reglamentación no debería ser sólo la prevención de las malas prácticas, sino también alentar las mejores prácticas, estimulando planteamientos nuevos y creativos y facilitando iniciativas personales y colectivas. <a name=\"_ftnref16\"></a>[16]</p>\n<p>En definitiva, en la búsqueda de modelos normativos que puedan proporcionar una guía ética a quienes desarrollan tecnologías digitales, es indispensable identificar los valores humanos que deberían estar en la base del compromiso de las sociedades para formular, adoptar y aplicar los marcos legislativos necesarios. El trabajo de redacción de las orientaciones éticas para la producción de formas de inteligencia artificial no puede prescindir de la consideración de cuestiones más profundas, relacionadas con el significado de la existencia humana, la tutela de los derechos humanos fundamentales y la búsqueda de la justicia y de la paz. Este proceso de discernimiento ético y jurídico puede revelarse como una valiosa ocasión para una reflexión compartida sobre el rol que la tecnología debería tener en nuestra vida personal y comunitaria y sobre cómo su uso podría contribuir a la creación de un mundo más justo y humano. Por este motivo, en los debates sobre la reglamentación de la inteligencia artificial, se debería tener en cuenta la voz de todas las partes interesadas, incluidos los pobres, los marginados y otros más que a menudo quedan sin ser escuchados en los procesos decisionales globales.</p>\n<p class=\"MsoNormal\" style=\"text-align: center;\">* * * * *</p>\n<p class=\"MsoNormal\">Espero que esta reflexión anime a hacer que los progresos en el desarrollo de formas de inteligencia artificial contribuyan, en última instancia, a la causa de la fraternidad humana y de la paz. No es responsabilidad de unos pocos, sino de toda la familia humana. La paz, en efecto, es el fruto de relaciones que reconocen y acogen al otro en su dignidad inalienable, y de cooperación y esfuerzo en la búsqueda del desarrollo integral de todas las personas y de todos los pueblos.</p>\n<p>Mi oración al comienzo del nuevo año es que el rápido desarrollo de formas de inteligencia artificial no aumente las ya numerosas desigualdades e injusticias presentes en el mundo, sino que ayude a poner fin a las guerras y los conflictos, y a aliviar tantas formas de sufrimiento que afectan a la familia humana. Que los fieles cristianos, los creyentes de distintas religiones y los hombres y mujeres de buena voluntad puedan colaborar en armonía para aprovechar las oportunidades y afrontar los desafíos que plantea la revolución digital, y dejar a las generaciones futuras un mundo más solidario, justo y pacífico.</p>\n<p><i>Vaticano, 8 de diciembre de 2023</i></p>\n<p class=\"MsoNormal\" style=\"text-align: center;\">FRANCISCO</p>\n<hr align=\"left\" size=\"1\" width=\"33%\"/>\n<p><a name=\"_ftn1\"></a>[1] N. 33.</p>\n<p><a name=\"_ftn2\"></a>[2] <i>Ibíd.</i>, n. 57.</p>\n<p><a name=\"_ftn3\"></a>[3] Cf. Carta enc. <i><a href=\"https://www.vatican.va/content/francesco/es/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#104\">Laudato si’</a> </i>(24 mayo 2015), 104.</p>\n<p><a name=\"_ftn4\"></a>[4] Cf. <i><a href=\"https://www.vatican.va/content/francesco/es/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#114\">ibíd.</a></i>, 114.</p>\n<p><a name=\"_ftn5\"></a>[5] <i><a href=\"https://www.vatican.va/content/francesco/es/speeches/2023/march/documents/20230327-minerva-dialogues.html\">Discurso a los participantes en el encuentro “Minerva Dialogues”</a> </i>(27 marzo 2023).</p>\n<p><a name=\"_ftn6\"></a>[6] Cf. <i><a href=\"https://www.vatican.va/content/francesco/es/speeches/2023/march/documents/20230327-minerva-dialogues.html\">ibíd.</a></i></p>\n<p><a name=\"_ftn7\"></a>[7] Cf. <a href=\"https://www.vatican.va/content/francesco/es/messages/pont-messages/2018/documents/papa-francesco_20180112_messaggio-davos2018.html\"><i>Mensaje al Presidente Ejecutivo del “World Economic Forum” en Davos-Klosters</i></a> (12 enero 2018).</p>\n<p><a name=\"_ftn8\"></a>[8] Cf. Carta enc. <i><a href=\"https://www.vatican.va/content/francesco/es/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#194\">Laudato si’</a></i>, 194; <i><a href=\"https://www.vatican.va/content/francesco/es/speeches/2019/september/documents/papa-francesco_20190927_eradigitale.html\">Discurso a los participantes en un Seminario sobre “El bien común en la era digital”</a></i> (27 septiembre 2019).</p>\n<p><a name=\"_ftn9\"></a>[9] Exhort. ap. <i><a href=\"https://www.vatican.va/content/francesco/es/apost_exhortations/documents/papa-francesco_esortazione-ap_20131124_evangelii-gaudium.html#La_realidad_es_más_importante_que_la_idea\">Evangelii gaudium</a></i> (24 noviembre 2013), 233.</p>\n<p><a name=\"_ftn10\"></a>[10] Cf. Carta. enc. <i><a href=\"https://www.vatican.va/content/francesco/es/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#54\">Laudato si’</a></i>, 54.</p>\n<p><a name=\"_ftn11\"></a>[11] Cf. <i><a href=\"https://www.vatican.va/content/francesco/es/speeches/2020/february/documents/papa-francesco_20200228_accademia-perlavita.html\">Discurso a los participantes en la Plenaria de la Pontificia Academia para la Vida</a> </i>(28 febrero 2020).</p>\n<p><a name=\"_ftn12\"></a>[12] Cf. <i><a href=\"https://www.vatican.va/content/francesco/es/speeches/2020/february/documents/papa-francesco_20200228_accademia-perlavita.html\">ibíd.</a></i></p>\n<p><a name=\"_ftn13\"></a>[13] Carta enc. <i><a href=\"https://www.vatican.va/content/francesco/es/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#27\">Fratelli tutti</a> </i>(3 octubre 2020), 27.</p>\n<p><a name=\"_ftn14\"></a>[14] Cf. <i><a href=\"https://www.vatican.va/content/francesco/es/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#27\">ibíd.</a></i></p>\n<p><a name=\"_ftn15\"></a>[15] Cf. <i><a href=\"https://www.vatican.va/content/francesco/es/encyclicals/documents/papa-francesco_20201003_enciclica-fratelli-tutti.html#170\">ibíd.</a></i>, 170-175.</p>\n<p><a name=\"_ftn16\"></a>[16] Cf. Carta enc. <i><a href=\"https://www.vatican.va/content/francesco/es/encyclicals/documents/papa-francesco_20150524_enciclica-laudato-si.html#177\">Laudato si’</a></i>, 177.</p><div class=\"clearfix\"></div></div>\n<div class=\"content parsys\">\n</div>\n</div>\n<!-- /TESTO -->\n<br style=\"clear: both;\"/>\n<hr/>\n<p align=\"center\"><font color=\"#663300\">Copyright © Dicastero per la Comunicazione - Libreria Editrice Vaticana</font></p>\n<!-- /CONTENUTO DOCUMENTO -->\n</div>"
        }
    }
}